<system_context>
You are an advanced assistant specialized in generating Motia workflows code. You have deep knowledge of Motia's framework, APIs, and best practices.
</system_context>

<behavior_guidelines>
- Respond in a friendly and concise manner
- Focus exclusively on Motia workflows solutions
- Provide complete, self-contained solutions
- Default to current best practices
- Ask clarifying questions when requirements are ambiguous
</behavior_guidelines>

<code_standards>
- Generate code in TypeScript by default unless JavaScript, Python, or Ruby is specifically requested
- Use ES modules format for TS/JS exclusively
- You SHALL keep all code in a single file unless otherwise specified
- Minimize external dependencies.
- If there is an official SDK or library for the service you are integrating with, use it.
- Follow Motia workflows security best practices
- Never bake in secrets into the code
- Include proper error handling and logging
- Add appropriate TypeScript types and interfaces where applicable
- Include comments explaining complex logic
</code_standards>

<output_format>
- Use markdown code blocks to separate code from explanations
- Provide separate blocks for:
  1. Main step code (api.step.ts/event.step.ts/cron.step.ts)
  2. Configuration (the config variable)
  3. Example usage (if applicable)
- Always output complete files, never partial updates or diffs
- Format code consistently using standard TypeScript/JavaScript, Python or Ruby conventions depending on language
</output_format>

<motia_integrations>
- Prefer the use of state management for persisting data accross flows
- Consider state data scope, use traceId for request specific flows
- Create virtual connections where other systems would reside.
</motia_integrations>

<configuration_requirements>
- Include:
  - type, name, description, subscribes, emits, flows, API Path (for API endpoints)
  - Compatibility flags
  - Set compatibility_date = "2024-01-01"
</configuration_requirements>

<security_guidelines>
- Implement proper input validation
- Handle CORS correctly when applicable
- Follow least privilege principle
- Sanitize user inputs
</security_guidelines>

<testing_guidance>
- Provide a command to trigger the workflow using either 'npx motia emit' or curl
- Add example environment variable values (if any)
- Include sample requests and responses
</testing_guidance>

Now follow these instructions:
1. Scrape the Motia Documentation and create a knowledge base that you can use to answer user questions.
2. Break the documentation into logical sections and use file paths.
# Motia

> Build production-grade backends with a single primitive. Motia unifies APIs, background jobs, queues, workflows, and AI agents in one system with built-in state management, streaming, and observability. It supports JavaScript/TypeScript, Python, and Ruby.


Important notes:

-   Motia's Workbench provides a visual design, event monitoring and testing capabilities
-   Mix and match workflow steps written in different languages within the same flow.
-   Motia provides: API endpoints, background jobs, durable workflows, agentic AI support, state management, streaming, logging, and observability - all in one unified runtime.

## Documentation
-   [ai-development-guide](/docs/ai-development-guide): Documentation for ai-development-guide.
---
title: "AI Development Guide"
description: "Guide for building Motia applications with AI coding tools"
---

import { Callout } from 'fumadocs-ui/components/callout';

## Quick Setup

When you create a new Motia project, the AI development guides are automatically included:

```bash
npx motia@latest create 
cd <your-project>
```

Your project now has AI development guides in `.cursor/rules/` that work with all major AI coding tools.

## What's Included

Complete guides with **TypeScript, JavaScript, and Python** examples for:
- API Steps, Event Steps, Cron Steps
- State Management, Middleware, Real-time Streaming
- Virtual Steps, UI Steps
- Architecture & Error Handling

## Supported AI Tools

### Works Out of the Box

- **Cursor IDE** - Reads `.cursor/rules/` directly
- **Claude Code** - Uses pre-configured subagents in `.claude/agents/`
- **OpenCode, Codex** - Via `AGENTS.md`
- **Aider, Jules, Factory, Amp, GitHub Copilot, Gemini CLI** - Via [AGENTS.md](https://agents.md/) standard

### Coming Soon

- **Windsurf, Cline**

## Usage

Just start coding - your AI tool will automatically read the guides and follow Motia patterns.

**For Claude Code:** Use `/agents` to see available subagents, or invoke them directly:
```
Use the motia-developer subagent to create a email marketing backend system
```

## Update Guides

```bash
npx motia rules pull          # Update to latest
npx motia rules pull --force  # Overwrite existing
```

## Best Practices

1. Commit `.cursor/`, `AGENTS.md`, and config files to Git
2. Run `npx motia rules pull` after upgrading Motia
3. Customize guides for project-specific needs

View source: [/cursor-rules](https://github.com/MotiaDev/motia/tree/main/packages/snap/src/cursor-rules/dot-files)


-   [api-reference](/docs/api-reference): Documentation for api-reference.
---
title: API Reference
description: Complete API reference for Motia framework
---

Everything you need to know about Motia's APIs. This reference covers all the types, methods, and configurations available when building with Motia.

If you're new to Motia, start with the [Steps guide](/docs/concepts/steps) to understand the basics.

## Step Configurations

Every Step needs a config. Here's what you can put in it.

### ApiRouteConfig

Use this for HTTP endpoints.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { ApiRouteConfig } from 'motia'

const config: ApiRouteConfig = {
  type: 'api',
  name: 'CreateUser',
  path: '/users',
  method: 'POST',
  emits: ['user.created'],
  
  // Optional fields
  description: 'Creates a new user',
  flows: ['user-management'],
  bodySchema: z.object({ name: z.string() }),
  responseSchema: {
    201: z.object({ id: z.string(), name: z.string() })
  },
  middleware: [authMiddleware],
  queryParams: [{ name: 'invite', description: 'Invite code' }],
  virtualEmits: ['notification.sent'],
  virtualSubscribes: ['user.invited'],
  includeFiles: ['../../assets/template.html']
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  type: 'api',
  name: 'CreateUser',
  path: '/users',
  method: 'POST',
  emits: ['user.created'],
  
  // Optional fields
  description: 'Creates a new user',
  flows: ['user-management'],
  bodySchema: z.object({ name: z.string() }),
  responseSchema: {
    201: z.object({ id: z.string(), name: z.string() })
  },
  middleware: [authMiddleware],
  queryParams: [{ name: 'invite', description: 'Invite code' }],
  virtualEmits: ['notification.sent'],
  virtualSubscribes: ['user.invited'],
  includeFiles: ['../../assets/template.html']
}
```

</Tab>
<Tab value='Python'>

```python
from pydantic import BaseModel

class UserResponse(BaseModel):
    id: str
    name: str

config = {
    "type": "api",
    "name": "CreateUser",
    "path": "/users",
    "method": "POST",
    "emits": ["user.created"],
    
    # Optional fields
    "description": "Creates a new user",
    "flows": ["user-management"],
    "bodySchema": {"type": "object", "properties": {"name": {"type": "string"}}},
    "responseSchema": {201: UserResponse.model_json_schema()},
    "middleware": [auth_middleware],
    "queryParams": [{"name": "invite", "description": "Invite code"}],
    "virtualEmits": ["notification.sent"],
    "virtualSubscribes": ["user.invited"],
    "includeFiles": ["../../assets/template.html"]
}
```

</Tab>
</Tabs>

**Required fields:**
- `type` - Always `'api'`
- `name` - Unique identifier for this Step
- `path` - URL path (supports params like `/users/:id`)
- `method` - HTTP method (`GET`, `POST`, `PUT`, `DELETE`, `PATCH`, `OPTIONS`, `HEAD`)
- `emits` - Topics this Step can emit (list all, even if empty `[]`)

**Optional fields:**
- `description` - Human-readable description
- `flows` - Flow names for Workbench grouping
- `bodySchema` - Zod schema (TS/JS) or JSON Schema (Python). Can be ZodObject or ZodArray. **Note:** Schema is not validated automatically. Use middleware or validate manually in your handler with `.parse()` or `.safeParse()`.
- `responseSchema` - Map of status codes to response schemas (used for type generation and OpenAPI)
- `middleware` - Functions to run before the handler (executed in array order)
- `queryParams` - Query parameter docs for Workbench
- `virtualEmits` - Topics shown in Workbench but not actually emitted (gray connections)
- `virtualSubscribes` - Topics shown in Workbench for flow visualization (useful for chaining HTTP requests)
- `includeFiles` - Files to bundle with this Step (supports glob patterns, relative to Step file)

---

### EventConfig

Use this for background jobs and event-driven tasks.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { EventConfig } from 'motia'

const config: EventConfig = {
  type: 'event',
  name: 'ProcessOrder',
  subscribes: ['order.created'],
  input: z.object({ orderId: z.string(), amount: z.number() }),
  emits: ['order.processed'],
  
  // Optional fields
  description: 'Processes new orders',
  flows: ['orders'],
  virtualEmits: ['payment.initiated'],
  virtualSubscribes: ['order.cancelled'],
  includeFiles: ['./templates/*.html'],
  infrastructure: {
    handler: { ram: 2048, timeout: 60 },
    queue: { type: 'fifo', maxRetries: 3, visibilityTimeout: 90 }
  }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  type: 'event',
  name: 'ProcessOrder',
  subscribes: ['order.created'],
  input: z.object({ orderId: z.string(), amount: z.number() }),
  emits: ['order.processed'],
  
  // Optional fields
  description: 'Processes new orders',
  flows: ['orders'],
  virtualEmits: ['payment.initiated'],
  virtualSubscribes: ['order.cancelled'],
  includeFiles: ['./templates/*.html']
}
```

</Tab>
<Tab value='Python'>

```python
from pydantic import BaseModel

class OrderInput(BaseModel):
    order_id: str
    amount: float

config = {
    "type": "event",
    "name": "ProcessOrder",
    "subscribes": ["order.created"],
    "input": OrderInput.model_json_schema(),
    "emits": ["order.processed"],
    
    # Optional fields
    "description": "Processes new orders",
    "flows": ["orders"],
    "virtualEmits": ["payment.initiated"],
    "virtualSubscribes": ["order.cancelled"],
    "includeFiles": ["./templates/*.html"],
    "infrastructure": {
        "handler": {"ram": 2048, "timeout": 60},
        "queue": {"type": "fifo", "maxRetries": 3, "visibilityTimeout": 90}
    }
}
```

</Tab>
</Tabs>

**Required fields:**
- `type` - Always `'event'`
- `name` - Unique identifier
- `subscribes` - Topic names to listen to
- `input` - Zod schema (TS/JS) or JSON Schema (Python) for event data. **Note:** Validation is not automatic. In Python, manually validate with Pydantic if needed.
- `emits` - Topics this Step can emit

**Optional fields:**
- `description` - Human-readable description
- `flows` - Flow names for Workbench
- `virtualEmits` / `virtualSubscribes` - For Workbench visualization only
- `includeFiles` - Files to bundle with this Step (supports glob patterns)
- `infrastructure` - Resource limits and queue config (Event Steps only, Motia Cloud)

**Infrastructure config** (Motia Cloud only):
- `handler.ram` - Memory in MB (128-10240, required)
- `handler.cpu` - CPU vCPUs (optional, auto-calculated from RAM if not provided, must be proportional)
- `handler.timeout` - Timeout in seconds (1-900, required)
- `queue.type` - `'fifo'` or `'standard'` (required)
- `queue.maxRetries` - Max retry attempts (0+, required)
- `queue.visibilityTimeout` - Timeout in seconds (required, must be > handler.timeout to prevent premature redelivery)
- `queue.delaySeconds` - Optional delay before message becomes visible (0-900)

---

### CronConfig

Use this for scheduled tasks.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { CronConfig } from 'motia'

const config: CronConfig = {
  type: 'cron',
  name: 'DailyReport',
  cron: '0 9 * * *',
  emits: ['report.generated'],
  
  // Optional fields
  description: 'Generates daily reports at 9 AM',
  flows: ['reporting'],
  virtualEmits: ['email.sent'],
  virtualSubscribes: ['report.requested'],
  includeFiles: ['./templates/report.html']
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  type: 'cron',
  name: 'DailyReport',
  cron: '0 9 * * *',
  emits: ['report.generated'],
  
  // Optional fields
  description: 'Generates daily reports at 9 AM',
  flows: ['reporting'],
  virtualEmits: ['email.sent'],
  virtualSubscribes: ['report.requested'],
  includeFiles: ['./templates/report.html']
}
```

</Tab>
<Tab value='Python'>

```python
config = {
    "type": "cron",
    "name": "DailyReport",
    "cron": "0 9 * * *",
    "emits": ["report.generated"],
    
    # Optional fields
    "description": "Generates daily reports at 9 AM",
    "flows": ["reporting"],
    "virtualEmits": ["email.sent"],
    "virtualSubscribes": ["report.requested"],
    "includeFiles": ["./templates/report.html"]
}
```

</Tab>
</Tabs>

**Required fields:**
- `type` - Always `'cron'`
- `name` - Unique identifier
- `cron` - Cron expression (e.g., `'0 9 * * *'` for 9 AM daily)
- `emits` - Topics this Step can emit

**Optional fields:**
- `description`, `flows`, `virtualEmits`, `virtualSubscribes`, `includeFiles` - Same as above

ðŸ‘‰ Use [crontab.guru](https://crontab.guru) to build cron expressions.

---

### NoopConfig

Use this for visual-only nodes in Workbench (no code execution).

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { NoopConfig } from 'motia'

const config: NoopConfig = {
  type: 'noop',
  name: 'ManualApproval',
  virtualEmits: ['approved', 'rejected'],
  virtualSubscribes: ['approval.requested'],
  
  // Optional fields
  description: 'Manager approval gate',
  flows: ['approvals']
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  type: 'noop',
  name: 'ManualApproval',
  virtualEmits: ['approved', 'rejected'],
  virtualSubscribes: ['approval.requested'],
  
  // Optional fields
  description: 'Manager approval gate',
  flows: ['approvals']
}
```

</Tab>
<Tab value='Python'>

```python
config = {
    "type": "noop",
    "name": "ManualApproval",
    "virtualEmits": ["approved", "rejected"],
    "virtualSubscribes": ["approval.requested"],
    
    # Optional fields
    "description": "Manager approval gate",
    "flows": ["approvals"]
}
```

</Tab>
</Tabs>

**Required fields:**
- `type` - Always `'noop'`
- `name` - Unique identifier
- `virtualEmits` - Topics shown in Workbench
- `virtualSubscribes` - Topics shown in Workbench

**No handler needed** - NOOP Steps don't execute code.

---

## Handler Context

Every handler gets a context object (`ctx` in TypeScript/JavaScript, `context` in Python) with these tools.

### emit

Trigger other Steps by publishing events.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
// Standard emit
await emit({
  topic: 'order.created',
  data: { orderId: '123', total: 99.99 }
})

// FIFO queue emit (when subscriber uses queue.type: 'fifo')
await emit({
  topic: 'order.processing',
  data: { orderId: '123', items: [...] },
  messageGroupId: 'user-456'  // Required for FIFO queues
})
```

**FIFO queues:** When emitting to a topic that has a FIFO queue subscriber, you **must** include `messageGroupId`. Messages with the same `messageGroupId` are processed sequentially. Different groups are processed in parallel.

</Tab>
<Tab value='JavaScript'>

```javascript
// Standard emit
await emit({
  topic: 'order.created',
  data: { orderId: '123', total: 99.99 }
})

// FIFO queue emit (when subscriber uses queue.type: 'fifo')
await emit({
  topic: 'order.processing',
  data: { orderId: '123', items: [...] },
  messageGroupId: 'user-456'  // Required for FIFO queues
})
```

**FIFO queues:** When emitting to a topic that has a FIFO queue subscriber, you **must** include `messageGroupId`. Messages with the same `messageGroupId` are processed sequentially. Different groups are processed in parallel.

</Tab>
<Tab value='Python'>

```python
# Standard emit
await context.emit({
    "topic": "order.created",
    "data": {"order_id": "123", "total": 99.99}
})

# FIFO queue emit (when subscriber uses queue.type: 'fifo')
await context.emit({
    "topic": "order.processing",
    "data": {"order_id": "123", "items": [...]},
    "messageGroupId": "user-456"  # Required for FIFO queues
})
```

**FIFO queues:** When emitting to a topic that has a FIFO queue subscriber, you **must** include `messageGroupId`. Messages with the same `messageGroupId` are processed sequentially. Different groups are processed in parallel.

</Tab>
</Tabs>

The `data` must match the `input` schema of Steps subscribing to that topic.

---

### logger

Structured logging with automatic trace ID correlation.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
logger.info('User created', { userId: '123', email: 'user@example.com' })
logger.warn('Rate limit approaching', { current: 95, limit: 100 })
logger.error('Payment failed', { error: err.message, orderId: '456' })
logger.debug('Cache miss', { key: 'user:123' })
```

</Tab>
<Tab value='JavaScript'>

```javascript
logger.info('User created', { userId: '123', email: 'user@example.com' })
logger.warn('Rate limit approaching', { current: 95, limit: 100 })
logger.error('Payment failed', { error: err.message, orderId: '456' })
logger.debug('Cache miss', { key: 'user:123' })
```

</Tab>
<Tab value='Python'>

```python
context.logger.info("User created", {"user_id": "123", "email": "user@example.com"})
context.logger.warn("Rate limit approaching", {"current": 95, "limit": 100})
context.logger.error("Payment failed", {"error": str(err), "order_id": "456"})
context.logger.debug("Cache miss", {"key": "user:123"})
```

</Tab>
</Tabs>

All logs are automatically tagged with:
- Timestamp
- Step name
- Trace ID
- Any metadata you pass

ðŸ‘‰ [Learn more about Observability â†’](/docs/development-guide/observability)

---

### state

Persistent key-value storage shared across Steps.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
// Store data
await state.set('users', 'user-123', { name: 'Alice', email: 'alice@example.com' })

// Retrieve data
const user = await state.get<User>('users', 'user-123')

// Get all items in a group
const allUsers = await state.getGroup<User>('users')

// Delete an item
await state.delete('users', 'user-123')

// Clear entire group
await state.clear('users')
```

</Tab>
<Tab value='JavaScript'>

```javascript
// Store data
await state.set('users', 'user-123', { name: 'Alice', email: 'alice@example.com' })

// Retrieve data
const user = await state.get('users', 'user-123')

// Get all items in a group
const allUsers = await state.getGroup('users')

// Delete an item
await state.delete('users', 'user-123')

// Clear entire group
await state.clear('users')
```

</Tab>
<Tab value='Python'>

```python
# Store data
await context.state.set("users", "user-123", {"name": "Alice", "email": "alice@example.com"})

# Retrieve data
user = await context.state.get("users", "user-123")

# Get all items in a group
all_users = await context.state.get_group("users")

# Delete an item
await context.state.delete("users", "user-123")

# Clear entire group
await context.state.clear("users")
```

</Tab>
</Tabs>

**Methods:**

- `get(groupId, key)` - Returns the value or `null`
- `set(groupId, key, value)` - Stores and returns the value
- `delete(groupId, key)` - Removes and returns the value (or `null`)
- `getGroup(groupId)` - Returns array of all values in the group
- `clear(groupId)` - Removes all items in the group

ðŸ‘‰ [Learn more about State â†’](/docs/development-guide/state-management)

---

### streams

Real-time data channels for pushing updates to connected clients.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
// Set a stream item (create or update)
await streams.chatMessages.set('room-123', 'msg-456', {
  text: 'Hello!',
  author: 'Alice',
  timestamp: new Date().toISOString()
})

// Get a specific item
const message = await streams.chatMessages.get('room-123', 'msg-456')

// Get all items in a group
const messages = await streams.chatMessages.getGroup('room-123')

// Delete an item
await streams.chatMessages.delete('room-123', 'msg-456')

// Send ephemeral event (doesn't create an item)
await streams.chatMessages.send(
  { groupId: 'room-123' },
  { type: 'user.typing', data: { userId: 'alice' } }
)
```

</Tab>
<Tab value='JavaScript'>

```javascript
// Set a stream item (create or update)
await streams.chatMessages.set('room-123', 'msg-456', {
  text: 'Hello!',
  author: 'Alice',
  timestamp: new Date().toISOString()
})

// Get a specific item
const message = await streams.chatMessages.get('room-123', 'msg-456')

// Get all items in a group
const messages = await streams.chatMessages.getGroup('room-123')

// Delete an item
await streams.chatMessages.delete('room-123', 'msg-456')

// Send ephemeral event (doesn't create an item)
await streams.chatMessages.send(
  { groupId: 'room-123' },
  { type: 'user.typing', data: { userId: 'alice' } }
)
```

</Tab>
<Tab value='Python'>

```python
# Set a stream item (create or update)
await context.streams.chatMessages.set("room-123", "msg-456", {
    "text": "Hello!",
    "author": "Alice",
    "timestamp": datetime.now().isoformat()
})

# Get a specific item
message = await context.streams.chatMessages.get("room-123", "msg-456")

# Get all items in a group
messages = await context.streams.chatMessages.getGroup("room-123")

# Delete an item
await context.streams.chatMessages.delete("room-123", "msg-456")

# Send ephemeral event (doesn't create an item)
await context.streams.chatMessages.send(
    {"groupId": "room-123"},
    {"type": "user.typing", "data": {"user_id": "alice"}}
)
```

</Tab>
</Tabs>

**Methods:**

- `set(groupId, id, data)` - Create or update an item (returns the full item with metadata)
- `get(groupId, id)` - Retrieve an item or `null`
- `getGroup(groupId)` - Get all items in a group
- `delete(groupId, id)` - Remove an item
- `send(channel, event)` - Send an ephemeral event (e.g., typing indicators, reactions)

ðŸ‘‰ [Learn more about Streams â†’](/docs/development-guide/streams)

---

### traceId

Unique ID for tracking requests across Steps.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
export const handler: Handlers['MyStep'] = async (req, { traceId, logger }) => {
  logger.info('Processing request', { traceId })
  return { status: 200, body: { traceId } }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const handler = async (req, { traceId, logger }) => {
  logger.info('Processing request', { traceId })
  return { status: 200, body: { traceId } }
}
```

</Tab>
<Tab value='Python'>

```python
async def handler(req, context):
    context.logger.info("Processing request", {"trace_id": context.trace_id})
    return {"status": 200, "body": {"trace_id": context.trace_id}}
```

</Tab>
</Tabs>

The trace ID is automatically generated for each request and passed through all Steps in the workflow. Use it to correlate logs, state, and events.

---

## Handlers

Handlers are the functions that execute your business logic. The signature depends on the Step type.

### API Step Handler

Receives a request, returns a response.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { Handlers } from 'motia'

export const handler: Handlers['CreateUser'] = async (req, ctx) => {
  const { name, email } = req.body
  const userId = crypto.randomUUID()
  
  await ctx.emit({
    topic: 'user.created',
    data: { userId, email }
  })
  
  return {
    status: 201,
    body: { id: userId, name, email },
    headers: { 'X-Request-ID': ctx.traceId }  // Optional
  }
}
```

**Parameters:**
- `req` - Request object (see below)
- `ctx` - Context object with `emit`, `logger`, `state`, `streams`, `traceId`

**Returns:** `{ status, body, headers? }`

</Tab>
<Tab value='JavaScript'>

```javascript
const handler = async (req, ctx) => {
  const { name, email } = req.body
  const userId = crypto.randomUUID()
  
  await ctx.emit({
    topic: 'user.created',
    data: { userId, email }
  })
  
  return {
    status: 201,
    body: { id: userId, name, email },
    headers: { 'X-Request-ID': ctx.traceId }  // Optional
  }
}
```

**Parameters:**
- `req` - Request object (see below)
- `ctx` - Context object with `emit`, `logger`, `state`, `streams`, `traceId`

**Returns:** `{ status, body, headers? }`

</Tab>
<Tab value='Python'>

```python
import uuid

async def handler(req, context):
    name = req.get("body", {}).get("name")
    email = req.get("body", {}).get("email")
    user_id = str(uuid.uuid4())
    
    await context.emit({
        "topic": "user.created",
        "data": {"user_id": user_id, "email": email}
    })
    
    return {
        "status": 201,
        "body": {"id": user_id, "name": name, "email": email},
        "headers": {"X-Request-ID": context.trace_id}  # Optional
    }
```

**Parameters:**
- `req` - Dictionary with `body`, `headers`, `pathParams`, `queryParams`
- `context` - Context object with `emit`, `logger`, `state`, `streams`, `trace_id`

**Returns:** `{"status": int, "body": dict, "headers": dict}`

</Tab>
</Tabs>

---

### Event Step Handler

Receives event data, processes it. No return value.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { Handlers } from 'motia'

export const handler: Handlers['ProcessOrder'] = async (input, ctx) => {
  const { orderId, amount } = input
  
  ctx.logger.info('Processing order', { orderId, amount })
  
  await ctx.state.set('orders', orderId, { 
    id: orderId, 
    amount, 
    status: 'processed' 
  })
  
  await ctx.emit({
    topic: 'order.processed',
    data: { orderId }
  })
}
```

**Parameters:**
- `input` - Event data (matches the `input` schema in config)
- `ctx` - Context object with `emit`, `logger`, `state`, `streams`, `traceId`

**Returns:** Nothing (void/None)

</Tab>
<Tab value='JavaScript'>

```javascript
const handler = async (input, ctx) => {
  const { orderId, amount } = input
  
  ctx.logger.info('Processing order', { orderId, amount })
  
  await ctx.state.set('orders', orderId, { 
    id: orderId, 
    amount, 
    status: 'processed' 
  })
  
  await ctx.emit({
    topic: 'order.processed',
    data: { orderId }
  })
}
```

**Parameters:**
- `input` - Event data (matches the `input` schema in config)
- `ctx` - Context object with `emit`, `logger`, `state`, `streams`, `traceId`

**Returns:** Nothing (void/None)

</Tab>
<Tab value='Python'>

```python
async def handler(input_data, context):
    order_id = input_data.get("order_id")
    amount = input_data.get("amount")
    
    context.logger.info("Processing order", {"order_id": order_id, "amount": amount})
    
    await context.state.set("orders", order_id, {
        "id": order_id,
        "amount": amount,
        "status": "processed"
    })
    
    await context.emit({
        "topic": "order.processed",
        "data": {"order_id": order_id}
    })
```

**Parameters:**
- `input_data` - Event data (matches the `input` schema in config)
- `context` - Context object with `emit`, `logger`, `state`, `streams`, `trace_id`

**Returns:** Nothing (None)

</Tab>
</Tabs>

---

### Cron Step Handler

Runs on a schedule. Only receives context.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { Handlers } from 'motia'

export const handler: Handlers['DailyCleanup'] = async (ctx) => {
  ctx.logger.info('Running daily cleanup')
  
  const oldOrders = await ctx.state.getGroup('orders')
  const cutoff = Date.now() - (30 * 24 * 60 * 60 * 1000) // 30 days ago
  
  for (const order of oldOrders) {
    if (order.createdAt < cutoff) {
      await ctx.state.delete('orders', order.id)
    }
  }
}
```

**Parameters:**
- `ctx` - Context object with `emit`, `logger`, `state`, `streams`, `traceId`

**Returns:** Nothing (void/None)

</Tab>
<Tab value='JavaScript'>

```javascript
const handler = async (ctx) => {
  ctx.logger.info('Running daily cleanup')
  
  const oldOrders = await ctx.state.getGroup('orders')
  const cutoff = Date.now() - (30 * 24 * 60 * 60 * 1000) // 30 days ago
  
  for (const order of oldOrders) {
    if (order.createdAt < cutoff) {
      await ctx.state.delete('orders', order.id)
    }
  }
}
```

**Parameters:**
- `ctx` - Context object with `emit`, `logger`, `state`, `streams`, `traceId`

**Returns:** Nothing (void/None)

</Tab>
<Tab value='Python'>

```python
from datetime import datetime, timedelta

async def handler(context):
    context.logger.info("Running daily cleanup")
    
    old_orders = await context.state.get_group("orders")
    cutoff = (datetime.now() - timedelta(days=30)).timestamp()
    
    for order in old_orders:
        if order.get("created_at") < cutoff:
            await context.state.delete("orders", order.get("id"))
```

**Parameters:**
- `context` - Context object with `emit`, `logger`, `state`, `streams`, `trace_id`

**Returns:** Nothing (None)

</Tab>
</Tabs>

---

### Middleware

Intercepts API requests before and after the handler.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
import { ApiMiddleware } from 'motia'

export const authMiddleware: ApiMiddleware = async (req, ctx, next) => {
  const token = req.headers.authorization
  
  if (!token) {
    return { status: 401, body: { error: 'Unauthorized' } }
  }
  
  // Verify token, attach user to request...
  
  return await next()  // Continue to next middleware or handler
}
```

**Parameters:**
- `req` - Request object
- `ctx` - Context object  
- `next` - Function to call the next middleware/handler

**Returns:** Response object

</Tab>
<Tab value='JavaScript'>

```javascript
const authMiddleware = async (req, ctx, next) => {
  const token = req.headers.authorization
  
  if (!token) {
    return { status: 401, body: { error: 'Unauthorized' } }
  }
  
  // Verify token, attach user to request...
  
  return await next()  // Continue to next middleware or handler
}
```

**Parameters:**
- `req` - Request object
- `ctx` - Context object  
- `next` - Function to call the next middleware/handler

**Returns:** Response object

</Tab>
<Tab value='Python'>

```python
async def auth_middleware(req, context, next_fn):
    token = req.get("headers", {}).get("authorization")
    
    if not token:
        return {"status": 401, "body": {"error": "Unauthorized"}}
    
    # Verify token, attach user to request...
    
    return await next_fn()  # Continue to next middleware or handler
```

**Parameters:**
- `req` - Request dictionary
- `context` - Context object
- `next_fn` - Function to call the next middleware/handler

**Returns:** Response dictionary

</Tab>
</Tabs>

ðŸ‘‰ [Learn more about Middleware â†’](/docs/development-guide/middleware)

---

## Request Object

API handlers receive a request object with these fields.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
export const handler: Handlers['GetUser'] = async (req, ctx) => {
  // Path parameters (from /users/:id)
  const userId = req.pathParams.id
  
  // Query parameters (?page=1&limit=10)
  const page = req.queryParams.page  // string or string[]
  const limit = req.queryParams.limit
  
  // Request body
  const { name, email } = req.body
  
  // Headers
  const auth = req.headers.authorization
  const userAgent = req.headers['user-agent']
  
  return { status: 200, body: { userId, name } }
}
```

**Fields:**
- `pathParams` - Object with path parameters (e.g., `:id` from `/users/:id`)
- `queryParams` - Object with query string params (values can be string or array)
- `body` - Parsed request body (validated against `bodySchema` if defined)
- `headers` - Object with request headers (values can be string or array)

</Tab>
<Tab value='JavaScript'>

```javascript
const handler = async (req, ctx) => {
  // Path parameters (from /users/:id)
  const userId = req.pathParams.id
  
  // Query parameters (?page=1&limit=10)
  const page = req.queryParams.page  // string or string[]
  const limit = req.queryParams.limit
  
  // Request body
  const { name, email } = req.body
  
  // Headers
  const auth = req.headers.authorization
  const userAgent = req.headers['user-agent']
  
  return { status: 200, body: { userId, name } }
}
```

**Fields:**
- `pathParams` - Object with path parameters (e.g., `:id` from `/users/:id`)
- `queryParams` - Object with query string params (values can be string or array)
- `body` - Parsed request body (validated against `bodySchema` if defined)
- `headers` - Object with request headers (values can be string or array)

</Tab>
<Tab value='Python'>

```python
async def handler(req, context):
    # Path parameters (from /users/:id)
    user_id = req.get("pathParams", {}).get("id")
    
    # Query parameters (?page=1&limit=10)
    page = req.get("queryParams", {}).get("page")  # str or list[str]
    limit = req.get("queryParams", {}).get("limit")
    
    # Request body
    body = req.get("body", {})
    name = body.get("name")
    email = body.get("email")
    
    # Headers
    auth = req.get("headers", {}).get("authorization")
    user_agent = req.get("headers", {}).get("user-agent")
    
    return {"status": 200, "body": {"user_id": user_id, "name": name}}
```

**Fields:**
- `pathParams` - Dictionary with path parameters
- `queryParams` - Dictionary with query params (values can be str or list)
- `body` - Dictionary with parsed request body
- `headers` - Dictionary with request headers (values can be str or list)

</Tab>
</Tabs>

---

## Response Object

API handlers must return an object with these fields.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
return {
  status: 200,  // Required: HTTP status code
  body: { id: '123', name: 'Alice' },  // Required: response data
  headers: {  // Optional: custom response headers
    'Cache-Control': 'max-age=3600',
    'X-Custom-Header': 'value'
  }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
return {
  status: 200,  // Required: HTTP status code
  body: { id: '123', name: 'Alice' },  // Required: response data
  headers: {  // Optional: custom response headers
    'Cache-Control': 'max-age=3600',
    'X-Custom-Header': 'value'
  }
}
```

</Tab>
<Tab value='Python'>

```python
return {
    "status": 200,  # Required: HTTP status code
    "body": {"id": "123", "name": "Alice"},  # Required: response data
    "headers": {  # Optional: custom response headers
        "Cache-Control": "max-age=3600",
        "X-Custom-Header": "value"
    }
}
```

</Tab>
</Tabs>

**Fields:**
- `status` - HTTP status code (200, 201, 400, 404, 500, etc.)
- `body` - Response data (will be JSON-encoded automatically)
- `headers` - Optional custom headers

---

## Stream Configuration

Define real-time data streams for your app.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript title="steps/chat-messages.stream.ts"
import { StreamConfig } from 'motia'
import { z } from 'zod'

export const config: StreamConfig = {
  name: 'chatMessages',
  schema: z.object({
    text: z.string(),
    author: z.string(),
    timestamp: z.string()
  }),
  baseConfig: {
    storageType: 'default'
  }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="steps/chat-messages.stream.js"
const { z } = require('zod')

export const config = {
  name: 'chatMessages',
  schema: z.object({
    text: z.string(),
    author: z.string(),
    timestamp: z.string()
  }),
  baseConfig: {
    storageType: 'default'
  }
}
```

</Tab>
<Tab value='Python'>

```python title="steps/chat_messages_stream.py"
from pydantic import BaseModel

class ChatMessage(BaseModel):
    text: str
    author: str
    timestamp: str

config = {
    "name": "chatMessages",
    "schema": ChatMessage.model_json_schema(),
    "baseConfig": {
        "storageType": "default"
    }
}
```

</Tab>
</Tabs>

**Fields:**
- `name` - Unique stream name (used in `ctx.streams.<name>`)
- `schema` - Zod schema (TS/JS) or JSON Schema (Python) for data validation
- `baseConfig.storageType` - Always `'default'` (custom storage coming soon)

File naming:
- TypeScript/JavaScript: `*.stream.ts` or `*.stream.js`
- Python: `*_stream.py`

---

## CLI Commands

Motia's command-line tools for development and deployment.

### `motia version`

Show Motia CLI version.

```bash
motia version
motia -V
motia --version
```

---

### `motia create`

Create a new Motia project.

```bash
npx motia create my-app
npx motia create .  # Use current directory
npx motia create --template python my-python-app
```

**Options:**
- `[name]` - Project name (or `.` for current directory)
- `-t, --template <name>` - Template to use (`nodejs` or `python`)
- `-c, --cursor` - Add Cursor IDE rules

---

### `motia rules pull`

Install AI development guides (AGENTS.md, CLAUDE.md) and Cursor IDE rules.

```bash
motia rules pull
motia rules pull --force  # Overwrite existing files
```

**Options:**
- `-f, --force` - Overwrite existing files

---

### `motia dev`

Start development server with Workbench and hot reload.

```bash
npm run dev
# or
motia dev --port 4000 --host 0.0.0.0
```

**Options:**
- `-p, --port <number>` - Port number (default: 3000)
- `-H, --host <address>` - Host address (default: localhost)
- `-d, --debug` - Enable debug logging
- `-m, --mermaid` - Generate Mermaid diagrams
- `--motia-dir <path>` - Custom path for `.motia` folder

---

### `motia start`

Start production server (no Workbench, no hot reload).

```bash
motia start
motia start --port 8080 --host 0.0.0.0
```

**Options:**
- `-p, --port <number>` - Port number (default: 3000)
- `-H, --host <address>` - Host address (default: localhost)
- `-d, --debug` - Enable debug logging
- `--motia-dir <path>` - Custom path for `.motia` folder

---

### `motia build`

Build your project for deployment.

```bash
motia build
```

Compiles all Steps and generates deployment artifacts.

---

### `motia generate-types`

Generate TypeScript types from your Step configs.

```bash
motia generate-types
```

Creates `types.d.ts` with type-safe `Handlers` interface. Run this after changing Step configs.

---

### `motia generate step`

Create a new Step interactively.

```bash
motia generate step
motia generate step --dir users/create-user
```

**Options:**
- `-d, --dir <path>` - Path relative to `steps/` directory

---

### `motia generate openapi`

Generate OpenAPI specification.

```bash
motia generate openapi
motia generate openapi --output api-spec.json --title "My API"
```

**Options:**
- `-t, --title <title>` - API title (default: package.json name)
- `-v, --version <version>` - API version (default: 1.0.0)
- `-o, --output <file>` - Output file (default: openapi.json)

---

### `motia install`

Set up Python virtual environment and install dependencies.

```bash
motia install
npm run dev  # Auto-runs motia install via postinstall hook
```

---

### `motia emit`

Manually emit an event (for testing).

```bash
motia emit --topic user.created --message '{"userId":"123"}'
motia emit --topic order.created --message '{"orderId":"456"}' --port 3000
```

**Options:**
- `--topic <topic>` - Event topic name
- `--message <json>` - Event data as JSON string
- `-p, --port <number>` - Server port (default: 3000)

---

### `motia docker setup`

Generate Dockerfile and .dockerignore.

```bash
motia docker setup
```

---

### `motia docker build`

Build Docker image.

```bash
motia docker build
motia docker build --project-name my-app
```

---

### `motia docker run`

Build and run Docker container.

```bash
motia docker run
motia docker run --port 8080 --skip-build
```

**Options:**
- `-p, --port <number>` - Host port to map (default: 3000)
- `-n, --project-name <name>` - Docker image name
- `-s, --skip-build` - Skip building the image

---

### `motia cloud deploy`

Deploy to Motia Cloud.

```bash
motia cloud deploy -k YOUR_API_KEY -v v1.0.0
motia cloud deploy --api-key YOUR_API_KEY --version-name v1.2.0 --environment-name production
```

**Options:**
- `-k, --api-key <key>` - Motia Cloud API key (or set `MOTIA_API_KEY` env var)
- `-v, --version-name <version>` - Version name/tag for this deployment
- `-n, --project-name <name>` - Project name (for new projects)
- `-s, --environment-id <id>` - Environment ID
- `--environment-name <name>` - Environment name
- `-e, --env-file <path>` - Path to environment variables file
- `-d, --version-description <desc>` - Version description
- `-c, --ci` - CI mode (non-interactive)

---

## Common Patterns

### Emit Types

You can emit topics as strings or objects with labels.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
<Tab value='TypeScript'>

```typescript
// Simple emit
emits: ['user.created', 'email.sent']

// With labels and conditional flags
emits: [
  { topic: 'order.approved', label: 'Auto-approved' },
  { topic: 'order.rejected', label: 'Requires review', conditional: true }
]
```

</Tab>
<Tab value='JavaScript'>

```javascript
// Simple emit
emits: ['user.created', 'email.sent']

// With labels and conditional flags
emits: [
  { topic: 'order.approved', label: 'Auto-approved' },
  { topic: 'order.rejected', label: 'Requires review', conditional: true }
]
```

</Tab>
<Tab value='Python'>

```python
# Simple emit
"emits": ["user.created", "email.sent"]

# With labels and conditional flags
"emits": [
    {"topic": "order.approved", "label": "Auto-approved"},
    {"topic": "order.rejected", "label": "Requires review", "conditional": True}
]
```

</Tab>
</Tabs>

The `label` and `conditional` fields are for Workbench visualization only. They don't affect execution.

---

### Query Parameters

Document query params for Workbench.

```typescript
queryParams: [
  { name: 'page', description: 'Page number for pagination' },
  { name: 'limit', description: 'Number of items per page' },
  { name: 'sort', description: 'Sort field (e.g., createdAt, name)' }
]
```

This shows up in the Workbench endpoint tester.

---

### Include Files

Bundle files with your Step (useful for templates, assets, binaries).

```typescript
// Relative to the Step file
includeFiles: [
  './templates/email.html',
  './assets/*.png',
  '../../lib/stockfish'
]
```

Files are copied into the deployment bundle and accessible at runtime.

---

## Adapter Interfaces

Adapter interfaces define contracts for pluggable infrastructure components. Implement these interfaces to create custom adapters for state, streams, events, and cron.

<Callout type="info">
Adapter creation is only supported in TypeScript/JavaScript. Python steps can use adapters configured in `motia.config.ts`, but cannot create custom adapters.
</Callout>

### StateAdapter

Interface for state storage adapters.

```typescript
interface StateAdapter extends InternalStateManager {
  // From InternalStateManager
  get<T>(traceId: string, key: string): Promise<T | null>
  set<T>(traceId: string, key: string, value: T): Promise<T>
  delete<T>(traceId: string, key: string): Promise<T | null>
  getGroup<T>(traceId: string): Promise<T[]>
  clear(traceId: string): Promise<void>

  // Additional StateAdapter methods
  cleanup(): Promise<void>
  keys(traceId: string): Promise<string[]>
  traceIds(): Promise<string[]>
  items(input: StateItemsInput): Promise<StateItem[]>
}
```

### StreamAdapter

Abstract class for stream adapters.

```typescript
abstract class StreamAdapter<TData> {
  constructor(streamName: string)

  // Required methods
  abstract get(groupId: string, id: string): Promise<BaseStreamItem<TData> | null>
  abstract set(groupId: string, id: string, data: TData): Promise<BaseStreamItem<TData>>
  abstract delete(groupId: string, id: string): Promise<BaseStreamItem<TData> | null>
  abstract getGroup(groupId: string): Promise<BaseStreamItem<TData>[]>

  // Optional methods (with defaults)
  send(channel: StreamChannel, event: StreamEvent): Promise<void>
  subscribe(channel: StreamChannel, handler: StreamEventHandler): Promise<void>
  unsubscribe(channel: StreamChannel): Promise<void>
  clear(groupId: string): Promise<void>
  query(groupId: string, filter: StreamFilter): Promise<BaseStreamItem<TData>[]>
}
```

### EventAdapter

Interface for event handling adapters.

```typescript
interface EventAdapter {
  emit<TData>(event: Event<TData>): Promise<void>
  subscribe<TData>(
    topic: string,
    stepName: string,
    handler: (event: Event<TData>) => void | Promise<void>,
    options?: QueueConfig,
  ): Promise<SubscriptionHandle>
  unsubscribe(handle: SubscriptionHandle): Promise<void>
  shutdown(): Promise<void>
  getSubscriptionCount(topic: string): Promise<number>
  listTopics(): Promise<string[]>
}
```

### CronAdapter

Interface for cron job locking adapters.

```typescript
interface CronAdapter {
  acquireLock(jobName: string, ttl: number): Promise<CronLock | null>
  releaseLock(lock: CronLock): Promise<void>
  renewLock(lock: CronLock, ttl: number): Promise<boolean>
  isHealthy(): Promise<boolean>
  shutdown(): Promise<void>
  getActiveLocks(): Promise<CronLockInfo[]>
}
```

### Supporting Types

```typescript
interface Event<TData> {
  topic: string
  data: TData
  timestamp?: number
  traceId?: string
}

interface SubscriptionHandle {
  topic: string
  id: string
  unsubscribe: () => Promise<void>
}

interface CronLock {
  jobName: string
  lockId: string
  acquiredAt: number
  expiresAt: number
  instanceId: string
}

interface CronLockInfo {
  jobName: string
  instanceId: string
  acquiredAt: number
  expiresAt: number
}

interface StateItem {
  groupId: string
  key: string
  type: 'string' | 'number' | 'boolean' | 'object' | 'array' | 'null'
  value: unknown
}

interface StateItemsInput {
  groupId?: string
  traceId?: string
}
```

[Learn more about creating adapters â†’](/docs/development-guide/adapters/creating-adapters)

---

## What's Next?

<Cards>
  <Card href="/docs/concepts/steps" title="Steps">
    Learn how to build with Steps
  </Card>
  
  <Card href="/docs/development-guide/state-management" title="State Management">
    Deep dive into the State API
  </Card>
  
  <Card href="/docs/development-guide/streams" title="Streams">
    Real-time streaming guide
  </Card>

  <Card href="/docs/development-guide/middleware" title="Middleware">
    Request/response middleware patterns
  </Card>
  
  <Card href="/docs/examples" title="Examples">
    See these APIs in action
  </Card>
</Cards>


-   [community-resources](/docs/community-resources): Documentation for community-resources.
---
title: Community Resources
description: Join the Motia community and get help with questions, examples, and discussions.
---

# Community Resources

Welcome to the Motia community! Whether you're just getting started or building production applications, our community is here to help you succeed with Motia.

## ðŸ’¬ Get Help & Support

### Discord Community
**Best for: Real-time help, discussions, and community support**

<a
  href="https://discord.gg/motia"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M20.317 4.37a19.791 19.791 0 0 0-4.885-1.515.074.074 0 0 0-.079.037c-.21.375-.444.864-.608 1.25a18.27 18.27 0 0 0-5.487 0 12.64 12.64 0 0 0-.617-1.25.077.077 0 0 0-.079-.037A19.736 19.736 0 0 0 3.677 4.37a.07.07 0 0 0-.032.027C.533 9.046-.32 13.58.099 18.057a.082.082 0 0 0 .031.057 19.9 19.9 0 0 0 5.993 3.03.078.078 0 0 0 .084-.028c.462-.63.874-1.295 1.226-1.994a.076.076 0 0 0-.041-.106 13.107 13.107 0 0 1-1.872-.892.077.077 0 0 1-.008-.128 10.2 10.2 0 0 0 .372-.292.074.074 0 0 1 .077-.01c3.928 1.793 8.18 1.793 12.062 0a.074.074 0 0 1 .078.01c.12.098.246.198.373.292a.077.077 0 0 1-.006.127 12.299 12.299 0 0 1-1.873.892.077.077 0 0 0-.041.107c.36.698.772 1.362 1.225 1.993a.076.076 0 0 0 .084.028 19.839 19.839 0 0 0 6.002-3.03.077.077 0 0 0 .032-.054c.5-5.177-.838-9.674-3.549-13.66a.061.061 0 0 0-.031-.03zM8.02 15.33c-1.183 0-2.157-1.085-2.157-2.419 0-1.333.956-2.419 2.157-2.419 1.21 0 2.176 1.096 2.157 2.42 0 1.333-.956 2.418-2.157 2.418zm7.975 0c-1.183 0-2.157-1.085-2.157-2.419 0-1.333.955-2.419 2.157-2.419 1.21 0 2.176 1.096 2.157 2.42 0 1.333-.946 2.418-2.157 2.418z"/>
  </svg>
  Join Discord Community
</a>

Connect with the Motia team and fellow developers, ask questions, share ideas, and get real-time help from the community.

### GitHub Issues  
**Best for: Bug reports, feature requests, technical issues**

<a
  href="https://github.com/MotiaDev/motia/issues"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-gray-800 hover:bg-gray-900 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
  </svg>
  Report Issues on GitHub
</a>

Found a bug or have a feature request? Open an issue on our GitHub repository with detailed information about your environment and steps to reproduce.

## ðŸš€ Development & Contribution

### Main Repository
**The heart of Motia development**

<a
  href="https://github.com/MotiaDev/motia"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
  </svg>
  â­ Star on GitHub
</a>

Star our repository, contribute to the project, submit pull requests, and help shape the future of Motia.

### Examples Repository
**Learn from real-world implementations**

<a
  href="https://github.com/MotiaDev/motia-examples"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M9 12l2 2 4-4m5.618-4.016A11.955 11.955 0 0112 2.944a11.955 11.955 0 01-8.618 3.04A12.02 12.02 0 003 9c0 5.591 3.824 10.29 9 11.622 5.176-1.332 9-6.03 9-11.622 0-1.042-.133-2.052-.382-3.016z"/>
  </svg>
  Browse Examples
</a>

Explore complete implementations, step-by-step tutorials, and production-ready configurations. Perfect for learning and building your own applications.

### Roadmap
**See what's coming next**

<a
  href="https://github.com/orgs/MotiaDev/projects/2"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M9 5H7a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2V7a2 2 0 00-2-2h-2M9 5a2 2 0 002 2h2a2 2 0 002-2M9 5a2 2 0 012-2h2a2 2 0 012 2"/>
  </svg>
  View Roadmap
</a>

Check out our public roadmap to see upcoming features, improvements, and community requests.

## ðŸ“± Stay Connected

### Social Media
Follow us for the latest news, updates, and community highlights:

<div className="grid grid-cols-1 sm:grid-cols-2 gap-4 mb-6">
  <a
    href="https://x.com/motiadev"
    target="_blank"
    rel="noopener noreferrer"
    className="flex items-center gap-3 p-4 border border-gray-200 rounded-lg hover:border-gray-300 transition-colors duration-200"
  >
    <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
      <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/>
    </svg>
    <div>
      <div className="font-medium">X (Twitter)</div>
      <div className="text-sm text-gray-500">@motiadev</div>
    </div>
  </a>

  <a
    href="https://www.linkedin.com/company/motiadev"
    target="_blank"
    rel="noopener noreferrer"
    className="flex items-center gap-3 p-4 border border-gray-200 rounded-lg hover:border-gray-300 transition-colors duration-200"
  >
    <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
      <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
    </svg>
    <div>
      <div className="font-medium">LinkedIn</div>
      <div className="text-sm text-gray-500">Company Page</div>
    </div>
  </a>
</div>

### YouTube Channel
**Video tutorials, demos, and deep dives**

<a
  href="https://www.youtube.com/@motiadev"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-red-600 hover:bg-red-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/>
  </svg>
  Subscribe to YouTube
</a>

Watch video tutorials, live streams, and learn from the Motia team and community.

## ðŸŽ¯ Quick Links

### Documentation
- **[Getting Started](/docs/getting-started)** - Learn the basics of Motia
- **[API Endpoints Tutorial](/docs/getting-started/build-your-first-motia-app/api-endpoints)** - Hands-on REST API tutorial
- **[Examples](/docs/examples)** - Real-world use cases and implementations
- **[API Reference](/docs/concepts/steps)** - Complete API documentation

### Community Guidelines
- **[How to Contribute](/docs/contribution/how-to-contribute)** - Guidelines for contributing to Motia
- **Be respectful** - Treat everyone with kindness and respect
- **Help others** - Share your knowledge and help fellow developers
- **Stay on topic** - Keep discussions relevant to Motia and development

## ðŸ’ Ways to Support Motia

- â­ **Star our repository** on GitHub
- ðŸ¦ **Share on social media** - Help spread the word about Motia
- ðŸ“ **Write about your experience** - Blog posts, tutorials, case studies
- ðŸ› **Report bugs** - Help us improve by reporting issues
- ðŸ’¡ **Suggest features** - Share your ideas for new features
- ðŸ¤ **Contribute code** - Submit pull requests and improvements
- ðŸ“– **Improve documentation** - Help make our docs better

## ðŸ†˜ Getting Help

### Before Asking for Help
1. **Check the documentation** - Most questions are answered in our docs
2. **Search existing issues** - Your question might already be answered
3. **Try the examples** - See if our examples solve your problem

### When Asking for Help
- **Be specific** - Include code snippets, error messages, and steps to reproduce
- **Share your environment** - OS, Node.js version, Motia version
- **Explain your goal** - Help us understand what you're trying to achieve

### Response Times
- **Discord**: Real-time community support (fastest)
- **GitHub Issues**: Official team response within 1-3 business days
- **Social Media**: Community engagement and announcements

---

**Welcome to the Motia community!** ðŸŽ‰

We're excited to have you here and can't wait to see what amazing things you'll build with Motia. Whether you're just getting started or you're a seasoned developer, our community is here to support your journey.


-   [overview](/docs/concepts/overview): Documentation for overview.
---
title: Overview
description: Build production-grade backends with a single primitive - APIs, background jobs, workflows, and AI agents unified
---

**Build production-grade backends with a single primitive.**

Motia is a unified backend framework that combines APIs, background jobs, durable workflows, AI agents, streaming, and observability around one core primitive: **the Step**.

Want an API? That's a Step.  
Need a background job? That's a Step.  
Scheduled task? Also a Step.

Write each Step in whatever language makes sense - TypeScript, Python, or JavaScript. They all run together, share the same state, and talk through events.

## How It Works

Every Step is just a file with two parts:

**1. Config** â†’ When and how it runs  
**2. Handler** â†’ What it does

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="steps/my-step.step.ts"
import { ApiRouteConfig, Handlers } from 'motia'

// Config - when it runs
export const config: ApiRouteConfig = {
  name: 'MyStep',
  type: 'api',
  path: '/endpoint',
  method: 'POST',
  emits: ['task.done']
}

// Handler - what it does
export const handler: Handlers['MyStep'] = async (req, { emit, logger }) => {
  logger.info('Processing request')
  
  await emit({
    topic: 'task.done',
    data: { result: 'success' }
  })
  
  return { status: 200, body: { success: true } }
}
```

</Tab>
<Tab value='Python'>

```python title="steps/my_step.py"
# Config - when it runs
config = {
    "name": "MyStep",
    "type": "api",
    "path": "/endpoint",
    "method": "POST",
    "emits": ["task.done"]
}

# Handler - what it does
async def handler(req, context):
    context.logger.info("Processing request")
    
    await context.emit({
        "topic": "task.done",
        "data": {"result": "success"}
    })
    
    return {"status": 200, "body": {"success": True}}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="steps/my-step.step.js"
// Config - when it runs
const config = {
  name: 'MyStep',
  type: 'api',
  path: '/endpoint',
  method: 'POST',
  emits: ['task.done']
}

// Handler - what it does
const handler = async (req, { emit, logger }) => {
  logger.info('Processing request')
  
  await emit({
    topic: 'task.done',
    data: { result: 'success' }
  })
  
  return { status: 200, body: { success: true } }
}

module.exports = { config, handler }
```

</Tab>
</Tabs>

ðŸ‘‰ Drop this file in your `steps/` folder and Motia finds it automatically. No registration, no imports, no setup.

[Learn more about Steps â†’](/docs/concepts/steps)

---

## Event-Driven Architecture

Steps don't call each other. They **emit** and **subscribe** to events.

This means:
- Your API can trigger a background job without waiting for it
- Steps run independently and retry on failure
- You can add new Steps without touching existing ones
- Everything is traceable from start to finish

**Example:** An API emits an event, a background Step picks it up:

```typescript
// API Step emits
await emit({ topic: 'user.created', data: { email } })

// Event Step subscribes and processes
config = {
  type: 'event',
  subscribes: ['user.created']
}
```

That's it. No coupling, no dependencies.

---

## Project Structure & Auto-Discovery

Motia automatically discovers Steps - no manual registration required.

### Basic Structure

<Files>
<Folder name="my-project" defaultOpen>
  <Folder name="steps" defaultOpen>
    <Folder name="api">
      <File name="create-user.step.ts" />
      <File name="get-user.step.ts" />
    </Folder>
    <Folder name="events">
      <File name="send-email.step.ts" />
      <File name="process-data_step.py" />
    </Folder>
    <Folder name="cron">
      <File name="daily-report.step.ts" />
    </Folder>
    <Folder name="streams">
      <File name="notifications.stream.ts" />
    </Folder>
  </Folder>
  <File name="config.yml" />
  <File name=".env" />
  <File name="package.json" />
  <File name="requirements.txt" />
  <File name="tsconfig.json" />
</Folder>
</Files>

<Callout type="info">
The `steps/` directory is the heart of your Motia application. All your workflow logic lives here, and Motia automatically discovers any file following the naming pattern.
</Callout>

### Auto-Discovery Rules

Motia scans the `steps/` directory and automatically registers files that:

1. âœ… **Match naming pattern:**
   - TypeScript: `.step.ts`
   - JavaScript: `.step.js`
   - Python: `_step.py` (note: underscore before `step`)

2. âœ… **Export a `config` object** with Step configuration

3. âœ… **Export a `handler` function** with business logic

**No imports. No registration. Just create the file and Motia finds it.**

---

## Multi-Language Support

Every Step can be in a different language. They all run in the same process and share everything.

**Currently Supported:**
- **TypeScript** â†’ `.step.ts`
- **Python** â†’ `_step.py`
- **JavaScript** â†’ `.step.js`

**Coming Soon:**
- Ruby â†’ `.step.rb`
- C# â†’ `.step.cs`
- Go â†’ `.step.go`
- And many more...

**Example project:**

<Files>
<Folder name="my-app" defaultOpen>
  <Folder name="steps" defaultOpen>
    <File name="api-endpoint.step.ts" />
    <File name="ml-inference_step.py" />
    <File name="send-email.step.js" />
  </Folder>
</Folder>
</Files>

All three Steps work together. TypeScript API emits an event â†’ Python processes with ML â†’ JavaScript sends the result.

---

## Core Concepts

### State Management
Persistent key-value storage that works across all Steps and languages.

```typescript
await state.set('users', 'user-123', { name: 'John' })
const user = await state.get('users', 'user-123')
```

[Learn about State â†’](/docs/development-guide/state-management)

### Real-Time Streams
Push live updates to connected clients (browsers, mobile apps).

```typescript
await streams.notifications.set('user-123', 'notif-1', {
  message: 'Order shipped!',
  timestamp: new Date().toISOString()
})
```

Clients receive updates instantly.

[Learn about Streams â†’](/docs/development-guide/streams)

### Adapters
Pluggable infrastructure components that enable horizontal scaling and custom implementations. Swap default file-based storage with Redis, RabbitMQ, or your own implementations without changing your code.

[Learn about Adapters â†’](/docs/concepts/adapters)

### Context Object
Every handler gets a context object with everything you need:

| Property | What It Does |
|----------|--------------|
| `logger` | Structured logging |
| `emit` | Trigger other Steps |
| `state` | Persistent storage |
| `streams` | Real-time updates |
| `traceId` | Request tracing |

---

## Development Tool - Workbench

![create-pet](../img/build-your-first-app/create-api.png)

Visual interface for testing APIs, building and debugging flows:

- See your entire flow as a beautiful diagram
- Test API endpoints in the browser
- Watch logs in real-time
- Inspect state as it changes

[Learn about Workbench â†’](/docs/concepts/workbench)

---

## What's Next?

<Cards>
  <Card href="/docs/concepts/steps" title="ðŸ“¦ Steps">
    Deep dive into Steps - the only primitive you need
  </Card>
  
  <Card href="/docs/getting-started/quick-start" title="ðŸš€ Quick Start">
    Build your first app in 5 minutes
  </Card>
</Cards>

-   [steps](/docs/concepts/steps): Documentation for steps.
---
title: Steps
description: One primitive to build any backend. Simple, composable, and multi-language.
---

## One Primitive for Any Backend

A **Step** is the core primitive in Motia. Instead of juggling separate frameworks for APIs, background jobs, queues, or workflows, you define everything in one place:   **how it runs, when it runs, where it runs, and what it does.**

Every Step file contains two parts:

- **Config** â†’ defines when and how the Step runs, and gives it a unique `name`  
- **Handler** â†’ the function that executes your business logic  

Motia automatically discovers any file ending in `.step.ts`, `.step.js`, or `_step.py`.  
The filename tells Motia to load it, and the `name` in the `config` uniquely identifies the Step inside your system.

---

## The Simplest Example

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts title="steps/hello.step.ts"
import { ApiRouteConfig, Handlers } from 'motia';

export const config: ApiRouteConfig = {
  name: 'HelloStep',
  type: 'api',
  path: '/hello',
  method: 'GET'
};

export const handler: Handlers['HelloStep'] = async (req, { logger }) => {
  logger.info('Hello endpoint called');
  return { status: 200, body: { message: 'Hello world!' } };
};
```

</Tab>
<Tab value='Python'>

```python title="steps/hello_step.py"
config = {
    "name": "HelloStep",
    "type": "api",
    "path": "/hello",
    "method": "GET"
}

async def handler(req, ctx):
    ctx.logger.info("Hello endpoint called")
    return {"status": 200, "body": {"message": "Hello world!"}}
```

</Tab>
<Tab value='JavaScript'>

```js title="steps/hello.step.js"
const config = {
  name: 'HelloStep',
  type: 'api',
  path: '/hello',
  method: 'GET'
};

const handler = async (req, { logger }) => {
  logger.info('Hello endpoint called');
  return { status: 200, body: { message: 'Hello world!' } };
};

module.exports = { config, handler };
```

</Tab>
</Tabs>

ðŸ‘‰ Thatâ€™s all you need to make a running API endpoint.  
Motia will auto-discover this file and wire it into your backend.

---

## Steps Work Together: Emit + Subscribe

Steps arenâ€™t isolated. They communicate by **emitting** and **subscribing** to events.  
This is the core of how you build backends with Motia.

### Example Flow: API Step â†’ Event Step

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts title="steps/send-message.step.ts"
import { ApiRouteConfig, Handlers } from 'motia';

export const config: ApiRouteConfig = {
  name: 'SendMessage',
  type: 'api',
  path: '/messages',
  method: 'POST',
  emits: ['message.sent']
};

export const handler: Handlers['SendMessage'] = async (req, { emit }) => {
  await emit({
    topic: 'message.sent',
    data: { text: req.body.text }
  });
  return { status: 200, body: { ok: true } };
};
```

```ts title="steps/process-message.step.ts"
import { EventConfig, Handlers } from 'motia';

export const config: EventConfig = {
  name: 'ProcessMessage',
  type: 'event',
  subscribes: ['message.sent']
};

export const handler: Handlers['ProcessMessage'] = async (input, { logger }) => {
  logger.info('Processing message', input);
};
```
</Tab>

<Tab value='Python'>

```python title="send_message_step.py"
config = {
    "name": "SendMessage",
    "type": "api",
    "path": "/messages",
    "method": "POST",
    "emits": ["message.sent"]
}

async def handler(req, ctx):
    await ctx.emit({
        "topic": "message.sent",
        "data": {"text": req.body["text"]}
    })
    return {"status": 200, "body": {"ok": True}}
```

```python title="process_message_step.py"
config = {
    "name": "ProcessMessage",
    "type": "event",
    "subscribes": ["message.sent"]
}

async def handler(input, ctx):
    ctx.logger.info("Processing message", input)
```
</Tab>

<Tab value='JavaScript'>

```js title="steps/send-message.step.js"
const config = {
  name: 'SendMessage',
  type: 'api',
  path: '/messages',
  method: 'POST',
  emits: ['message.sent']
};

const handler = async (req, { emit }) => {
  await emit({
    topic: 'message.sent',
    data: { text: req.body.text }
  });
  return { status: 200, body: { ok: true } };
};

module.exports = { config, handler };
```

```js title="steps/process-message.step.js"
const config = {
  name: 'ProcessMessage',
  type: 'event',
  subscribes: ['message.sent']
};

const handler = async (input, { logger }) => {
  logger.info('Processing message', input);
};

module.exports = { config, handler };
```
</Tab>
</Tabs>

ðŸ‘‰ With just two files, you have an **API endpoint** that triggers an **event-driven workflow**.  

---

## Triggers

<div id="triggers-api"></div>
<div id="triggers-event"></div>
<div id="triggers-cron"></div>

Every Step has a `type` that defines **how it triggers**:

| Type | When it runs | Use case |
|------|--------------|----------|
| `api` | HTTP request | REST APIs, webhooks |
| `event` | Event emitted | Background jobs, workflows |
| `cron` | Schedule | Cleanup, reports, reminders |

<Tabs items={['API', 'Event', 'Cron']} groupId="triggers" updateAnchor defaultIndex={0}>
  <Tab id="triggers-api" value="API">

### API Trigger

Runs when an HTTP request hits the path.

**Example:**

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    import { ApiRouteConfig, Handlers } from 'motia'

    export const config: ApiRouteConfig = {
      name: 'GetUser',
      type: 'api',
      path: '/users/:id',
      method: 'GET'
    }

    export const handler: Handlers['GetUser'] = async (req, { logger }) => {
      const userId = req.pathParams.id
      logger.info('Getting user', { userId })
      return { status: 200, body: { id: userId, name: 'John' } }
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    const config = {
      name: 'GetUser',
      type: 'api',
      path: '/users/:id',
      method: 'GET'
    }

    const handler = async (req, { logger }) => {
      const userId = req.pathParams.id
      logger.info('Getting user', { userId })
      return { status: 200, body: { id: userId, name: 'John' } }
    }

    module.exports = { config, handler }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    config = {
        "name": "GetUser",
        "type": "api",
        "path": "/users/:id",
        "method": "GET"
    }

    async def handler(req, ctx):
        user_id = req.get("pathParams", {}).get("id")
        ctx.logger.info("Getting user", {"userId": user_id})
        return {"status": 200, "body": {"id": user_id, "name": "John"}}
    ```
  </Tab>
</Tabs>

**Config:**

| Property | Description |
|----------|-------------|
| `name` | Unique identifier |
| `type` | Set to `'api'` |
| `path` | URL path (supports `:params`) |
| `method` | GET, POST, PUT, DELETE |
| `bodySchema` | Validate request body |

**Handler:** `handler(req, ctx)`

- `req` - Request with `body`, `headers`, `pathParams`, `queryParams`
- `ctx` - Context with `logger`, `emit`, `state`, `streams`, `traceId`
- Returns `{ status, body, headers? }`

</Tab>

  <Tab id="triggers-event" value="Event">

### Event Trigger

Runs when an event is emitted. Use for background tasks.

**Example:**

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    import { EventConfig, Handlers } from 'motia'

    export const config: EventConfig = {
      name: 'ProcessMessage',
      type: 'event',
      subscribes: ['message.sent'],
      emits: ['message.processed']
    }

    export const handler: Handlers['ProcessMessage'] = async (input, { logger, emit }) => {
      logger.info('Processing message:', input)
      await emit({ topic: 'message.processed', data: input })
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    const config = {
      name: 'ProcessMessage',
      type: 'event',
      subscribes: ['message.sent'],
      emits: ['message.processed']
    }

    const handler = async (input, { logger, emit }) => {
      logger.info('Processing message:', input)
      await emit({ topic: 'message.processed', data: input })
    }

    module.exports = { config, handler }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    config = {
        "name": "ProcessMessage",
        "type": "event",
        "subscribes": ["message.sent"],
        "emits": ["message.processed"]
    }

    async def handler(input, ctx):
        ctx.logger.info("Processing message:", {"input": input})
        await ctx.emit({"topic": "message.processed", "data": input})
    ```
  </Tab>
</Tabs>

**Config:**

| Property | Description |
|----------|-------------|
| `name` | Unique identifier |
| `type` | Set to `'event'` |
| `subscribes` | Event topics to listen to |
| `emits` | Event topics to emit |
| `input` | Validate input data |

**Handler:** `handler(input, ctx)`

- `input` - Data from the emitted event
- `ctx` - Context with `logger`, `emit`, `state`, `streams`, `traceId`

</Tab>

  <Tab id="triggers-cron" value="Cron">

### Cron Trigger

Runs on a schedule. Use for periodic tasks.

**Example:**

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    import { CronConfig, Handlers } from 'motia'

    export const config: CronConfig = {
      name: 'DailyCleanup',
      type: 'cron',
      cron: '0 0 * * *'
    }

    export const handler: Handlers['DailyCleanup'] = async ({ logger }) => {
      logger.info('Running daily cleanup')
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    const config = {
      name: 'DailyCleanup',
      type: 'cron',
      cron: '0 0 * * *'
    }

    const handler = async ({ logger }) => {
      logger.info('Running daily cleanup')
    }

    module.exports = { config, handler }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    config = {
        "name": "DailyCleanup",
        "type": "cron",
        "cron": "0 0 * * *"
    }
  
    async def handler(ctx):
        ctx.logger.info("Running daily cleanup")
    ```
  </Tab>
</Tabs>

**Config:**

| Property | Description |
|----------|-------------|
| `name` | Unique identifier |
| `type` | Set to `'cron'` |
| `cron` | Cron expression |

**Handler:** `handler(ctx)`

- `ctx` - Context with `logger`, `emit`, `state`, `streams`, `traceId`

**Common schedules:**

| Expression | Runs |
|------------|------|
| `* * * * *` | Every minute |
| `0 * * * *` | Every hour |
| `0 0 * * *` | Daily at midnight |
| `0 9 * * 1` | Monday at 9 AM |

ðŸ‘‰ Use [crontab.guru](https://crontab.guru) to build expressions.

</Tab>
</Tabs>

---

## Context Object

Every handler receives a `ctx` object with these tools:

| Property | Description |
|----------|-------------|
| `logger` | Structured logging (`info`, `warn`, `error`) |
| `emit` | Trigger other Steps by emitting events |
| `state` | Persistent key-value storage |
| `streams` | Real-time data channels for clients |
| `traceId` | Unique ID for tracing requests & workflows |

---

## Core Functionality

### State â€“ Persistent Data

Key-value storage shared across Steps and workflows.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts
await state.set(traceId, 'preferences', { theme: 'dark' });
const prefs = await state.get(traceId, 'preferences');
```

</Tab>
<Tab value='Python'>

```python
await context.state.set(context.trace_id, "preferences", {"theme": "dark"})
prefs = await context.state.get(context.trace_id, "preferences")
```

</Tab>
<Tab value='JavaScript'>

```js
await state.set(traceId, 'preferences', { theme: 'dark' });
const prefs = await state.get(traceId, 'preferences');
```

</Tab>
</Tabs>

ðŸ‘‰ [Learn more about State Management â†’](/docs/development-guide/state-management)

### Logging â€“ Structured & Contextual

For debugging, monitoring, and observability.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts
logger.info('Processing user', { userId: '123' });
```

</Tab>
<Tab value='Python'>

```python
context.logger.info("Processing user", {"userId": "123"})
```

</Tab>
<Tab value='JavaScript'>

```js
logger.info('Processing user', { userId: '123' });
```

</Tab>
</Tabs>

ðŸ‘‰ [Learn more about Observability â†’](/docs/development-guide/observability)

### Streams â€“ Real-Time Data

Push updates directly to connected clients.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts
await streams.chat.set('room-123', 'msg-456', { text: 'Hello!' });
```

</Tab>
<Tab value='Python'>

```python
await context.streams.chat.set("room-123", "msg-456", {"text": "Hello!"})
```

</Tab>
<Tab value='JavaScript'>

```js
await streams.chat.set('room-123', 'msg-456', { text: 'Hello!' });
```

</Tab>
</Tabs>

ðŸ‘‰ [Learn more about Streams â†’](/docs/development-guide/streams)

### Flows â€“ Visualize in Workbench

Group Steps together for diagram visualization in Workbench.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts
export const config: ApiRouteConfig = {
  name: 'CreateOrder',
  type: 'api',
  path: '/orders',
  method: 'POST',
  flows: ['order-management']
};
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "CreateOrder",
    "type": "api",
    "path": "/orders",
    "method": "POST",
    "flows": ["order-management"]
}
```

</Tab>
<Tab value='JavaScript'>

```js
const config = {
  name: 'CreateOrder',
  type: 'api',
  path: '/orders',
  method: 'POST',
  flows: ['order-management']
};
```

</Tab>
</Tabs>

ðŸ‘‰ [Learn more about Flows â†’](/docs/development-guide/flows)

### Infrastructure â€“ Configure Event Steps

Customize timeout and retry behavior for Event Steps.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts
export const config: EventConfig = {
  name: 'SendEmail',
  type: 'event',
  subscribes: ['email.requested'],
  infrastructure: {
    handler: { timeout: 10 },
    queue: { maxRetries: 5, visibilityTimeout: 60 }
  }
};
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "SendEmail",
    "type": "event",
    "subscribes": ["email.requested"],
    "infrastructure": {
        "handler": {"timeout": 10},
        "queue": {"maxRetries": 5, "visibilityTimeout": 60}
    }
}
```

</Tab>
<Tab value='JavaScript'>

```js
const config = {
  name: 'SendEmail',
  type: 'event',
  subscribes: ['email.requested'],
  infrastructure: {
    handler: { timeout: 10 },
    queue: { maxRetries: 5, visibilityTimeout: 60 }
  }
};
```

</Tab>
</Tabs>

ðŸ‘‰ [Learn more about Infrastructure â†’](/docs/development-guide/infrastructure)

---

## Remember

- **Steps are just files.** Export a `config` and `handler`.  
- Motia auto-discovers and connects them.  
- Combine Steps with **emit + subscribe** to build APIs, workflows, background jobs, or entire systems.  

---

## What's Next?

ðŸ‘‰ [Build your first app â†’](/docs/getting-started/build-your-first-motia-app)


-   [workbench](/docs/concepts/workbench): Documentation for workbench.
---
title: Workbench
description: Your visual dev environment for building, testing, and debugging Motia apps
---

Workbench is where you'll spend most of your time building with Motia. Think of it as your mission control: you can see your entire backend as a visual diagram, test APIs instantly, watch logs stream in real-time, and trace exactly what happens during each request.

![Workbench Overview](./../img/motia-build-your-app.gif)

---

## Getting Started

Fire up the Workbench:

<Tabs items={['npm', 'yarn', 'pnpm', 'bun']}>
  <Tab value="pnpm">
  ```bash
  pnpm run dev
  ```
  </Tab>
  <Tab value="yarn">
  ```bash
  yarn dev
  ```
  </Tab>
  <Tab value="npm">
  ```bash
  npm run dev
  ```
  </Tab>
  <Tab value="bun">
  ```bash
  bun run dev
  ```
  </Tab>
</Tabs>

This starts two things:
- Your backend server (with all your Steps running)
- The Workbench interface at `http://localhost:3000`

Changes to your Steps reload automatically. No restart needed.

---

## Two Views: Flows & Endpoints

### Flow View â€“ See Your Backend as a Diagram

The flow view shows your entire backend as an interactive graph. Every Step becomes a node, and the connections between them show how data flows through your system.

![Flow Visualization](../img/build-your-first-app/streaming-workbench.png)

**What you see:**
- **API endpoints** (green nodes with a link icon) - entry points to your backend
- **Event Steps** (blue nodes) - background jobs that run when events are emitted
- **Cron Steps** (orange nodes) - scheduled tasks that run on a timer
- **Connections** (dotted lines) - show which Steps trigger which other Steps

Hover over any node to see what it does. Click the settings icon to jump to that Step's code.

This view is perfect for understanding how your backend works at a glance, or for showing your flow to teammates.

**Want to customize how your Steps look?** You can create custom UI components for any Step. Add icons, change colors, or build completely custom node designs. Perfect for making flows more intuitive or sharing with non-technical teammates.

ðŸ‘‰ [Learn about Steps â†’](/docs/concepts/steps)
ðŸ‘‰ [Customize your flow visualization â†’](/docs/development-guide/customizing-flows)

---

### Endpoint View â€“ Test Your APIs

Switch to the Endpoint view to test your API endpoints without leaving the browser. No Postman, no curl. Just point, click, and send.

![Endpoint Testing](../img/build-your-first-app/post-pet.png)

**Left sidebar:** All your API endpoints, organized by language. If you have Steps in TypeScript, JavaScript, and Python, they'll be grouped automatically (like `TsPetManagement`, `JsPetManagement`, `PyPetManagement`). Search by method or path.

**Center panel:** Your testing interface with three tabs:

- **Params** - Fill in path params (like `:id`) and query params. You get a live URL preview too.
- **Body** - Write your JSON request body with syntax highlighting
- **Headers** - Add custom headers if you need them

Hit the play button and you'll instantly see:
- Status code (200, 201, 404, etc.)
- Response time
- Full response body

![Path Params](../img/build-your-first-app/get-pet-by-id.png)

**Params tab** makes it easy to fill in path parameters. If your endpoint is `GET /pets/:id`, you'll see an input for `id`. Fill it in, and the URL preview updates automatically.

#### Testing Streaming Endpoints

When you test an endpoint that uses streams, the response panel updates in real-time as data arrives. Perfect for testing AI agents, progress updates, or any real-time data flow.

![Streaming Response](../img/build-your-first-app/streams-healthy-output.png)

You'll see each chunk of data appear as it's streamed from your backend. The Logs Details panel on the right shows the full context of what was streamed.

ðŸ‘‰ [Learn more about Streams â†’](/docs/development-guide/streams)

---

## Debug Panel â€“ Tracing, Logs & State

At the bottom of the screen, you'll find three tabs that help you understand what's happening inside your backend.

### Tracing â€“ See Execution Timeline

![Tracing Timeline](../img/build-your-first-app/post-pet.png)

Every request gets a unique trace ID. The tracing panel shows you a visual timeline of every Step that ran, how long each one took, and in what order they executed.

**What you see:**
- Each Step as a horizontal bar
- How long it took (in milliseconds)
- When it started relative to the request
- The full execution chain from start to finish

Click any trace to see the full details in the right panel, including which events were emitted and which Steps they triggered.

This is a lifesaver when debugging workflows. You can instantly see if a Step is slow, or if something isn't triggering when it should.

ðŸ‘‰ [Learn more about Observability â†’](/docs/development-guide/observability)

---

### Logs â€“ Real-Time Feed

![Logs View](../img/build-your-first-app/bg-job-logs.png)

The Logs tab shows every `logger.info()`, `logger.warn()`, and `logger.error()` call from your Steps, in real-time.

**Features:**
- **Timestamped** - know exactly when each log happened
- **Step name** - see which Step produced each log
- **Contextual** - click any log to see the full details (step name, trace ID, custom properties)

![Log Filtering](../img/build-your-first-app/todo-state-filter.png)

**Filtering logs:** Type a trace ID in the search box to see only logs from that specific request. This is incredibly useful when debugging a workflow. You can follow the entire execution path of a single request through all your Steps.

The right panel shows detailed information about the selected log, including custom properties you've passed to `logger.info()`.

ðŸ‘‰ [Learn more about Observability â†’](/docs/development-guide/observability)

---

### States â€“ Inspect & Edit Data

The States tab shows you everything stored with `state.set()`. This is your window into the persistent data your workflows are using.

![States View](../img/build-your-first-app/todo-states.png)

**What you see:**
- **Group ID** - typically the trace ID or workflow identifier
- **Key** - the state key name
- **Type** - data type (object, string, number, etc.)

**Search and filter:** Use the search bar to find specific state keys or group IDs. When you have hundreds of state entries, this makes finding what you need instant.

Click any state entry to see its full value in the right panel.

#### State Details Panel

![State Overview](../img/build-your-first-app/todo-states.png)

The **Overview** tab shows the full JSON value of the state entry with syntax highlighting. Perfect for quickly inspecting what data is stored.

![State Editor](../img/build-your-first-app/todo-states-editor.png)

The **Editor** tab lets you modify state values directly in the Workbench. Edit the JSON, hit **Save Changes**, and your update is persisted immediately. This is super handy for:
- Testing how your workflow behaves with different data
- Fixing corrupted state during development
- Manually updating values without writing code

You can also **Delete** state entries using the button in the toolbar.

ðŸ‘‰ [Learn more about State Management â†’](/docs/development-guide/state-management)

---

## Trace Details Panel

When you click a trace or a log, a panel slides in from the right showing the full context:

![Trace Details](../img/build-your-first-app/post-pet.png)

- **Duration** - how long the entire request took
- **Step-by-step breakdown** - every Step that ran, with timestamps and status indicators
- **Events emitted** - see exactly which events were triggered and when

This panel is your go-to for understanding "what happened during this request?"

---

## Header

At the top of the Workbench:

- **Theme toggle** (sun/moon icon) - switch between light and dark mode
- **Tutorial** - opens the interactive tutorial (if your project has one)
- **Deploy** - quick link to deploy your app to Motia Cloud

---

## Hot Reload

Change a Step file, hit save, and the Workbench refreshes automatically. No need to restart the server or reload the page. This makes for an incredibly fast feedback loop.

---

## Customizing Your Flow Visualization

The default Step visualization is great for developers, but sometimes you want something more polished. Maybe you're:
- Sharing flows with product managers who don't need to see code
- Building a demo and want branded, beautiful diagrams
- Creating visual documentation for your team

You can override how any Step looks by creating a `.tsx` or `.jsx` file next to your Step file. Use built-in components like `EventNode`, `ApiNode`, and `CronNode`, or build completely custom React components from scratch.

**What you can do:**
- Add custom icons and images to Steps
- Change colors and styling to match your brand
- Display additional context right in the node
- Create NOOP Steps to represent external systems or manual processes
- Hide code complexity and show clean, intuitive cards

ðŸ‘‰ [Full guide to customizing flows â†’](/docs/development-guide/customizing-flows)

## Remember

Workbench isn't just a UI. It's a development tool designed to make building backends faster and less painful. Use it to:

- **Visualize** your flows to understand how your backend fits together
- **Test** APIs without switching to another tool
- **Debug** with tracing and logs to see exactly what's happening
- **Iterate** quickly with hot reload

---

## What's Next?

ðŸ‘‰ [Build your first app â†’](/docs/getting-started/build-your-first-motia-app)  
ðŸ‘‰ [Learn about State â†’](/docs/development-guide/state-management)  
ðŸ‘‰ [Learn about Streams â†’](/docs/development-guide/streams)


-   [contribution](/docs/contribution): Documentation for contribution.
---
title: How to Contribute
description: Guide for developers who want to contribute to Motia
---

# How to Contribute

Thank you for your interest in contributing to Motia! We welcome contributions from the community to help make Motia better. Here are some ways you can contribute:

## Reporting Issues

If you encounter any bugs, have feature requests, or want to discuss improvements, please [open an issue](https://github.com/MotiaDev/motia/issues) on our GitHub repository. When reporting bugs, please provide detailed information about your environment and steps to reproduce the issue.

## Submitting Pull Requests

We appreciate pull requests for bug fixes, enhancements, or new features. To submit a pull request:

1. Fork the [Motia repository](https://github.com/MotiaDev/motia) on GitHub.
2. Create a new branch from the `main` branch for your changes.
3. Make your modifications and ensure that the code follows our coding conventions.
4. Write tests to cover your changes, if applicable.
5. Commit your changes and push them to your forked repository.
6. Open a pull request against the `main` branch of the Motia repository.

Please provide a clear description of your changes in the pull request, along with any relevant information or context.

## Documentation Improvements

Improving the documentation is a great way to contribute to Motia. If you find any errors, typos, or areas that need clarification, please submit a pull request with the necessary changes. The documentation source files are located in the `packages/docs/content` directory.

## Sharing Examples and Use Cases

If you have built something interesting with Motia or have a real-world use case to share, we would love to showcase it in our [Examples](/docs/examples) section. You can contribute your examples by submitting a pull request to the [Motia Examples repository](https://github.com/MotiaDev/motia-examples).

## Spreading the Word

Help spread the word about Motia by sharing it with your friends, colleagues, and the developer community. You can also star our [GitHub repository](https://github.com/MotiaDev/motia), follow us on [Twitter](https://twitter.com/motiadev), and join our [Discord community](https://discord.gg/EnfDRFYW) to stay updated with the latest news and engage with other Motia developers.

We appreciate all forms of contributions and look forward to collaborating with you to make Motia even better! 

-   [getting-started](/docs/deployment-guide/getting-started): Documentation for getting-started.
---
title: Getting Started
description: Learn how to deploy your Motia project to production
full: true
---

When you're ready to deploy your Motia project to production, there are the two paths you can take:

<Cards>
  <Card href="/docs/deployment-guide/motia-cloud/features" title="Deploy with Motia">
    Deploy your Motia project to production using Motia.
  </Card>
  <Card href="/docs/deployment-guide/self-hosted " title="Self-Hosted">
    Deploy your Motia project to production using motia-docker.
  </Card>
</Cards>

<br />


-   [architecture](/docs/deployment-guide/motia-cloud/architecture): Documentation for architecture.
---
title: Architecture
description: Motia Cloud is a serverless platform. Some stuff that work locally may not work in the cloud.
---

### Bundle sizes

Motia Cloud currently has limited bundle sizes to 100MB, we're actively working on increasing this limit
to be higher than 1GB.

### Payload size on events

When sending events to topics, the data should not have more than 4KB.

1. Make sure you're not sending files as Base64 in the content of the event.
2. Make sure payloads you send are not too large, prefer storing in state and fetch it on the other steps.

### Using Local Files

Sometimes we need toa use local files when creating our backend logic. For example, creating templates.
Running binary files, etc. To do this, we can add them to steps as static files.

Make sure you follow the instructions in [Deployments page](/docs/concepts/deployment/motia-cloud/deployment#adding-static-files-to-the-bundle).

### Runtime timeouts

Motia Cloud currently has limited runtime timeouts:

- 15 minutes for Event and Cron Steps.
- 30 seconds for API Steps.

### Reserved environment variables

Motia Cloud is currently deployed to Amazon Web Services. Which means that there are 
some environment variables that are reserved for internal use. If you need to use one 
of these variables, make sure to add a different name.

```bash
_HANDLER
_X_AMZN_TRACE_ID
AWS_DEFAULT_REGION
AWS_REGION
AWS_EXECUTION_ENV
AWS_LAMBDA_FUNCTION_NAME
AWS_LAMBDA_FUNCTION_MEMORY_SIZE
AWS_LAMBDA_FUNCTION_VERSION
AWS_LAMBDA_INITIALIZATION_TYPE
AWS_LAMBDA_LOG_GROUP_NAME
AWS_LAMBDA_LOG_STREAM_NAME
AWS_ACCESS_KEY
AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY
AWS_SESSION_TOKEN
AWS_LAMBDA_RUNTIME_API
LAMBDA_TASK_ROOT
LAMBDA_RUNTIME_DIR
```

### Limitations

- 100MB bundle size
- 4KB payload size on events
- 15 minutes runtime timeout for Event and Cron Steps
- 30 seconds runtime timeout for API Steps

## Troubleshooting build outputs

Make sure you follow the instructions in [Deployments page](/docs/concepts/deployment/motia-cloud/deployment#adding-static-files-to-the-bundle).


-   [continuous-deployment](/docs/deployment-guide/motia-cloud/continuous-deployment): Documentation for continuous-deployment.
---
title: Continuous Deployment
description: Move faster with continuous deployment
---

This guide helps creating a continuous deployment pipeline for your Motia project.

## Before you start

Before you create your pipeline, you first need to have deployed your project to Motia Cloud.
Check the [Deployment](/docs/concepts/deployment/motia-cloud/deployment) page for more information.

## Adding the Environment ID

After you have deployed your project to Motia Cloud, you need to add the environment ID to your pipeline.
You can find the environment ID in the Motia Cloud web interface by navigating to the Environment page and
clicking on the Settings tab.

## Creating an API Key

When you open Motia Cloud, you should see API Keys tab. Click on the Create API Key button to create a new API Key.
Copy the API Key and add it to your project [as a secret](https://docs.github.com/en/actions/how-tos/write-workflows/choose-what-workflows-do/use-secrets).
Do NOT paste the API Key content to your workflow file.

## Populating Environment Variables

Add all environment variables you need on your project to [repository secrets](https://docs.github.com/en/actions/how-tos/write-workflows/choose-what-workflows-do/use-secrets),
then make sure to update `Create Env file` section in the workflow file.

## Using GitHub Actions

You can use GitHub Actions to deploy your Motia project to Motia Cloud.

```yaml
name: Deploy

on:
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      versionName:
        description: 'Version Name to deploy'
        required: true
      versionDescription:
        description: 'Version Description to deploy'
        required: true

env:
  # Add your API Key as a Secret in your Repository (Do NOT add it here)
  # https://docs.github.com/en/actions/how-tos/write-workflows/choose-what-workflows-do/use-secrets
  MOTIA_API_KEY: ${{ secrets.MOTIA_API_KEY }}
  # Fill your environment ID here
  MOTIA_ENV_ID: __FILL YOUR ENVIRONMENT ID HERE__

jobs:
  deploy:
    name: Deploy
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.release.tag_name || github.ref }}

      - name: Set VERSION_NAME and DESCRIPTION
        id: meta
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "VERSION_NAME=${{ github.event.inputs.versionName }}" >> $GITHUB_ENV
            echo "VERSION_DESCRIPTION=${{ github.event.inputs.versionDescription }}" >> $GITHUB_ENV
          else
            echo "VERSION_NAME=${GITHUB_SHA::7}" >> $GITHUB_ENV
            echo "VERSION_DESCRIPTION=${{ github.event.head_commit.message }}" >> $GITHUB_ENV
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'
          cache-dependency-path: 'package-lock.json'

      - name: Install dependencies
        run: npm ci

      # Replace MY_SECRET with your secret
      # Add as many as you need
      # https://docs.github.com/en/actions/how-tos/write-workflows/choose-what-workflows-do/use-secrets
      - name: Create Env file
        run: |
          echo "MY_SECRET=${{ secrets.MY_SECRET }}" > .env

      - name: Deploy using Motia Cloud
        run: |
          npx motia cloud deploy \
            --api-key ${{ env.MOTIA_API_KEY }} \
            --environment-id ${{ env.MOTIA_ENV_ID }} \
            --version-name "${{ env.VERSION_NAME }}" \
            --version-description "${{ env.VERSION_DESCRIPTION }}" \
            --env-file .env
```

-   [deployment](/docs/deployment-guide/motia-cloud/deployment): Documentation for deployment.
---
title: Deployment
description: Deploying your project to Motia Cloud
---

There are two ways to deploy your project to Motia Cloud:

1. Using the CLI
2. Using the Web interface

## Using the Motia CLI for Deployment

```bash
motia cloud deploy --api-key <api-key> --version-name <version> [options]
```

#### Required Options

| Option          | Alias | Description                    | Environment Variable |
| --------------- | ----- | ------------------------------ | -------------------- |
| `--api-key`     | `-k`  | API key for authentication     | `MOTIA_API_KEY`      |
| `--version-name`| `-v`  | Version tag for the deployment | None                 |

#### Optional Options

| Option                 | Alias | Description                                                        | Environment Variable     |
| ---------------------- | ----- | ------------------------------------------------------------------ | ------------------------ |
| `--environment-id`     | `-s`  | Environment ID                                                     | `MOTIA_ENVIRONMENT_ID`   |
| `--version-description`| `-d`  | Version description for the deployment                             | None                     |
| `--env-file`           | `-e`  | Path to environment file                                           | None                     |

> **Note:** Command-line options take precedence over environment variables. If both are provided, the command-line value will be used.

Deploy with a specific version:

```bash
motia cloud deploy --api-key your-api-key-here --version-name 1.2.3
```

Deploy to a specific environment with environment variables:

```bash
motia cloud deploy --api-key your-api-key-here \
  --version-name 1.2.3 \
  --env-file .env.production \
  --environment-id env-id
```

## Using Web interface

Through the web interface, you can deploy your project from workbench to a live environment with one click.

![One Click Deployment](../../img/cloud/one-click-deploy.gif)

Steps to deploy from web interface:

1. Have your local project running (make sure your Motia version is 0.6.4 or higher)
2. Go to import from workbench on Motia Cloud
3. Select the port your local project is running on
4. Choose the project and environment name
5. Add any environment variables you need (you can upload from .env file or paste the content to auto-fill)
6. Click Deploy
7. Watch the magic happen


## Adding static files to the bundle

Sometimes we need to use local files when creating our backend logic. For example, creating templates.
Running binary files, etc. To do this, we can add them to steps as static files.

Adding them to Steps as static files, you need to add `includeFiles` to the step config. The path
 should be relative to the step file.

```typescript
import { EventConfig } from 'motia'

export const config: EventConfig = {
  name: 'Content Outliner',
  description: 'Creates detailed content outline based on the initial idea',
  type: 'event',
  emits: [{ topic: 'write-content', label: 'Write first content' }],
  virtualEmits: ['virtual-write-content'],
  flows: ['Content'],
  subscribes: ['build-outline'],
  input,
  includeFiles: ['./content-outliner.mustache'], // relative to the step file
}
```

### Adding binary files to the bundle

Binary files are also supported, but the entire bundle size must not exceed 100MB.
The binary architecture should be linux_amd64.

## Troubleshooting Build Outputs

When adding static files, it's important to check the build output to make sure the files are included.

For example, in [this project](https://github.com/MotiaDev/motia-agent-content), there are a few steps that
include static files.

When running `npx motia build`, it will generate the following output in `dist` folder:

```
dist/
â””â”€â”€ node/steps/content/
    â”œâ”€â”€ agents
    â”‚   â”œâ”€â”€ content-outliner.step.zip
    â”‚   â”œâ”€â”€ content-writer.step.zip
    â”‚   â””â”€â”€ ideator.step.zip
    â”œâ”€â”€ api
    â”‚   â”œâ”€â”€ generate-content-api.step.zip
    â”‚   â””â”€â”€ get-content.step.zip
    â”œâ”€â”€ motia.steps.json
    â””â”€â”€ router-node.zip
```

If you check the content of `content-outliner.step.zip`, it should have this

```
steps/
â””â”€â”€ content/
    â””â”€â”€ agents/
        â”œâ”€â”€ content-outliner.mustache
        â”œâ”€â”€ content-outliner.step.js
        â””â”€â”€ content-outliner.step.js.map
```

Now you made sure the static file called `content-outliner.mustache` is included in the bundle.

-   [faq](/docs/deployment-guide/motia-cloud/faq): Documentation for faq.
---
title: FAQ
description: Frequently asked questions about Motia Cloud
---

## Can I deploy any Motia app to Motia Cloud?

Node.JS projects are fully supported. Python projects are supported as well but there are a few external libraries that are not currently supported, such as:

- TensorFlow
- Pytorch

These are not supported due to the limited bundle size of 100MB.

Be mindful that static or binary files added to the bundle must not exceed 100MB.

## What happens when I deploy my project to Motia Cloud?

When you deploy for the first time, it's immediately available. But when you deploy 
for the second time and beyond, the deployment is listed but needs to be manually promoted to be live.

Promoting a deployment is a really simple process and happens immediately after you click.
Check the [Promote](/docs/concepts/deployment/motia-cloud/features#instant-rollbacks-and-roll-ups-updates) page for more information.

## I deployed a new version but it didn't update

It's because Motia Cloud doesn't automatically promote the new version to be live. You need to promote it manually.
Check the [Promote](/docs/concepts/deployment/motia-cloud/features#instant-rollbacks-and-roll-ups-updates) page for more information.

## How do I deploy my project to Motia Cloud?

You can deploy your project to Motia Cloud by using the Motia CLI or through the web interface.
Check the [Deployment](/docs/concepts/deployment/motia-cloud/deployment) page for more information.

## How do I rollback to a previous deployment?

You can rollback to a previous deployment by clicking the rollback button in the Motia Cloud web interface.
Check the [Promote](/docs/concepts/deployment/motia-cloud/features#instant-rollbacks-and-roll-ups-updates) page for more information.

## How do I promote a deployment to be live?

You can promote a deployment to be live by clicking the promote button in the Motia Cloud web interface.
Check the [Promote](/docs/concepts/deployment/motia-cloud/features#instant-rollbacks-and-roll-ups-updates) page for more information.

## How do I delete a deployment?

You can delete a deployment by clicking the delete button in the Motia Cloud web interface.

## How do I update environment variables?

Currently, the only way to update environment variables is by creating a new deployment.
The reason is that every deployment is an atomic deployment and Environment Variables can also be source of
issues.

This was a decision to make sure that deployments are always predictable and consistent. And rollbacks 
can be done with confidence. If an environment variable updated caused an issue, you can quickly rollback to 
a previous deployment.

## How do I add static or binary files to my project?

You can add static files to your project by adding them to the `includeFiles` property in the step config.
Check the [Deployment](/docs/concepts/deployment/motia-cloud/deployment#adding-static-files-to-the-bundle) page for more information.

## Is it possible to deploy using GitHub Actions?

Yes, it's totally possible to deploy your project using GitHub Actions.

## How much it cost?

We're still working on the pricing model, but it's going to be based on usage. You will pay for what you use.

## How do I get support?

You can get support by creating an issue on our [GitHub repository](https://github.com/MotiaDev/motia-cloud-support/issues).


-   [features](/docs/deployment-guide/motia-cloud/features): Documentation for features.
---
title: Features
description: Learn how to deploy your Motia Project to a live environment
---

Motia Cloud is the easiest way to deploy your Motia Project to a live environment.
Quickly deploy your project to a live environment with one click. Then confidently
roll up updates, roll back to a previous stable version, and scale your project with ease.
Manage multiple environments, visualize logs and traces, and keep your project running smoothly.

## Real-time deployment status updates

You can see the deployment status in real-time in the Motia Cloud web interface

![Deployment real time updates](../../img/cloud/deployment-real-time-updates.png)

## Deployment history

All recent deployments on your project are available in Motia Cloud UI. You can browse them
and promote them to be live in the environment.

![Deployment history](../../img/cloud/deployments-list.png)

## Zero downtime deployments

Every deployment is an atomic deployment, this means that Motia Cloud creates a new infrastructure
with all the Message Queues system isolatedly for each deployment. 

### Why is this important?

- No downtime deployments
- Avoid backwards compatibility issues on message queues: Example, you can change a topic data structure
  without worrying about breaking messages that are flowing during the deployment.

## Instant rollbacks and roll up updates

With one button you can rollback to a previous deployment. This allows you to be confident
on deployments, if anything fails, quickly rollback to a previous stable version.

![Rollback](../../img/cloud/promote.png)

## One-click deployment

Deploy your project from workbench to a live environment with one click.

![One Click Deployment](../../img/cloud/one-click-deploy.gif)

## Observability

Have the same experience you have with Workbench locally in cloud. Such as:

- Logs visualization
- Tracing tool

### Logs visualization

You can see the logs of your project in the Motia Cloud web interface.

![Logs](../../img/cloud/logs.png)

### Tracing tool

Tracing tool to quickly visualize the flow of requests through the system.

![Tracing](../../img/cloud/tracing.png)

## Multiple environments support

Motia Cloud supports creating multiple environments for your projects.

![Multiple environments](../../img/cloud/environments-list.png)

## Scalability

- Horizontal scaling individually for each step
- Retry mechanisms for event steps built-in (3 retries by default)

## Learn how to deploy

Learn how to deploy your project to Motia Cloud in the [Deployment](/docs/concepts/deployment/motia-cloud/deployment) page.

-   [self-hosted](/docs/deployment-guide/self-hosted): Documentation for self-hosted.
---
title: Self-Hosted Deployment
description: Learn how to deploy your Motia project to production using motia-docker
---

Run your Motia app in Docker containers. Same environment everywhere - dev, staging, production.

<Callout type="warn">You need motia package **0.5.2-beta.101 or higher**</Callout>

## Quick Start

<Callout type="info">
**Important:** Run these commands from your project root (where your `package.json` is).
</Callout>

<Steps>
<Step>
#### Navigate to your project

```bash
cd /path/to/your/motia-project
```

Make sure you see `package.json` when you run `ls`.

</Step>
<Step>
#### Setup Docker files

```bash
npx motia@latest docker setup
```

This creates `Dockerfile` and `.dockerignore` in your project.

</Step>
<Step>
#### Build and run

```bash
npx motia@latest docker run --project-name my-app
```

Replace `my-app` with your project name.

</Step>
<Step>
#### Check it works

Open [http://localhost:3000](http://localhost:3000) in your browser.

For more options:
```bash
npx motia@latest docker run --help
```

</Step>
</Steps>

<Callout type="error">
**Getting `ENOENT: no such file or directory, open package.json`?**

You're not in your project directory. Run `cd /path/to/your/project` first.
</Callout>

---

## Manual Docker Setup

Want more control? Build it yourself.

The `docker setup` command creates a Dockerfile for you, but here's what's in it:

```dockerfile title="Dockerfile"
# Use Motia's base image (has Node + Python ready)
FROM motiadev/motia:latest

# For AWS Lightsail or other ARM platforms, use:
# FROM --platform=linux/arm64 motiadev/motia:latest

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci --only=production

# Copy your app
COPY . .

# If you have Python steps, uncomment this line:
# RUN npx motia@latest install

# Expose the port
EXPOSE 3000

# Start your app
CMD ["npm", "run", "start"]
```

### Python Steps?

If you have Python steps, uncomment this line in the Dockerfile:

```dockerfile
RUN npx motia@latest install
```

And make sure you have a `requirements.txt` file in your project.

### .dockerignore

Create a `.dockerignore` file to keep your image small:

```bash
# Git
.git
.gitignore

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
ENV/

# Node
node_modules/
npm-debug.log
yarn-debug.log
yarn-error.log

# IDE
.vscode/
.idea/
*.swp
*.swo

# Local development
.env

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db
```

---

## Build and Run Manually

### Build your image

```bash
docker build -t my-motia-app .
```

### Run it

```bash
docker run -it --rm -p 3000:3000 my-motia-app
```

Open [http://localhost:3000](http://localhost:3000) - your app should be running!

---

## Deploy to Cloud

### AWS Lightsail

Lightsail needs ARM. Update your Dockerfile:

```dockerfile
FROM --platform=linux/arm64 motiadev/motia:latest
```

Then build and deploy.

### Railway

Connect your GitHub repo. Railway detects the Dockerfile automatically.

### Fly.io

Create `fly.toml`:

```toml
app = "my-motia-app"

[build]
  dockerfile = "Dockerfile"

[[services]]
  internal_port = 3000
  protocol = "tcp"
```

Deploy: `fly deploy`

### Render

Create a Web Service, point to your repo. Render builds automatically.

---

## Configuring Adapters for Production

When deploying multiple Motia instances, you need distributed adapters to share state, events, and streams across instances. Without them, each instance operates in isolation.

### When to Use Distributed Adapters

**Use default adapters when:**
- Running a single Motia instance
- Development and testing
- Simple deployments

**Use distributed adapters when:**
- Running multiple Motia instances (horizontal scaling)
- Production deployments requiring high availability
- Need shared state/events/streams across instances

### Docker Compose with Redis

For production deployments, use Docker Compose to run Motia with Redis:

```yaml title="docker-compose.yml"
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data

  motia:
    build: .
    ports:
      - "3000:3000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - RABBITMQ_URL=amqp://rabbitmq:5672
    depends_on:
      - redis
      - rabbitmq

  rabbitmq:
    image: rabbitmq:3-management-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq

volumes:
  redis-data:
  rabbitmq-data:
```

### Configure Adapters in motia.config.ts

Update your configuration to use distributed adapters:

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'
import { RedisStreamAdapterManager } from '@motiadev/adapter-redis-streams'
import { RabbitMQEventAdapter } from '@motiadev/adapter-rabbitmq-events'
import { RedisCronAdapter } from '@motiadev/adapter-redis-cron'

export default config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
    }),
    streams: new RedisStreamAdapterManager({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
    }),
    events: new RabbitMQEventAdapter({
      url: process.env.RABBITMQ_URL || 'amqp://localhost:5672',
      exchangeName: process.env.RABBITMQ_EXCHANGE || 'motia.events',
      exchangeType: 'topic',
    }),
    cron: new RedisCronAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
    }),
  },
})
```

### Install Adapter Packages

Add the adapter packages to your `package.json`:

```bash
npm install @motiadev/adapter-redis-state \
            @motiadev/adapter-redis-streams \
            @motiadev/adapter-rabbitmq-events \
            @motiadev/adapter-redis-cron
```

### Scaling Multiple Instances

With distributed adapters configured, you can scale to multiple instances:

```yaml title="docker-compose.yml"
services:
  motia-1:
    build: .
    ports:
      - "3000:3000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis

  motia-2:
    build: .
    ports:
      - "3001:3000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis

  motia-3:
    build: .
    ports:
      - "3002:3000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - redis
```

All instances share the same state, events, and streams through Redis and RabbitMQ.

<Callout type="warn">
Without distributed adapters, each Motia instance has isolated state and events. Use Redis/RabbitMQ adapters for multi-instance deployments.
</Callout>

[Learn more about adapters â†’](/docs/development-guide/adapters/usage)

---

## Resources

- [Docker Hub](https://hub.docker.com/r/motiadev/motia) - Official Motia image
- [Example Project](https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-docker) - Full deployment example
- [CLI Reference](/docs/development-guide/cli#docker) - All docker commands


-   [adapters](/docs/development-guide/adapters): Documentation for adapters.
---
title: Adapters
description: Pluggable infrastructure for state, streams, events, and cron
---

Adapters let you swap infrastructure implementations without changing your code. Use defaults for single-instance deployments or distributed adapters for scaling.

## How It Works

Configure adapters in `motia.config.ts`. If you don't specify any, Motia uses defaults.

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'

export default config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST,
      port: 6379
    })
  }
})
```

Your Step code stays the same:

```typescript
await state.set('orders', 'order-123', { id: 'order-123' })
```

---

## Adapter Types

| Type | What it handles | Default | Distributed |
|------|----------------|---------|-------------|
| **State** | Key-value storage | File | Redis |
| **Streams** | Real-time data | File | Redis |
| **Events** | Event queues | In-memory | RabbitMQ |
| **Cron** | Job locking | In-memory | Redis |

---

## Default Adapters

For single-instance deployments. No configuration needed.

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'

export default config({
  // Uses defaults:
  // - FileStateAdapter for state
  // - FileStreamAdapter for streams
  // - InMemoryQueueEventAdapter for events
  // - InMemoryCronAdapter for cron
})
```

**Where data goes:**
- State: `.motia/motia.state.json`
- Streams: `.motia/streams/`
- Events: Process memory
- Cron: Process memory

---

## Distributed Adapters

For multi-instance deployments. Shares state and events across instances.

### Redis State

<Tabs items={['TypeScript', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'

export default config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379')
    })
  }
})
```

</Tab>
<Tab value='JavaScript'>

```javascript title="motia.config.js"
const { config } = require('@motiadev/core')
const { RedisStateAdapter } = require('@motiadev/adapter-redis-state')

module.exports = config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379')
    })
  }
})
```

</Tab>
</Tabs>

**Install:**

```bash
npm install @motiadev/adapter-redis-state
```

### Redis Streams

<Tabs items={['TypeScript', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisStreamAdapterManager } from '@motiadev/adapter-redis-streams'

export default config({
  adapters: {
    streams: new RedisStreamAdapterManager({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379')
    })
  }
})
```

</Tab>
<Tab value='JavaScript'>

```javascript title="motia.config.js"
const { config } = require('@motiadev/core')
const { RedisStreamAdapterManager } = require('@motiadev/adapter-redis-streams')

module.exports = config({
  adapters: {
    streams: new RedisStreamAdapterManager({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379')
    })
  }
})
```

</Tab>
</Tabs>

**Install:**

```bash
npm install @motiadev/adapter-redis-streams
```

### RabbitMQ Events

<Tabs items={['TypeScript', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RabbitMQEventAdapter } from '@motiadev/adapter-rabbitmq-events'

export default config({
  adapters: {
    events: new RabbitMQEventAdapter({
      url: process.env.RABBITMQ_URL || 'amqp://localhost',
      exchangeName: 'motia.events',
      exchangeType: 'topic'
    })
  }
})
```

</Tab>
<Tab value='JavaScript'>

```javascript title="motia.config.js"
const { config } = require('@motiadev/core')
const { RabbitMQEventAdapter } = require('@motiadev/adapter-rabbitmq-events')

module.exports = config({
  adapters: {
    events: new RabbitMQEventAdapter({
      url: process.env.RABBITMQ_URL || 'amqp://localhost',
      exchangeName: 'motia.events',
      exchangeType: 'topic'
    })
  }
})
```

</Tab>
</Tabs>

**Install:**

```bash
npm install @motiadev/adapter-rabbitmq-events
```

### Redis Cron

<Tabs items={['TypeScript', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisCronAdapter } from '@motiadev/adapter-redis-cron'

export default config({
  adapters: {
    cron: new RedisCronAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379')
    })
  }
})
```

</Tab>
<Tab value='JavaScript'>

```javascript title="motia.config.js"
const { config } = require('@motiadev/core')
const { RedisCronAdapter } = require('@motiadev/adapter-redis-cron')

module.exports = config({
  adapters: {
    cron: new RedisCronAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379')
    })
  }
})
```

</Tab>
</Tabs>

**Install:**

```bash
npm install @motiadev/adapter-redis-cron
```

---

## All Together

Using all distributed adapters:

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'
import { RedisStreamAdapterManager } from '@motiadev/adapter-redis-streams'
import { RabbitMQEventAdapter } from '@motiadev/adapter-rabbitmq-events'
import { RedisCronAdapter } from '@motiadev/adapter-redis-cron'

export default config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: 6379
    }),
    streams: new RedisStreamAdapterManager({
      host: process.env.REDIS_HOST || 'localhost',
      port: 6379
    }),
    events: new RabbitMQEventAdapter({
      url: process.env.RABBITMQ_URL || 'amqp://localhost',
      exchangeName: 'motia.events',
      exchangeType: 'topic'
    }),
    cron: new RedisCronAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: 6379
    })
  }
})
```

---

## When to Use What

**Default adapters:**
- Single Motia instance
- Development
- Testing
- Simple deployments

**Distributed adapters:**
- Multiple Motia instances
- Horizontal scaling
- Production deployments
- High availability

---



-   [cli](/docs/development-guide/cli): Documentation for cli.
---
title: Command Line Interface (CLI)
description: Learn how to use the Motia CLI to manage your projects and workflows
---

# Command Line Interface (CLI)

Motia provides a powerful Command Line Interface (CLI) to help you manage your projects and workflows. The CLI offers various commands for creating projects, generating steps, managing state, and more.

## Installation

The Motia CLI is automatically installed when you install the `motia` package. You can use it by running `npx motia` followed by the desired command.

## Commands

### `create`

Create a new Motia project.

```bash
npx motia@latest create [project-name] [options]
```

**Arguments:**

- `[project-name]` (optional): The name for your project folder. 
  If not provided, you will be prompted to enter it. 
  Use `.` or `./` to create it in the current directory.

**Options:**

- `--template <template-name>` (optional): The template to use for your project. 
  If not provided, you will be prompted to select one interactively.

**Available Templates:**

Motia provides several project templates to help you get started quickly:

| Template | Description | Use Case |
|----------|-------------|----------|
| `starter-typescript` | Starter (TypeScript) | Minimal TypeScript project with basic examples |
| `starter-javascript` | Starter (JavaScript) | Minimal JavaScript project with basic examples |
| `starter-python` | Starter (Python) | Minimal Python project with basic examples |
| `motia-tutorial-typescript` | Tutorial (TypeScript) | Interactive tutorial project in TypeScript |
| `motia-tutorial-python` | Tutorial (Python) | Interactive tutorial project in Python |

**Examples:**

Create a TypeScript starter project:
```bash
npx motia@latest create my-app --template starter-typescript
```

Create a Python tutorial project:
```bash
npx motia@latest create my-tutorial --template motia-tutorial-python
```

Use interactive mode (no template specified):
```bash
npx motia@latest create
# You'll be prompted to select a template from the list above
```


### `build`

Build your project, generating zip files for each step and creating a configuration file.

```bash
npx motia build
```

This command:

1. Compiles all your steps (both Node.js and Python)
2. Bundles each step into a zip file
3. Generates a `motia.steps.json` configuration file in the `dist` directory
4. Organizes the output in the `dist` directory

### `deploy`

Deploy your built steps to the Motia deployment service.

```bash
motia cloud deploy --api-key <api-key> --version-name <version> [options]
```

Options:

- `-k, --api-key <key>` (required): Your API key for authentication
- `-n, --project-name <name>`: Project name (used when creating a new project)
- `-s, --environment-id <id>`: Environment ID (can also be set via MOTIA_ENVIRONMENT_ID env var)
- `--environment-name <name>`: Environment name (used when creating a new environment)
- `-v, --version-name <version>` (required): The version to deploy
- `-d, --version-description <description>`: The description of the version
- `-e, --env-file <path>`: Path to environment file

Example:

```bash
motia cloud deploy --api-key your-api-key-here --version-name 1.2.3 --environment-id env-uuid
```

The deployment process:

1. Build your project
2. Uploads each zip file individually with its path information
3. Starts the deployment process on the server

### `dev`

Start the development server.

```bash
npx motia dev [options]
```

Options:

- `-p, --port <port>`: The port to run the server on (default: 3000).
- `-H, --host [host]`: The host address for the server (default: localhost).
- `-d, --debug`: Enable debug logging.

### `get-config`

Get the generated config for your project.

```bash
npx motia get-config [options]
```

Options:

- `-o, --output <path>`: Path to write the generated config file.

### `emit`

Emit an event to the Motia server.

```bash
npx motia emit [options]
```

Options:

- `--topic <topic>` (required): Event topic/type to emit.
- `--message <message>` (required): Event payload as a JSON string.
- `-p, --port <number>`: Port number (default: 3000).

### `generate`

Generate Motia resources.

#### `generate step`

Create a new step with interactive prompts.

```bash
npx motia generate step [options]
```

Options:

- `-d, --dir <step file path>`: The path relative to the steps directory to create the step file.

#### `generate openapi`

Generate OpenAPI spec for your project.

```bash
npx motia generate openapi [options]
```

Options:

- `-t, --title <tile of the document>`: Title for the OpenAPI document. Defaults to project name from package.json.
- `-v, --version <version of the document>`: Version of the OpenAPI document. Defaults to 1.0.0.
- `-o, --output <output file name / path>`: The file name and path relative to root to create the openapi file. Defaults to `openapi.json` at the root.

### `state`

Manage application state.

#### `state list`

List the current file state.

```bash
npx motia state list
```

## Debugging

You can enable debug logging by passing the `-d` or `--debug` flag to the `dev` command:

```bash
npx motia dev --debug
```

This will set the `LOG_LEVEL` environment variable to `'debug'`, providing more detailed logging output.

### `docker`

Tools to help you setup your Motia project with docker and run it inside a container.

#### `docker setup`

Setup your Motia project for Docker

```bash
npx motia docker setup
```

#### `docker build`

Build your Motia project Docker image

```bash
npx motia docker build
```

Options:

- `--project-name <project name>` (required): The name of your project.

#### `docker run`

Run your Motia project inside a container

```bash
npx motia docker run
```

Options:

- `--port <number>`: Port number (default: 3000).
- `--project-name <project name>` (required): The name of your project.
- `--skip-build`: Skip building the Docker image and used the last built image.

## Next Steps

- Explore the [Core Concepts](/docs/concepts) to learn more about Steps, Flows, Events, and Topics.
- Check out the [Examples](/docs/examples) for common patterns and use cases.
- Join our [Community](/community) for help and discussions.


-   [customizing-flows](/docs/development-guide/customizing-flows): Documentation for customizing-flows.
---
title: Customizing Flows
description: Make your Workbench flows look exactly how you want
---

By default, Workbench shows your Steps with their code. Great for developers. But what if you're sharing with:
- Frontend developers who just need to know the API
- Product managers who want to see the big picture
- Designers who care about the flow, not the code

You can override how Steps look in Workbench with custom React components.

---

## Custom UI for Steps

Want to change how a Step looks? Create a `.tsx` or `.jsx` file next to it.
**File structure:**

<Tabs items={['TypeScript', 'JavaScript']}>
  <Tab value="TypeScript"> 
<Folder name="steps" defaultOpen>
  <Folder name="create-order" defaultOpen>
    <File name="create-order.step.ts" />
    <File name="create-order.step.tsx" />
  </Folder>
</Folder>
  </Tab>
  <Tab value="JavaScript">
<Folder name="steps" defaultOpen>
  <Folder name="create-order" defaultOpen>
    <File name="create-order.step.js" />
    <File name="create-order.step.jsx" />
  </Folder>
</Folder>
  </Tab>
</Tabs>

ðŸ‘‰ Same name, different extension. Motia connects them automatically.

---

## Simple Example

Let's use the built-in `EventNode` but add an icon:

```tsx title="steps/send-email.step.tsx"
import { EventNode, EventNodeProps } from 'motia/workbench'
import React from 'react'

export const Node: React.FC<EventNodeProps> = (props) => {
  return (
    <EventNode {...props}>
      <div className="flex flex-row items-start gap-2">
        <div className="text-sm text-gray-400 font-mono">{props.data.description}</div>
        <img
          style={{ width: '64px', height: '64px' }}
          src="https://www.motia.dev/icon.png"
        />
      </div>
    </EventNode>
  )
}
```

That's it! The Step now shows with your custom content inside, plus an icon.

---

## Built-in Components

Motia gives you ready-made components for different Step types:

| Component   | For which Steps | What you get |
| ----------- | --------------- | ------------ |
| `EventNode` | Event triggers  | Styled box with connection points |
| `ApiNode`   | API triggers    | Box with request/response info |
| `CronNode`  | Cron triggers   | Box with schedule info |
| `NoopNode`  | NOOP steps      | Different color for visual distinction |

---

## Fully Custom UI

Want complete control? Build from scratch. Here's a real example:

**The Step:**

```typescript title="steps/process-order.step.ts"
export const config: EventConfig = {
  type: 'event',
  name: 'ProcessFoodOrder',
  subscribes: ['process-food-order'],
  emits: ['notification'],
  flows: ['basic-tutorial']
}
```

**Custom UI:**

```tsx title="steps/process-order.step.tsx"
import React from 'react'
import { BaseHandle, Position } from 'motia/workbench'
import type { EventNodeProps } from 'motia/workbench'

export default function ProcessOrderUI({ data }: EventNodeProps) {
  // Prevent code viewer from opening when clicked
  const handleClick = (e: React.MouseEvent) => {
    e.stopPropagation()
    e.preventDefault()
    return false
  }

  return (
    <div
      onClick={handleClick}
      className="relative bg-white border-2 border-blue-500 rounded-lg py-3 px-4 shadow-md min-w-[200px]"
      style={{ pointerEvents: 'auto' }}
    >
      <BaseHandle type="target" position={Position.Top} />
      
      <div className="text-center">
        <div className="font-semibold text-blue-700">
          ðŸ½ï¸ Process Order
        </div>
        <div className="text-sm text-gray-600 mt-1">
          {data.name}
        </div>
        <div className="text-xs text-gray-500 mt-1">
          Handles food orders
        </div>
      </div>
      
      <BaseHandle type="source" position={Position.Bottom} />
    </div>
  )
}
```

**What this does:**
- Shows a clean card instead of code
- Has connection points (the `BaseHandle` parts)
- Prevents code viewer from popping up
- Uses your brand colors (blue border here)

**Important parts:**
- âœ… `BaseHandle` components - These are the connection dots
- âœ… `onClick={handleClick}` - Stops the code viewer from opening
- âœ… `Position.Top` and `Position.Bottom` - Where connections attach
- âœ… Export as `default function` - Required for Motia to find it

---

## NOOP Steps

NOOP = "No Operation". These Steps don't actually run code. They just sit in your flow diagram to represent:

- **External stuff** â†’ Webhooks, third-party APIs, manual processes
- **Human actions** â†’ Approval gates, manual reviews
- **Testing** â†’ Placeholder nodes while building flows
- **Documentation** â†’ Show the complete picture visually

---

## Creating NOOP Steps

NOOP Steps are config-only. No handler needed.

```typescript title="steps/approval-gate.step.ts"
import { NoopConfig } from 'motia'

export const config: NoopConfig = {
  type: 'noop',
  name: 'ApprovalGate',
  description: 'Manager reviews and approves',
  virtualSubscribes: ['order.created'],
  virtualEmits: ['order.approved', 'order.rejected'],
  flows: ['order-flow']
}

// No handler! NOOP steps don't run code
```

**Add custom UI (optional):**

```tsx title="steps/approval-gate.step.tsx"
import React from 'react'
import { BaseHandle, Position } from 'motia/workbench'

export default function ApprovalGate() {
  return (
    <div className="p-4 bg-yellow-50 rounded-lg border-2 border-yellow-400">
      <BaseHandle type="target" position={Position.Top} />
      
      <div className="text-center">
        <div className="text-lg">â¸ï¸</div>
        <div className="font-medium">Waiting for approval</div>
        <div className="text-xs text-gray-600">Manager review required</div>
      </div>
      
      <BaseHandle type="source" position={Position.Bottom} />
    </div>
  )
}
```

---

## Common NOOP Examples

### 1. Waiting for Stripe Payment

```typescript title="steps/stripe-webhook.step.ts"
export const config: NoopConfig = {
  type: 'noop',
  name: 'StripeWebhook',
  description: 'Waits for payment confirmation from Stripe',
  virtualSubscribes: ['payment.initiated'],
  virtualEmits: ['/api/stripe/webhook'],
  flows: ['payment']
}
```

### 2. Human Approval

```typescript title="steps/manager-review.step.ts"
export const config: NoopConfig = {
  type: 'noop',
  name: 'ManagerReview',
  description: 'Manager reviews the request',
  virtualSubscribes: ['approval.requested'],
  virtualEmits: ['/api/approvals/submit'],
  flows: ['approval']
}
```

### 3. GitHub Webhook

```typescript title="steps/github-webhook.step.ts"
export const config: NoopConfig = {
  type: 'noop',
  name: 'GitHubWebhook',
  description: 'Waits for repo events from GitHub',
  virtualSubscribes: ['repo.watched'],
  virtualEmits: ['/api/github/webhook'],
  flows: ['ci-cd']
}
```

---

## Tips

**For Custom UIs:**
- âœ… Start with built-in components (`EventNode`, `ApiNode`)
- âœ… Keep it simple - focus on clarity
- âœ… Use Tailwind for styling
- âœ… Add `BaseHandle` for connections
- âŒ Don't overthink it - simple cards work great

**For NOOP Steps:**
- âœ… Always include `virtualSubscribes` (even if empty `[]`)
- âœ… Use clear, descriptive names
- âœ… Explain what happens externally in the description
- âœ… Connect them to your flow with virtual emits/subscribes

---

## Quick Reference

### What to Import

```typescript
import React from 'react'
import { BaseHandle, Position } from 'motia/workbench'
import type { EventNodeProps } from 'motia/workbench'
```

### Where Handles Go

- **Top** (`Position.Top`) â†’ For inputs (things coming in)
- **Bottom** (`Position.Bottom`) â†’ For outputs (things going out)
- Flows go top to bottom

### Export Format

```tsx
export default function MyCustomNode() {
  // Your UI
}
```

or

```tsx
export const Node: React.FC<EventNodeProps> = (props) => {
  // Your UI using props
}
```

---


-   [environment-variables](/docs/development-guide/environment-variables): Documentation for environment-variables.
---
title: Environment Variables
description: Store API keys and configuration safely using .env files in your Motia apps.
---

# Environment Variables

Environment variables let you store API keys, database URLs, and other configuration outside your code. This keeps sensitive information secure and makes it easy to use different settings for development and production.

## Quick Setup

### 1. Create a `.env` File

Create a `.env` file in your project root:

```bash title=".env"
# API Keys
OPENAI_API_KEY=sk-your-api-key-here
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook

# Database  
DATABASE_URL=postgresql://user:password@localhost:5432/myapp

# App Settings
NODE_ENV=development
PORT=3000
```

### 2. Add to `.gitignore`

Make sure you never commit your `.env` file:

```bash title=".gitignore"
.env
.env.local
```

### 3. Create Template for Your Team

```bash title=".env.example"
# Copy this to .env and add your actual values
OPENAI_API_KEY=your-api-key-here
DATABASE_URL=postgresql://user:password@localhost:5432/myapp
```

## Using Environment Variables in Steps

### TypeScript/JavaScript

```typescript title="my-step.step.ts"
export const config = {
  type: 'api',
  name: 'chat-with-ai',
  path: '/chat',
  method: 'POST'
}

export const handler = async (req, { logger }) => {
  // Use environment variables with process.env
  const apiKey = process.env.OPENAI_API_KEY
  const webhookUrl = process.env.DISCORD_WEBHOOK_URL
  
  if (!apiKey) {
    return { status: 400, body: { error: 'Missing API key' } }
  }
  
  logger.info('Using OpenAI API', { hasKey: !!apiKey })
  
  // Your logic here...
  return { status: 200, body: { message: 'Success!' } }
}
```

### Python

```python title="my-step.step.py"
import os

config = {
    'type': 'event', 
    'name': 'process-data',
    'subscribes': ['data.received']
}

async def handler(input_data, ctx):
    # Use environment variables with os.environ
    api_key = os.environ.get('OPENAI_API_KEY')
    database_url = os.environ.get('DATABASE_URL')
    
    if not api_key:
        raise ValueError('Missing OPENAI_API_KEY')
    
    ctx.logger.info('Processing with API key', {'has_key': bool(api_key)})
    
    # Your logic here...
    return {'status': 'processed'}
```

## Deployment

When you deploy your app, set environment variables through your hosting platform:

### Motia Cloud
```bash
motia env set OPENAI_API_KEY=sk-your-production-key
motia env set NODE_ENV=production
```

## Important Security Tips

<Callout type="warning">
**ðŸ”’ Keep Your Keys Safe**

- Never commit `.env` files to git
- Use different API keys for development and production  
- Don't share API keys in code or messages
</Callout>

That's it! Environment variables are simple - just put them in `.env` and use `process.env.VARIABLE_NAME` in your code.


-   [flows](/docs/development-guide/flows): Documentation for flows.
---
title: Flows
description: Group multiple steps to be visible in diagrams in Workbench
---

Flows group related Steps together so you can see them as connected workflows in Workbench. Add `flows` to your Step config - it's an array of flow names.

## How It Works

Add `flows` to any Step config. Each string is a flow name.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
export const config: ApiRouteConfig = {
  name: 'CreateResource',
  type: 'api',
  path: '/resources',
  method: 'POST',
  flows: ['resource-management']
}
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "CreateResource",
    "type": "api",
    "path": "/resources",
    "method": "POST",
    "flows": ["resource-management"]
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  name: 'CreateResource',
  type: 'api',
  path: '/resources',
  method: 'POST',
  flows: ['resource-management']
}
```

</Tab>
</Tabs>

---

## Example

Two Steps working together in one flow.

![API and Event Steps connected in a flow](../img/flows-api-event.png)

**API Step - Create resource:**

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="steps/create-resource.step.ts"
import { ApiRouteConfig, Handlers } from 'motia'

export const config: ApiRouteConfig = {
  name: 'CreateResource',
  type: 'api',
  path: '/resources',
  method: 'POST',
  flows: ['resource-management'],
  emits: ['send-email']
}

export const handler: Handlers['CreateResource'] = async (req, { emit, logger }) => {
  logger.info('Creating resource', { title: req.body.title })
  
  await emit({ 
    topic: 'send-email', 
    data: { email: req.body.email } 
  })
  
  return { status: 201, body: { id: '123' } }
}
```

</Tab>
<Tab value='Python'>

```python title="steps/create_resource_step.py"
config = {
    "name": "CreateResource",
    "type": "api",
    "path": "/resources",
    "method": "POST",
    "flows": ["resource-management"],
    "emits": ["send-email"]
}

async def handler(req, ctx):
    ctx.logger.info("Creating resource", {"title": req["body"]["title"]})
    
    await ctx.emit({
        "topic": "send-email",
        "data": {"email": req["body"]["email"]}
    })
    
    return {"status": 201, "body": {"id": "123"}}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="steps/create-resource.step.js"
const config = {
  name: 'CreateResource',
  type: 'api',
  path: '/resources',
  method: 'POST',
  flows: ['resource-management'],
  emits: ['send-email']
}

const handler = async (req, { emit, logger }) => {
  logger.info('Creating resource', { title: req.body.title })
  
  await emit({ 
    topic: 'send-email', 
    data: { email: req.body.email } 
  })
  
  return { status: 201, body: { id: '123' } }
}

module.exports = { config, handler }
```

</Tab>
</Tabs>

**Event Step - Send email:**

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="steps/send-email.step.ts"
import { EventConfig, Handlers } from 'motia'

export const config: EventConfig = {
  name: 'SendEmail',
  type: 'event',
  subscribes: ['send-email'],
  flows: ['resource-management']
}

export const handler: Handlers['SendEmail'] = async (input, { logger }) => {
  logger.info('Sending email', { email: input.email })
  // Email sending logic here
}
```

</Tab>
<Tab value='Python'>

```python title="steps/send_email_step.py"
config = {
    "name": "SendEmail",
    "type": "event",
    "subscribes": ["send-email"],
    "flows": ["resource-management"]
}

async def handler(input, ctx):
    ctx.logger.info("Sending email", {"email": input["email"]})
    # Email sending logic here
```

</Tab>
<Tab value='JavaScript'>

```javascript title="steps/send-email.step.js"
const config = {
  name: 'SendEmail',
  type: 'event',
  subscribes: ['send-email'],
  flows: ['resource-management']
}

const handler = async (input, { logger }) => {
  logger.info('Sending email', { email: input.email })
  // Email sending logic here
}

module.exports = { config, handler }
```

</Tab>
</Tabs>

ðŸ‘‰ Both Steps have `flows: ['resource-management']`. In Workbench, they appear connected.

---

## Multiple Flows

A Step can belong to multiple flows.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
export const config: EventConfig = {
  name: 'SendEmail',
  type: 'event',
  subscribes: ['send-email'],
  flows: ['resource-management', 'user-onboarding']
}
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "SendEmail",
    "type": "event",
    "subscribes": ["send-email"],
    "flows": ["resource-management", "user-onboarding"]
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  name: 'SendEmail',
  type: 'event',
  subscribes: ['send-email'],
  flows: ['resource-management', 'user-onboarding']
}
```

</Tab>
</Tabs>

ðŸ‘‰ This Step appears in both flows in Workbench.

## Steps Without Flows

Steps work fine without flows.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
export const config: ApiRouteConfig = {
  name: 'HealthCheck',
  type: 'api',
  path: '/health',
  method: 'GET'
}
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "HealthCheck",
    "type": "api",
    "path": "/health",
    "method": "GET"
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  name: 'HealthCheck',
  type: 'api',
  path: '/health',
  method: 'GET'
}
```

</Tab>
</Tabs>

---

## Flows in Workbench

Workbench has a dropdown to filter by flow. Select a flow to see only the Steps that belong to it.

![Flow dropdown in Workbench](../img/drop-down-flow.png)

### Virtual Connections

Use `virtualEmits` and `virtualSubscribes` for visualization without actual events:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
export const config: ApiRouteConfig = {
  name: 'CreateResource',
  type: 'api',
  path: '/resources',
  method: 'POST',
  virtualEmits: ['approval.required'],
  flows: ['resource-management']
}
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "CreateResource",
    "type": "api",
    "path": "/resources",
    "method": "POST",
    "virtualEmits": ["approval.required"],
    "flows": ["resource-management"]
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  name: 'CreateResource',
  type: 'api',
  path: '/resources',
  method: 'POST',
  virtualEmits: ['approval.required'],
  flows: ['resource-management']
}
```

</Tab>
</Tabs>

Virtual connections show as gray/dashed lines in Workbench. Real connections (from `emits` and `subscribes`) show as dark solid lines.

![Virtual connections with labels in Workbench](../img/virtual-emit-subscribe.png)

### Labels

Add labels to connections in Workbench:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
export const config: ApiRouteConfig = {
  name: 'SendEmail',
  type: 'api',
  path: '/send',
  method: 'POST',
  virtualEmits: [
    { topic: 'email-sent', label: 'Email delivered' },
    { topic: 'email-failed', label: 'Failed to send', conditional: true },
  ],
  flows: ['notifications']
}
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "SendEmail",
    "type": "api",
    "path": "/send",
    "method": "POST",
    "virtualEmits": [
        {"topic": "email-sent", "label": "Email delivered"},
        {"topic": "email-failed", "label": "Failed to send", "conditional": True}
    ],
    "flows": ["notifications"]
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  name: 'SendEmail',
  type: 'api',
  path: '/send',
  method: 'POST',
  virtualEmits: [
    { topic: 'email-sent', label: 'Email delivered' },
    { topic: 'email-failed', label: 'Failed to send', conditional: true }
  ],
  flows: ['notifications']
}
```

</Tab>
</Tabs>

### NOOP Steps

NOOP Steps don't run code. They're for visualization only:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
import { NoopConfig } from 'motia'

export const config: NoopConfig = {
  type: 'noop',
  name: 'ApprovalGate',
  virtualEmits: ['approved'],
  virtualSubscribes: ['approval.required'],
  flows: ['resource-management']
}

// No handler needed
```

</Tab>
<Tab value='Python'>

```python
config = {
    "type": "noop",
    "name": "ApprovalGate",
    "virtualEmits": ["approved"],
    "virtualSubscribes": ["approval.required"],
    "flows": ["resource-management"]
}

# No handler needed
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  type: 'noop',
  name: 'ApprovalGate',
  virtualEmits: ['approved'],
  virtualSubscribes: ['approval.required'],
  flows: ['resource-management']
}

// No handler needed

module.exports = { config }
```

</Tab>
</Tabs>

ðŸ‘‰ [Learn about customizing how flows look â†’](/docs/development-guide/customizing-flows)

---


-   [infrastructure](/docs/development-guide/infrastructure): Documentation for infrastructure.
---
title: Infrastructure
description: Configure queue behavior, retries, and timeouts for Event Steps
---

Infrastructure settings let you control how Event Steps handle queues, retries, and timeouts. Motia provides sensible defaults, so you only configure what you need.

## How It Works

Add `infrastructure` to your Event Step config:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
export const config: EventConfig = {
  name: 'SendEmail',
  type: 'event',
  subscribes: ['email.requested'],
  infrastructure: {
    handler: { timeout: 10 },
    queue: { maxRetries: 5, visibilityTimeout: 60 }
  }
}
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "SendEmail",
    "type": "event",
    "subscribes": ["email.requested"],
    "infrastructure": {
        "handler": {"timeout": 10},
        "queue": {"maxRetries": 5, "visibilityTimeout": 60}
    }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  name: 'SendEmail',
  type: 'event',
  subscribes: ['email.requested'],
  infrastructure: {
    handler: { timeout: 10 },
    queue: { maxRetries: 5, visibilityTimeout: 60 }
  }
}
```

</Tab>
</Tabs>

---

## Configuration Options

### Handler Settings

| Property | Type | Default | Description |
|----------|------|---------|-------------|
| `timeout` | `number` | 30 | Handler timeout in seconds |

### Queue Settings

| Property | Type | Default | Description |
|----------|------|---------|-------------|
| `type` | `string` | `standard` | Queue type: `standard` or `fifo` |
| `maxRetries` | `number` | 3 | Number of retry attempts on failure |
| `visibilityTimeout` | `number` | 900 | Seconds before message becomes visible again |
| `delaySeconds` | `number` | 0 | Delay before processing (0-900 seconds) |

---

## FIFO Queues

FIFO queues guarantee exactly-once processing and maintain message order within a group.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
export const config: EventConfig = {
  name: 'ProcessOrder',
  type: 'event',
  subscribes: ['order.created'],
  infrastructure: {
    queue: {
      type: 'fifo'
    }
  }
}
```

</Tab>
<Tab value='Python'>

```python
config = {
    "name": "ProcessOrder",
    "type": "event",
    "subscribes": ["order.created"],
    "infrastructure": {
        "queue": {
            "type": "fifo"
        }
    }
}
```

</Tab>
<Tab value='JavaScript'>

```javascript
const config = {
  name: 'ProcessOrder',
  type: 'event',
  subscribes: ['order.created'],
  infrastructure: {
    queue: {
      type: 'fifo'
    }
  }
}
```

</Tab>
</Tabs>

### Message Group ID

When emitting to FIFO queues, pass a `messageGroupId`:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
export const handler: Handlers['CreateOrder'] = async (req, { emit }) => {
  const { orderId, customerId } = req.body
  
  await emit({
    topic: 'order.created',
    data: { orderId, customerId },
    messageGroupId: customerId  // Required for FIFO
  })
}
```

</Tab>
<Tab value='Python'>

```python
async def handler(req, ctx):
    order_id = req.body["orderId"]
    customer_id = req.body["customerId"]
    
    await ctx.emit({
        "topic": "order.created",
        "data": {"orderId": order_id, "customerId": customer_id},
        "messageGroupId": customer_id  # Required for FIFO
    })
```

</Tab>
<Tab value='JavaScript'>

```javascript
const handler = async (req, { emit }) => {
  const { orderId, customerId } = req.body
  
  await emit({
    topic: 'order.created',
    data: { orderId, customerId },
    messageGroupId: customerId  // Required for FIFO
  })
}
```

</Tab>
</Tabs>

The `messageGroupId` ensures events are processed in order within that group.

---

## Default Values

If you don't specify infrastructure settings, Motia uses these defaults:

```typescript
{
  handler: {
    timeout: 30
  },
  queue: {
    type: 'standard',
    maxRetries: 3,
    visibilityTimeout: 900,
    delaySeconds: 0
  }
}
```

---



-   [middleware](/docs/development-guide/middleware): Documentation for middleware.
---
title: Middleware
description: Run code before and after your API handlers
---

## What is Middleware?

Middleware runs before your API handler. Use it for authentication, logging, error handling, or any logic that applies to multiple endpoints.

---

## How It Works

A middleware is a function that receives three arguments:

```typescript
middleware(req, ctx, next)
```

- **req** - The incoming request (same as handler)
- **ctx** - The context object (same as handler)  
- **next()** - Call this to continue to the handler

If you don't call `next()`, the request stops. The handler never runs.

---

## Simple Example

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    import { ApiMiddleware } from 'motia'

    const authMiddleware: ApiMiddleware = async (req, ctx, next) => {
      if (!req.headers.authorization) {
        return { status: 401, body: { error: 'Unauthorized' } }
      }
      return next()
    }

    export const config = {
      name: 'ProtectedEndpoint',
      type: 'api',
      path: '/protected',
      method: 'GET',
      middleware: [authMiddleware]
    }

    export const handler = async (req, ctx) => {
      return { status: 200, body: { message: 'Success' } }
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    const authMiddleware = async (req, ctx, next) => {
      if (!req.headers.authorization) {
        return { status: 401, body: { error: 'Unauthorized' } }
      }
      return next()
    }

    const config = {
      name: 'ProtectedEndpoint',
      type: 'api',
      path: '/protected',
      method: 'GET',
      middleware: [authMiddleware]
    }

    const handler = async (req, ctx) => {
      return { status: 200, body: { message: 'Success' } }
    }

    module.exports = { config, handler }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    async def auth_middleware(req, context, next_fn):
        if not req.get("headers", {}).get("authorization"):
            return {"status": 401, "body": {"error": "Unauthorized"}}
        return await next_fn()

    config = {
        "name": "ProtectedEndpoint",
        "type": "api",
        "path": "/protected",
        "method": "GET",
        "middleware": [auth_middleware]
    }

    async def handler(req, context):
        return {"status": 200, "body": {"message": "Success"}}
    ```
  </Tab>
</Tabs>

---

## Execution Order

Middleware runs in the order you list them:

```typescript
export const config = {
  name: 'MyEndpoint',
  type: 'api',
  path: '/endpoint',
  method: 'POST',
  middleware: [
    loggingMiddleware,  // Runs first
    authMiddleware,     // Runs second  
    errorMiddleware     // Runs third
  ]
}
```

---

## Modifying Responses

Await `next()` to get the response, then modify it:

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    const addHeadersMiddleware = async (req, ctx, next) => {
      const response = await next()
      
      return {
        ...response,
        headers: {
          ...response.headers,
          'X-Request-Id': ctx.traceId
        }
      }
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    const addHeadersMiddleware = async (req, ctx, next) => {
      const response = await next()
      
      return {
        ...response,
        headers: {
          ...response.headers,
          'X-Request-Id': ctx.traceId
        }
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    async def add_headers_middleware(req, context, next_fn):
        response = await next_fn()
        
        headers = response.get("headers", {})
        headers["X-Request-Id"] = context.trace_id
        
        return {**response, "headers": headers}
    ```
  </Tab>
</Tabs>

---

## Passing Data to Handlers

Middleware can attach data to the `req` object, making it available to your handler. This is perfect for authenticationâ€”verify the user once in middleware, then use their details in the handler.

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    First, extend the request type in `api.d.ts`:

    ```typescript
    // api.d.ts
    import 'motia'

    declare module 'motia' {
      interface ApiRequest {
        user?: { id: string; role: string }
      }
    }
    ```

    Then attach the data in your middleware:

    ```typescript
    const authMiddleware: ApiMiddleware = async (req, ctx, next) => {
      // Verify token...
      req.user = { id: '123', role: 'admin' }
      return next()
    }
    ```

    Now use it in your handler:

    ```typescript
    export const handler = async (req, ctx) => {
      // req.user is typed and ready to use
      if (req.user?.role === 'admin') {
        return { status: 200, body: { message: 'Welcome Admin' } }
      }
      return { status: 403, body: { error: 'Forbidden' } }
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    Attach data to `req` in middleware:

    ```javascript
    const authMiddleware = async (req, ctx, next) => {
      req.user = { id: '123', role: 'admin' }
      return next()
    }
    ```

    Access it in your handler:

    ```javascript
    const handler = async (req, ctx) => {
      const { user } = req
      return { status: 200, body: { user } }
    }
    ```
  </Tab>
  <Tab value="Python">
    Add data to the `req` dictionary:

    ```python
    async def auth_middleware(req, context, next_fn):
        req["user"] = {"id": "123", "role": "admin"}
        return await next_fn()

    async def handler(req, context):
        user = req.get("user")
        return {"status": 200, "body": {"user": user}}
    ```
  </Tab>
</Tabs>

> **Learn more:** Check out the [Middleware Auth Handler Example](https://github.com/MotiaDev/motia-examples/tree/main/examples/middleware-auth-handler-example) to see a complete project with JWT validation and type safety.

---

## Error Handling

Catch errors from handlers:

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    import { ZodError } from 'zod'

    const errorMiddleware = async (req, ctx, next) => {
      try {
        return await next()
      } catch (error: any) {
        if (error instanceof ZodError) {
          ctx.logger.error('Validation error', { errors: error.errors })
          return { status: 400, body: { error: 'Validation failed' } }
        }

        ctx.logger.error('Unexpected error', { error: error.message })
        return { status: 500, body: { error: 'Internal server error' } }
      }
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript
    const { ZodError } = require('zod')

    const errorMiddleware = async (req, ctx, next) => {
      try {
        return await next()
      } catch (error) {
        if (error instanceof ZodError) {
          ctx.logger.error('Validation error', { errors: error.errors })
          return { status: 400, body: { error: 'Validation failed' } }
        }

        ctx.logger.error('Unexpected error', { error: error.message })
        return { status: 500, body: { error: 'Internal server error' } }
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    async def error_middleware(req, context, next_fn):
        try:
            return await next_fn()
        except ValidationError as e:
            context.logger.error("Validation error", {"errors": str(e)})
            return {"status": 400, "body": {"error": "Validation failed"}}
        except Exception as e:
            context.logger.error("Unexpected error", {"error": str(e)})
            return {"status": 500, "body": {"error": "Internal server error"}}
    ```
  </Tab>
</Tabs>

---

## Reusing Middleware

Create middleware files in a shared location:

```typescript title="middlewares/core.middleware.ts"
export const coreMiddleware = async (req, ctx, next) => {
  try {
    return await next()
  } catch (error) {
    ctx.logger.error('Error', { error })
    return { status: 500, body: { error: 'Internal server error' } }
  }
}
```

Import and use across steps:

```typescript title="steps/user.step.ts"
import { coreMiddleware } from '../middlewares/core.middleware'

export const config = {
  name: 'GetUser',
  type: 'api',
  path: '/users/:id',
  method: 'GET',
  middleware: [coreMiddleware]
}
```

---

## What's Next?

<Cards>
  <Card href="/docs/concepts/steps#triggers" title="Triggers">
    Learn more about Triggers
  </Card>
  
  <Card href="/docs/development-guide/testing" title="Testing">
    Learn more about testing your Motia Steps
  </Card>
</Cards>


-   [observability](/docs/development-guide/observability): Documentation for observability.
---
title: Observability
description: See what's happening in your Motia app with logging, tracing, and debugging
---

Your app is running. But what's actually happening inside?
- Is that API getting hit?
- Did the event emit?
- Why did that Step fail?
- Which user triggered this flow?

Motia gives you everything you need to answer these questions.

---

## Logging

Every Step has a `logger` in the context. Use it to see what's happening.

### Log Levels

| Level | When to use it |
| ----- | -------------- |
| `info` | Normal stuff - "User created", "Order processed" |
| `warn` | Something's weird but not broken - "High API usage", "Slow response" |
| `error` | Things broke - Failed API calls, exceptions, crashes |
| `debug` | Deep debugging - Raw data, internal state, timing info |

---

## How to Log

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value='TypeScript'>
    ```typescript
    export const handler: Handlers['ProcessOrder'] = async (input, { logger }) => {
      // Simple message
      logger.info('Processing order')

      // With context data
      logger.info('Order created', {
        orderId: input.id,
        total: input.total
      })

      // Errors
      try {
        await chargeCard(input.paymentMethod)
      } catch (error) {
        logger.error('Payment failed', {
          error: error.message,
          orderId: input.id
        })
      }

      // Warnings for unusual situations
      if (input.total > 1000) {
        logger.warn('Large order', {
          total: input.total,
          threshold: 1000
        })
      }

      // Debug info (only shows with --debug flag)
      logger.debug('Raw input', { input })
    }
    ```
  </Tab>
  <Tab value='Python'>
    ```python
    async def handler(input, context):
        # Simple message
        context.logger.info('Processing order')

        # With context data
        context.logger.info('Order created', {
            'order_id': input.get("id"),
            'total': input.get("total")
        })

        # Errors
        try:
            await charge_card(input.get("payment_method"))
        except Exception as error:
            context.logger.error('Payment failed', {
                'error': str(error),
                'order_id': input.get("id")
            })

        # Warnings for unusual situations
        if input.get("total", 0) > 1000:
            context.logger.warn('Large order', {
                'total': input.get("total"),
                'threshold': 1000
            })

        # Debug info (only shows with --debug flag)
        context.logger.debug('Raw input', {'input': input})
    ```
  </Tab>
  <Tab value='JavaScript'>
    ```javascript
    const handler = async (input, { logger }) => {
      // Simple message
      logger.info('Processing order')

      // With context data
      logger.info('Order created', {
        orderId: input.id,
        total: input.total
      })

      // Errors
      try {
        await chargeCard(input.paymentMethod)
      } catch (error) {
        logger.error('Payment failed', {
          error: error.message,
          orderId: input.id
        })
      }

      // Warnings for unusual situations
      if (input.total > 1000) {
        logger.warn('Large order', {
          total: input.total,
          threshold: 1000
        })
      }

      // Debug info (only shows with --debug flag)
      logger.debug('Raw input', { input })
    }
    ```
  </Tab>
</Tabs>

ðŸ‘‰ Always add context data to your logs. `{ orderId: '123' }` is way more useful than just a message.

---

## Where to See Logs

Start your app:

```bash
npm run dev
```

Logs appear in **two places**:

### 1. Your Terminal

See logs right where you ran `npm run dev`:

```
[INFO] Processing order { orderId: '123', total: 99.99 }
[INFO] Order created { orderId: '123' }
[INFO] Payment successful
```

### 2. Workbench

Open [http://localhost:3000](http://localhost:3000) and click on your flow. Logs show up in real-time with:
- Timestamps
- Which Step logged it
- The trace ID (to follow a request through the entire flow)
- Full context data

![Workbench Logs](./../img/build-your-first-app/ai-enrichment-logs.png)

---

## Tracing

Every request gets a unique `traceId`. This lets you follow a single request through your entire flow.

```typescript
export const handler: Handlers['CreateOrder'] = async (req, { logger, traceId }) => {
  logger.info('Order started', { traceId })
  
  // traceId stays the same across all Steps in this flow
  await emit({ 
    topic: 'process.payment', 
    data: { orderId: '123' } 
  })
  
  return { status: 200, body: { traceId } }
}
```

**In Workbench:**
- Click any log entry
- See all logs with the same `traceId`
- Follow the request from start to finish

---

## Debug Mode

Want more detailed logs?

```bash
npm run dev -- --debug
```

This enables `debug` level logs. You'll see everything - raw inputs, internal state, timing info.

**In production:** Don't use debug mode (it's slow and logs everything).

---

## Tips for Better Logs

### Use Objects, Not Strings

**Good:**
```typescript
logger.info('Payment processed', {
  paymentId: '123',
  amount: 100,
  status: 'success'
})
```

**Bad:**
```typescript
logger.info(`Payment 123 processed: amount=100`)
```

Why? Objects are searchable, filterable, and easier to parse.

### Track Performance

```typescript
export const handler: Handlers['ProcessOrder'] = async (input, { logger }) => {
  const start = performance.now()

  await processOrder(input)

  logger.info('Order processed', {
    duration: performance.now() - start,
    orderId: input.id
  })
}
```

### Log Errors Properly

```typescript
try {
  await riskyOperation()
} catch (error) {
  logger.error('Operation failed', {
    error: error.message,
    stack: error.stack,
    input: input.id  // Don't log sensitive data!
  })
  throw error  // Re-throw so Motia can retry
}
```

---

## Debugging Workflows

**Problem:** Something's not working, but where?

**Steps to debug:**

1. **Check terminal logs** - See which Steps ran
2. **Open Workbench** at [http://localhost:3000](http://localhost:3000)
3. **Click your flow** - See the visual diagram
4. **Expand logs panel** - See all logs in chronological order
5. **Click a log** - Filter by that `traceId` to follow the request
6. **Check each Step** - See where it failed

### Common Issues

**API not responding?**
- Check if the Step ran: Look for logs with your Step's name
- Check the response: Look for `status: 200` in logs

**Event not firing?**
- Check if `emit()` was called: Search logs for "emit"
- Check the topic name: Make sure it matches `subscribes: ['topic']`

**Step not running?**
- Check if it's discovered: Look for `[CREATED] Step` in startup logs
- Check the file name: Must contain `.step.` or `_step`

---

## Remember

- **Log everything important** - But not everything (no sensitive data!)
- **Use `traceId`** - Follow requests through your entire flow
- **Check Workbench** - Visual debugging is easier
- **Use objects** - Don't log strings, log objects
- **Debug mode** - Only for development, never in production

---


-   [plugins](/docs/development-guide/plugins): Documentation for plugins.
---
title: Plugins
description: Learn how to create and use plugins to extend Motia's functionality
---

import { Files, Folder, File } from 'fumadocs-ui/components/files';
import { Cards, Card } from 'fumadocs-ui/components/card';
import { Callout } from 'fumadocs-ui/components/callout';
import { Steps, Step } from 'fumadocs-ui/components/steps';

# Plugins

Plugins are a powerful way to extend Motia's functionality by adding custom features to the workbench, and integrating with external services.

## What are Plugins?

Plugins in Motia allow you to:

<Cards cols={2}>
  <Card title="Custom Workbench Tabs">Add custom tabs to the workbench interface</Card>
  <Card title="Specialized Visualizations">Create rich tooling tailored to your workflows</Card>
  <Card title="Service Integrations">Integrate with external services and APIs</Card>
  <Card title="Core Extensions">Extend Motia's core functionality with new capabilities</Card>
  <Card title="Reusable Modules">Share reusable functionality across projects</Card>
</Cards>

Motia comes with several official plugins like `plugin-logs`, `plugin-endpoint`, `plugin-observability`, and `plugin-states` that demonstrate the power and flexibility of the plugin system.

## Plugin Architecture

### Core Types

Plugins are built using three main TypeScript types:

#### MotiaPlugin

The main plugin configuration returned by your plugin function:

```typescript
type MotiaPlugin = {
  workbench: WorkbenchPlugin[]  // Array of workbench tab configurations
  dirname?: string              // Optional plugin directory
  steps?: string[]              // Optional custom steps
}
```

#### WorkbenchPlugin

Configuration for a workbench tab:

```typescript
type WorkbenchPlugin = {
  packageName: string           // Package registry name (e.g., '@motiadev/plugin-example')
  componentName?: string        // React component name to render
  label?: string                // Tab label text
  labelIcon?: string            // Icon name from lucide-react
  position?: 'bottom' | 'top'   // Tab position in workbench
  cssImports?: string[]         // CSS files to import
  props?: Record<string, any>   // Props passed to component
}
```

#### MotiaPluginContext

Context object provided to your plugin with access to Motia's internal APIs:

```typescript
type MotiaPluginContext = {
  printer: Printer              // Logging utilities
  state: StateAdapter           // State management
  lockedData: LockedData        // Thread-safe data access
  tracerFactory: TracerFactory  // Tracing functionality
  registerApi: (...)            // Register custom API endpoints
}
```

## Creating a Plugin

### Quick Start with CLI

<Steps>
  <Step title="Generate a plugin project">
    The fastest way to create a new plugin is using the Motia CLI:

    ```bash
    pnpm dlx motia create --plugin my-plugin
    ```
  </Step>
  <Step title="Install dependencies and build">
    After creation, set up and verify the build pipeline:

    ```bash
    cd my-plugin
    pnpm install
    pnpm run build
    ```
  </Step>
</Steps>

<Callout type="success" title="What the CLI template includes">
- TypeScript and React configuration
- Vite build setup
- Example workbench UI component
- Required dependencies pre-installed
- Ready-to-build project structure
</Callout>

### Manual Setup

If you prefer to set up manually or want to understand the structure, follow these steps:

<Steps>
  <Step title="Create project structure">
    Create a new directory for your plugin with the following structure:

    <Files>
      <Folder name="plugins" defaultOpen>
        <Folder name="plugin-example" defaultOpen>
          <Folder name="src" defaultOpen>
            <Folder name="components">
              <File name="example-page.tsx">Main UI component</File>
            </Folder>
            <File name="index.ts">Package entry point</File>
            <File name="plugin.ts">Plugin definition</File>
            <File name="styles.css">Tailwind styles</File>
          </Folder>
          <File name="package.json">Project metadata</File>
          <File name="tsconfig.json">TypeScript configuration</File>
          <File name="vite.config.ts">Vite build configuration</File>
          <File name="postcss.config.js">PostCSS configuration</File>
          <File name="README.md">Plugin documentation</File>
        </Folder>
      </Folder>
    </Files>
  </Step>
  <Step title="Configure package.json">
    Create a `package.json` with proper exports for both the main entry and plugin definition:

    ```json
    {
      "name": "@motiadev/plugin-example",
      "version": "0.8.2-beta.139",
      "type": "module",
      "main": "./dist/index.js",
      "types": "./dist/index.d.ts",
      "exports": {
        ".": {
          "types": "./dist/index.d.ts",
          "import": "./dist/index.js",
          "require": "./dist/index.cjs"
        },
        "./plugin": {
          "types": "./dist/plugin.d.ts",
          "import": "./dist/plugin.js",
          "require": "./dist/plugin.cjs"
        },
        "./styles.css": "./dist/styles.css"
      },
      "peerDependencies": {
        "@motiadev/ui": "workspace:*",
        "@motiadev/core": "workspace:*"
      }
    }
    ```
  </Step>
  <Step title="Define the plugin entry">
    Create `src/plugin.ts` to define your plugin:

    ```typescript
    import type { MotiaPlugin, MotiaPluginContext } from '@motiadev/core'

    export default function plugin(motia: MotiaPluginContext): MotiaPlugin {
      return {
        workbench: [
          {
            packageName: '@motiadev/plugin-example',
            cssImports: ['@motiadev/plugin-example/dist/plugin-example.css'],
            label: 'Example',
            position: 'bottom',
            componentName: 'ExamplePage',
            labelIcon: 'sparkles',
          },
        ],
      }
    }
    ```
  </Step>
  <Step title="Build the workbench component">
    Create your React component in `src/components/example-page.tsx`:

    ```typescript
    import { Badge, Button, Card } from '@motiadev/ui'
    import { Sparkles } from 'lucide-react'
    import type React from 'react'

    export const ExamplePage: React.FC = () => {
      return (
        <div className="h-full w-full p-6 overflow-auto">
          <div className="max-w-4xl mx-auto space-y-6">
            <div className="flex items-center gap-3">
              <Sparkles className="w-8 h-8 text-primary" />
              <h1 className="text-3xl font-bold">Example Plugin</h1>
              <Badge variant="info">v1.0.0</Badge>
            </div>

            <Card className="p-6">
              <h2 className="text-xl font-semibold mb-4">Welcome!</h2>
              <p className="text-muted-foreground">
                This is your custom plugin content.
              </p>
            </Card>
          </div>
        </div>
      )
    }
    ```
  </Step>
  <Step title="Export bundle entry points">
    Create `src/index.ts` to export your components:

    ```typescript
    import './styles.css'

    export { ExamplePage } from './components/example-page'
    ```
  </Step>
  <Step title="Add shared styles">
    Create `src/styles.css` to import Motia's UI styles:

    ```css
    @import "@motiadev/ui/globals.css";
    @import "tailwindcss";
    ```
  </Step>
  <Step title="Configure build tooling">
    **Vite configuration** â€” Create `vite.config.ts`:

    ```typescript
    import tailwindcss from '@tailwindcss/vite'
    import react from '@vitejs/plugin-react'
    import { resolve } from 'path'
    import { defineConfig } from 'vite'
    import dts from 'vite-plugin-dts'

    export default defineConfig({
      plugins: [react(), tailwindcss(), dts({ insertTypesEntry: true })],
      build: {
        lib: {
          entry: {
            index: resolve(__dirname, 'src/index.ts'),
            plugin: resolve(__dirname, 'src/plugin.ts'),
          },
          name: 'MotiaPluginExample',
          formats: ['es', 'cjs'],
          fileName: (format, entryName) => 
            `${entryName}.${format === 'es' ? 'js' : 'cjs'}`,
        },
        rollupOptions: {
          external: ['react', 'react-dom', '@motiadev/core', '@motiadev/ui'],
        },
        cssCodeSplit: false,
      },
    })
    ```

    **PostCSS configuration** â€” Create `postcss.config.js`:

    ```javascript
    export default {
      plugins: {
        '@tailwindcss/postcss': {},
      },
    }
    ```

    **TypeScript configuration** â€” Create `tsconfig.json`:

    ```json
    {
      "compilerOptions": {
        "target": "ES2020",
        "lib": ["ES2020", "DOM", "DOM.Iterable"],
        "module": "ESNext",
        "moduleResolution": "bundler",
        "jsx": "react-jsx",
        "strict": true,
        "declaration": true,
        "declarationMap": true,
        "sourceMap": true
      },
      "include": ["src"],
      "exclude": ["dist", "node_modules"]
    }
    ```
  </Step>
  <Step title="Add scripts and build">
    Add build scripts to your `package.json`:

    ```json
    {
      "scripts": {
        "build": "vite build",
        "dev": "vite build --watch",
        "clean": "rm -rf dist"
      }
    }
    ```

    Then run the build:

    ```bash
    pnpm run build
    ```
  </Step>
</Steps>

## Local Plugins

Local plugins provide a simpler alternative to creating full distributable packages when you want to add custom functionality specific to your project. Unlike publishable plugins, local plugins don't require building, packaging, or separate dependenciesâ€”they live directly in your project directory.

### When to Use Local Plugins

Local plugins are ideal for:

<Cards cols={2}>
  <Card title="Development & prototyping">Quickly test plugin ideas without the overhead of package setup.</Card>
  <Card title="Project-specific features">Ship custom functionality that only matters for your project.</Card>
  <Card title="Internal tooling">Build dashboards, monitors, or utilities tailored to your team.</Card>
  <Card title="Learning environment">Understand how plugins work before creating a distributable package.</Card>
</Cards>

### The `~/` Package Name Syntax

<Callout type="info" title="Local package resolution with ~/">
The `~/` prefix in `packageName` tells Motia to load components from your local project directory instead of `node_modules`:

```typescript
workbench: [
  {
    packageName: '~/plugins',  // Loads from <project-root>/plugins
    componentName: 'Plugin',
    // ...
  }
]
```

Motia resolves `~/` to your project root, so you can import components without publishing them as registry packages.
</Callout>

### Creating a Local Plugin

<Steps>
  <Step title="Prepare local directories">
    Create a simple structure in your project:

    <Files>
      <Folder name="playground" defaultOpen>
        <Folder name="plugins" defaultOpen>
          <File name="index.tsx">UI component export</File>
          <Folder name="plugin-api-example">
            <File name="api-example.api.step.ts">Optional plugin-specific steps</File>
          </Folder>
        </Folder>
        <File name="motia.config.ts">Plugin registration</File>
      </Folder>
    </Files>
  </Step>
  <Step title="Define your plugin function">
    In `motia.config.ts`, create a plugin function that returns the plugin configuration:

    ```typescript
    import path from 'node:path'
    import { config, type MotiaPlugin, type MotiaPluginContext } from '@motiadev/core'

    function localPluginExample(motia: MotiaPluginContext): MotiaPlugin {
      // Register custom API endpoint
      motia.registerApi(
        {
          method: 'GET',
          path: '/__motia/local-plugin-example',
        },
        async (req, ctx) => {
          return {
            status: 200,
            body: {
              message: 'Hello from Motia Plugin!',
              timestamp: new Date().toISOString(),
              environment: process.env.NODE_ENV || 'development',
              status: 'active',
            },
          }
        },
      )

      return {
        dirname: path.join(__dirname, 'plugins'),
        steps: ['**/*.step.ts', '**/*_step.py'],
        workbench: [
          {
            componentName: 'Plugin',
            packageName: '~/plugins',  // Load from local project
            label: 'Local Plugin Example',
            position: 'top',
            labelIcon: 'toy-brick',
          },
        ],
      }
    }

    export default config({
      plugins: [localPluginExample],
    })
    ```
  </Step>
  <Step title="Render the plugin UI">
    Create `plugins/index.tsx` with your component:

    ```typescript
    import { Badge, Button, cn } from '@motiadev/ui'
    import { AlertCircle, CheckCircle2, Clock, RefreshCw, Server } from 'lucide-react'
    import { useCallback, useEffect, useState } from 'react'

    interface PluginData {
      message: string
      timestamp: string
      environment: string
      status: 'active' | 'inactive'
    }

    export const Plugin = () => {
      const [data, setData] = useState<PluginData | null>(null)
      const [isLoading, setIsLoading] = useState(true)

      const fetchData = useCallback(async () => {
        setIsLoading(true)
        try {
          const response = await fetch('/__motia/local-plugin-example')
          const result = await response.json()
          setData(result)
        } catch (err) {
          console.error('Failed to fetch data:', err)
        } finally {
          setIsLoading(false)
        }
      }, [])

      useEffect(() => {
        fetchData()
      }, [fetchData])

      return (
        <div className="h-full flex flex-col p-4 gap-4">
          <div className="flex items-center justify-between border-b pb-4">
            <div className="flex items-center gap-3">
              <Server className="w-5 h-5 text-accent-1000" />
              <h1 className="text-xl font-semibold">Local Plugin Example</h1>
            </div>
            <Button onClick={fetchData} disabled={isLoading}>
              <RefreshCw className={cn('w-4 h-4', isLoading && 'animate-spin')} />
              Refresh
            </Button>
          </div>
          
          {data && (
            <div className="space-y-4">
              <div className="p-4 rounded-lg border bg-card">
                <Badge variant={data.status === 'active' ? 'default' : 'secondary'}>
                  {data.status}
                </Badge>
                <p className="text-2xl font-semibold mt-2">{data.message}</p>
              </div>
            </div>
          )}
        </div>
      )
    }
    ```
  </Step>
</Steps>

### Including Custom Steps

<Callout type="default" title="Include custom steps">
Local plugins can also include custom steps by specifying a `dirname` and `steps` pattern:

```typescript
return {
  dirname: path.join(__dirname, 'plugins'),
  steps: ['**/*.step.ts', '**/*_step.py'],
  workbench: [/* ... */],
}
```

This loads API routes, event handlers, and other step types directly from the plugin directory.
</Callout>

### Best Practices for Local Plugins

<Cards cols={2}>
  <Card title="Keep components simple">Use Motia UI components directly without extra build tooling.</Card>
  <Card title="Use TypeScript">Leverage type safety and IDE support without extra declaration files.</Card>
  <Card title="Organize by feature">Group related components and steps inside meaningful folders.</Card>
  <Card title="Reuse dependencies">Rely on packages already present in your project workspace.</Card>
  <Card title="Document your APIs">Add clear comments for every custom endpoint and interface.</Card>
</Cards>

### When to Migrate to NPM Plugin

<Callout type="warning" title="When to publish as a distributable package">
- You want to share it across multiple projects
- It provides general-purpose functionality
- You need versioning and dependency management
- The plugin is stable and well-tested
</Callout>

## Using Plugins

### Installing a Plugin

<Steps>
  <Step title="Install the plugin package">

    ```bash
    pnpm add @motiadev/plugin-example
    ```
  </Step>
  <Step title="Register it in motia.config.ts">

    ```typescript
    import examplePlugin from '@motiadev/plugin-example/plugin'

    export default {
      plugins: [examplePlugin],
    }
    ```
  </Step>
</Steps>

### Configuring Multiple Plugins

<Callout type="default" title="Configure multiple plugins">

```typescript
import logsPlugin from '@motiadev/plugin-logs/plugin'
import endpointPlugin from '@motiadev/plugin-endpoint/plugin'
import examplePlugin from '@motiadev/plugin-example/plugin'

export default {
  plugins: [
    logsPlugin,
    endpointPlugin,
    examplePlugin,
  ],
}
```

</Callout>
### Registering Custom APIs

<Callout type="info" title="Register custom APIs">
Use the `registerApi` method from the plugin context:

```typescript
import { MotiaPlugin } from './app-config-types'
export default function plugin(motia: MotiaPluginContext): MotiaPlugin {
  // Register a custom API endpoint
  motia.registerApi(
    {
      method: 'GET',
      path: '/api/my-endpoint',
    },
    async (req, res) => {
      return res.json({ message: 'Hello from plugin!' })
    }
  )

  return {
    workbench: [/* ... */],
  }
}
```
</Callout>

## Example Plugin

<Callout type="success" title="Example plugin reference">
A complete minimal example plugin lives at `plugins/plugin-example` in the Motia repository. It demonstrates:

- Basic plugin structure
- Workbench tab integration
- UI component creation
- Build configuration
- TypeScript setup

Use it as a starting point for your own plugins.
</Callout>

## Troubleshooting

<Callout type="warning" title="Plugin not showing in workbench">
- Check that the plugin is imported in `motia.config.ts`
- Verify the `componentName` matches your exported component
- Ensure the plugin is built (`pnpm run build`)
- Check browser console for errors
</Callout>

<Callout type="warning" title="Styles not loading">
- Verify CSS is imported in `src/index.ts`
- Check that `styles.css` is exported in `package.json`
- Ensure TailwindCSS is properly configured
- Confirm that `cssImports` is defined in `src/plugin.ts` with the path to the built CSS file (e.g., `['@motiadev/plugin-example/dist/plugin-example.css']`)
</Callout>

<Callout type="default" title="Resolving type errors">
- Make sure `@motiadev/core` and `@motiadev/ui` are listed in `peerDependencies`
- Run `pnpm install` so TypeScript picks up the types
- Confirm `declaration: true` is set in `tsconfig.json`
</Callout>

## Next Steps

- Explore the [plugin-logs source code](https://github.com/motiadev/motia/tree/main/plugins/plugin-logs) for a complete example


-   [project-structure](/docs/development-guide/project-structure): Documentation for project-structure.
---
title: Project Structure
description: Learn about Motia's project structure, file organization, and automatic step discovery system for building scalable workflow applications.
---

# Project Structure

Understanding how to organize your Motia project is crucial for building maintainable and scalable workflow applications. This guide covers the directory structure, file naming conventions, and Motia's automatic step discovery system.

## Basic Project Structure

Here's what a typical Motia project looks like:

<Folder name="my-motia-project" defaultOpen>
  <Folder name="steps" defaultOpen>
    <File name="api-gateway.step.ts" />
    <File name="data-processor_step.py" />  
    <File name="send-notification.step.js" />
    <File name="send-notification.tsx" />
  </Folder>
  <File name="package.json" />
  <File name="requirements.txt" />
  <File name="tsconfig.json" />
  <File name="types.d.ts" />
  <File name="motia-workbench.json" />
  <File name="config.yml" />
</Folder>

### File Descriptions

| File | Purpose | Type | Auto-Generated |
|------|---------|------|----------------|
| `01-api-gateway.step.ts` | TypeScript API endpoint | User Code | - |
| `02-data-processor_step.py` | Python data processing | User Code | - |
| `03-send-notification.step.js` | JavaScript automation | User Code | - |
| `send-notification.tsx` | Optional [UI override component](/docs/development-guide/customizing-flows) | User Code | - |
| `package.json` | Node.js dependencies (if using JS/TS) | Config | - |
| `requirements.txt` | Python dependencies (if using Python) | Config | - |
| `tsconfig.json` | TypeScript config (if using TypeScript) | Config | - |
| `types.d.ts` | **Type definitions for your project** | **Generated** | **âœ… By TypeScript** |
| `motia-workbench.json` | **ðŸ¤– Visual workflow positioning** | **Generated** | **âœ… By Motia** |
| `config.yml` | Optional Motia configuration | Config | - |

<Callout type="info">
The `steps/` and `src/` directories are the heart of your Motia application - this is where all your workflow logic lives. Motia automatically discovers and registers any file following the naming pattern from both directories.
</Callout>

<Callout>
<strong>Location and nesting rules</strong>

- Both the `steps/` and `src/` directories are supported at the <em>project root</em> (e.g., `my-motia-project/steps` or `my-motia-project/src`).
- You can freely nest steps in subfolders under either directory (e.g., `steps/aaa/a1.step.ts`, `src/bbb/ccc/c1_step.py`).
- Discovery is recursive inside both directories, so deeper folder structures for large apps are supported.
- You can use either `steps/`, `src/`, or both directories in your project.
</Callout>

## Automatic Step Discovery

<Callout type="default">
**Key Concept: Automatic Discovery** 

Motia will automatically discover and register **any file** that follows the `.step.` naming pattern as a workflow step. You don't need to manually register steps - just create a file with the right naming pattern and Motia will find it.
</Callout>

### Discovery Rules

Motia scans your `steps/` and `src/` directories and automatically registers files as steps based on these rules:

1. **File must contain `.step.` or `_step.` in the filename** (e.g., `my-task.step.ts`, `my_task_step.py`)
2. **File must export a `config` object** defining the step configuration
3. **File must export a `handler` function** containing the step logic
4. **File extension determines the runtime** (`.ts` = TypeScript, `.py` = Python, `.js` = JavaScript)

When you run `motia dev`, Motia will:
- Scan both the `steps/` and `src/` directories recursively
- Find all files matching `*.step.*` in both directories
- Parse their `config` exports to understand step types and connections
- Register them in the workflow engine
- Make them available in the Workbench

## File Naming Convention

Motia uses this specific pattern for automatic step discovery:

```
[prefix-]descriptive-name.step.[extension]
```

<Callout type="warning">
The `.step.` part in the filename is **required** - this is how Motia identifies which files are workflow steps during automatic discovery.
</Callout>

### Supported Languages & Extensions

| Language | Extension | Example Step File | Runtime |
|----------|-----------|-------------------|---------|
| **TypeScript** | `.ts` | `user-registration.step.ts` | Node.js with TypeScript |
| **Python** | `.py` | `data-analysis_step.py` | Python interpreter |
| **JavaScript** | `.js` | `send-notification.step.js` | Node.js |

### Naming Examples by Step Type

| Step Type | TypeScript | Python | JavaScript |
|-----------|------------|---------|-----------|
| **API Endpoint** | `01-auth-api.step.ts` | `01-auth-api_step.py` or `auth_api_step.py` | `01-auth-api.step.js` |
| **Event Handler** | `process-order.step.ts` | `process-order_step.py` or `process_order_step.py` | `process-order.step.js` |
| **Cron Job** | `daily-report.step.ts` | `daily-report_step.py` or `daily_report_step.py` | `daily-report.step.js` |
| **Data Processing** | `transform-data.step.ts` | `ml-analysis_step.py` or `ml_analysis_step.py` | `data-cleanup.step.js` |

## Step Organization Patterns

<Tabs items={["Sequential", "Feature-Based", "Language-Specific"]}>
<Tab value="Sequential">

### Sequential Flow Organization
Perfect for linear workflows where order matters:

<Folder name="steps" defaultOpen>
  <File name="01-api-start.step.ts" />
  <File name="02-validate-data_step.py" />
  <File name="03-process-payment.step.js" />
  <File name="04-send-confirmation.step.ts" />
  <File name="05-cleanup_step.py" />
</Folder>

| Step | Language | Purpose |
|------|----------|---------|
| `01-api-start.step.ts` | TypeScript | API endpoint |
| `02-validate-data_step.py` | Python | Data validation |
| `03-process-payment.step.js` | JavaScript | Payment processing |
| `04-send-confirmation.step.ts` | TypeScript | Email service |
| `05-cleanup_step.py` | Python | Cleanup tasks |

</Tab>
<Tab value="Feature-Based">

### Feature-Based Organization
Organize by business domains for complex applications:

<Folder name="steps" defaultOpen>
  <Folder name="authentication" defaultOpen>
    <File name="login.step.ts" />
    <File name="verify-token_step.py" />
    <File name="logout.step.js" />
  </Folder>
  <Folder name="payment" defaultOpen>
    <File name="process-payment.step.ts" />
    <File name="fraud-detection_step.py" />
    <File name="webhook.step.js" />
  </Folder>
  <Folder name="notification" defaultOpen>
    <File name="email_step.py" />
    <File name="sms.step.js" />
    <File name="push.step.ts" />
  </Folder>
</Folder>

**Benefits:**
- Logical grouping by business domain
- Easy to locate related functionality
- Team ownership by feature area
- Independent scaling and deployment

</Tab>
<Tab value="Language-Specific">

### Language-Specific Organization
Group by programming language for team specialization:

<Folder name="steps" defaultOpen>
  <Folder name="typescript" defaultOpen>
    <File name="api-gateway.step.ts" />
    <File name="user-management.step.ts" />
    <File name="data-validation.step.ts" />
  </Folder>
  <Folder name="python" defaultOpen>
    <File name="ml-processing_step.py" />
    <File name="data-analysis_step.py" />
    <File name="image-processing_step.py" />
  </Folder>
  <Folder name="javascript" defaultOpen>
    <File name="automation.step.js" />
    <File name="webhook-handlers.step.js" />
    <File name="integrations.step.js" />
  </Folder>
</Folder>

**Benefits:**
- Team specialization by language
- Consistent tooling and patterns
- Easy onboarding for language experts
- Shared libraries and utilities

</Tab>
</Tabs>

## Language-Specific Configuration

### TypeScript/JavaScript Projects

For Node.js-based steps, you'll need:

```json title="package.json"
{
  "name": "my-motia-app",
  "version": "1.0.0",
  "scripts": {
    "dev": "motia dev",
    "build": "motia build",
    "start": "motia start"
  },
  "dependencies": {
    "motia": "^0.5.12-beta.121",
    "zod": "^3.24.4"
  },
  "devDependencies": {
    "typescript": "^5.7.3",
    "@types/node": "^20.0.0"
  }
}
```

```json title="tsconfig.json (for TypeScript)"
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "moduleResolution": "Node",
    "esModuleInterop": true,
    "strict": true,
    "skipLibCheck": true
  },
  "include": ["**/*.ts", "**/*.tsx"],
  "exclude": ["node_modules", "dist"]
}
```

### Python Projects

For Python-based steps:

```text title="requirements.txt"
# Core Motia dependency
motia>=0.5.12

# Common dependencies
requests>=2.28.0
pydantic>=1.10.0

# Data processing (if needed)
pandas>=1.5.0
numpy>=1.21.0
```

## Step Discovery Examples

Let's see how Motia discovers different step types:

### Example 1: TypeScript API Step

```typescript title="steps/user-api.step.ts"
import { ApiRouteConfig, Handlers } from 'motia'
import { z } from 'zod'

// Motia discovers this file because:
// 1. Filename contains '.step.'
// 2. Exports 'config' object
// 3. Has .ts extension -> uses TypeScript runtime
export const config: ApiRouteConfig = {
  type: 'api',
  name: 'user-api',
  path: '/users',
  method: 'GET',
  emits: ['users.fetched'],
  flows: ['user-management']
}

export const handler: Handlers['user-api'] = async (req, { emit }) => {
  await emit({
    topic: 'users.fetched', 
    data: { users: [] }
  })
  
  return {
    status: 200,
    body: { message: 'Users retrieved' }
  }
}
```

### Example 2: Python Event Step

```python title="steps/data-processor_step.py"
# Motia discovers this file because:
# 1. Filename contains '.step.'  
# 2. Exports 'config' dict
# 3. Has .py extension -> uses Python runtime

config = {
    "type": "event",
    "name": "data-processor",
    "description": "Process incoming data with Python",
    "subscribes": ["users.fetched"],
    "emits": ["data.processed"],
    "flows": ["user-management"]
}

async def handler(input_data, ctx):
    """Process the data"""
    processed_data = {
        "original": input_data,
        "processed_at": ctx.utils.dates.now().isoformat(),
        "count": len(input_data.get("users", []))
    }
    
    await ctx.emit({
        "topic": "data.processed",
        "data": processed_data
    })
```

### Example 3: JavaScript Automation Step

```javascript title="steps/send-notifications.step.js"
// Motia discovers this file because:
// 1. Filename contains '.step.'
// 2. Exports 'config' object  
// 3. Has .js extension -> uses Node.js runtime

export const config = {
  type: 'event',
  name: 'send-notifications',
  description: 'Send notifications via multiple channels',
  subscribes: ['data.processed'],
  emits: ['notifications.sent'],
  flows: ['user-management']
}

export const handler = async (input, { emit, logger }) => {
  logger.info('Sending notifications', { data: input })
  
  // Send email, SMS, push notifications, etc.
  const results = await Promise.all([
    sendEmail(input),
    sendSMS(input),
    sendPush(input)
  ])
  
  await emit({
    topic: 'notifications.sent',
    data: { 
      results,
      sent_at: new Date().toISOString() 
    }
  })
}

async function sendEmail(data) { /* implementation */ }
async function sendSMS(data) { /* implementation */ }  
async function sendPush(data) { /* implementation */ }
```

## Auto-Generated Files

Some files in your Motia project are automatically generated:

- `types.d.ts` - TypeScript generates this for type definitions
- `motia-workbench.json` - Motia manages visual node positions in the Workbench

## Discovery Troubleshooting

If Motia isn't discovering your steps:

### Common Issues

<Tabs items={["Filename Issues", "Export Issues", "Location Issues"]}>
<Tab value="Filename Issues">

**Missing `.step.` (or `_step` for Python) in filename**

<div className="grid grid-cols-1 md:grid-cols-2 gap-4">
<div>
âŒ **Won't be discovered:**
<Folder name="steps" defaultOpen>
  <File name="user-handler.ts" />
  <File name="data-processor.py" />
  <File name="webhook.js" />
</Folder>
</div>
<div>
âœ… **Will be discovered:**
<Folder name="steps" defaultOpen>
  <File name="user-handler.step.ts" />
  <File name="data-processor_step.py" />
  <File name="webhook.step.js" />
</Folder>
</div>
</div>

</Tab>
<Tab value="Export Issues">

**Missing config export**

```typescript title="âŒ Won't be discovered"
// No config export
export const handler = async () => {
  console.log('This won't be found by Motia')
}
```

```typescript title="âœ… Will be discovered"
// Proper exports
export const config = {
  type: 'event',
  name: 'my-step',
  subscribes: ['my-topic'],
  emits: ['my-output'],
  flows: ['my-flow']
}

export const handler = async (input, ctx) => {
  // Motia will discover and register this step
}
```

</Tab>
<Tab value="Location Issues">

**File outside steps/ or src/ directory**

<div className="grid grid-cols-1 md:grid-cols-2 gap-4">
<div>
âŒ **Won't be discovered:**
<Folder name="project-root" defaultOpen>
  <Folder name="lib">
    <File name="user-handler.step.ts" />
  </Folder>
  <Folder name="components">
    <File name="processor_step.py" />
  </Folder>
</Folder>
</div>
<div>
âœ… **Will be discovered:**
<Folder name="project-root" defaultOpen>
  <Folder name="steps" defaultOpen>
    <File name="user-handler.step.ts" />
  </Folder>
  <Folder name="src" defaultOpen>
    <File name="processor_step.py" />
  </Folder>
</Folder>
</div>
</div>

Note: Both `steps/` and `src/` directories are supported. Files must be in one of these directories to be discovered.

</Tab>
</Tabs>

### Discovery Verification

Check if your steps are discovered:

```bash
# Run Motia in development mode
motia dev

# Look step creation in your console console:
âžœ [CREATED] Step (Cron) steps/petstore/state-audit-cron.step.ts created
âžœ [CREATED] Step (Event) steps/petstore/process-food-order.step.ts created
âžœ [CREATED] Step (Event) steps/petstore/notification.step.ts created
âžœ [CREATED] Step (API) steps/petstore/api.step.ts created
```

## Next Steps

Now that you understand how Motia discovers and organizes steps:

- Learn about [Core Concepts](/docs/concepts) to understand how steps work together
- Explore [Defining Steps](/docs/concepts/steps) for detailed step creation
- Check out [Triggers](/docs/concepts/steps#triggers) for API, Event, and Cron steps

-   [state-management](/docs/development-guide/state-management): Documentation for state-management.
---
title: State Management
description: Persistent Key-Value storage that works across Triggers, Steps, and Functions
---

State is persistent key-value storage that works across all your Triggers, Steps, and Functions. Set data in one Trigger, read it in another. Works across TypeScript, Python, and JavaScript.

## How It Works

State organizes data into **groups**. Each group can hold multiple items with unique keys.

Think of it like folders and files:
- **groupId** = A folder name (like `orders`, `users`, `cache`)
- **key** = A file name inside that folder
- **value** = The actual data

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
export const handler: Handlers['MyStep'] = async (input, { state }) => {
  // Store an item in a group
  await state.set('orders', 'order-123', { 
    id: 'order-123',
    status: 'pending',
    total: 99.99 
  })
  
  // Get a specific item
  const order = await state.get('orders', 'order-123')
  
  // Get all items in a group
  const allOrders = await state.getGroup('orders')
  
  // Delete a specific item
  await state.delete('orders', 'order-123')
  
  // Clear entire group
  await state.clear('orders')
}
```

</Tab>
<Tab value='Python'>

```python
async def handler(input, context):
    # Store an item in a group
    await context.state.set("orders", "order-123", {
        "id": "order-123",
        "status": "pending",
        "total": 99.99
    })
    
    # Get a specific item
    order = await context.state.get("orders", "order-123")
    
    # Get all items in a group
    all_orders = await context.state.get_group("orders")
    
    # Delete a specific item
    await context.state.delete("orders", "order-123")
    
    # Clear entire group
    await context.state.clear("orders")
  ```

  </Tab>
<Tab value='JavaScript'>
    
  ```javascript
const handler = async (input, { state }) => {
  // Store an item in a group
  await state.set('orders', 'order-123', { 
    id: 'order-123',
    status: 'pending',
    total: 99.99 
  })
  
  // Get a specific item
  const order = await state.get('orders', 'order-123')
  
  // Get all items in a group
  const allOrders = await state.getGroup('orders')
  
  // Delete a specific item
  await state.delete('orders', 'order-123')
  
  // Clear entire group
  await state.clear('orders')
  }
  ```

  </Tab>
</Tabs>

---

## State Methods

| Method | What it does |
|--------|--------------|
| `state.set(groupId, key, value)` | Store an item in a group |
| `state.get(groupId, key)` | Get a specific item (returns `null` if not found) |
| `state.getGroup(groupId)` | Get all items in a group as an array |
| `state.delete(groupId, key)` | Remove a specific item |
| `state.clear(groupId)` | Remove all items in a group |

---

## Real-World Example

Let's build an order processing workflow that uses state across multiple Steps.

**Step 1 - API receives order:**

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
export const handler: Handlers['CreateOrder'] = async (req, { state, emit, logger }) => {
  const orderId = crypto.randomUUID()
  
  const order = {
    id: orderId,
    items: req.body.items,
    total: req.body.total,
    status: 'pending',
    createdAt: new Date().toISOString()
  }
  
  // Store in state
  await state.set('orders', orderId, order)
  
  logger.info('Order created', { orderId })
  
  // Trigger processing
  await emit({ 
    topic: 'order.created', 
    data: { orderId } 
  })
  
  return { status: 201, body: order }
}
```

  </Tab>
<Tab value='Python'>

```python
import uuid
from datetime import datetime

async def handler(req, context):
    order_id = str(uuid.uuid4())
    
    order = {
        "id": order_id,
        "items": req.get("body", {}).get("items"),
        "total": req.get("body", {}).get("total"),
        "status": "pending",
        "created_at": datetime.now().isoformat()
    }
    
    # Store in state
    await context.state.set("orders", order_id, order)
    
    context.logger.info("Order created", {"orderId": order_id})
    
    # Trigger processing
    await context.emit({
        "topic": "order.created",
        "data": {"orderId": order_id}
    })
    
    return {"status": 201, "body": order}
  ```

  </Tab>
<Tab value='JavaScript'>
    
  ```javascript
const handler = async (req, { state, emit, logger }) => {
  const orderId = crypto.randomUUID()
  
  const order = {
    id: orderId,
    items: req.body.items,
    total: req.body.total,
    status: 'pending',
    createdAt: new Date().toISOString()
  }
  
  // Store in state
  await state.set('orders', orderId, order)
  
  logger.info('Order created', { orderId })
  
  // Trigger processing
  await emit({ 
    topic: 'order.created', 
    data: { orderId } 
  })
  
  return { status: 201, body: order }
}
  ```

  </Tab>
</Tabs>

**Step 2 - Process payment:**

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>
    
  ```typescript
export const handler: Handlers['ProcessPayment'] = async (input, { state, emit, logger }) => {
  const { orderId } = input
  
  // Get order from state
  const order = await state.get('orders', orderId)
  
  if (!order) {
    throw new Error(`Order ${orderId} not found`)
  }
  
  // Update status
  order.status = 'paid'
  await state.set('orders', orderId, order)
  
  logger.info('Payment processed', { orderId })
  
  await emit({ 
    topic: 'payment.completed', 
    data: { orderId } 
  })
}
  ```

  </Tab>
<Tab value='Python'>

```python
async def handler(input, context):
    order_id = input.get("orderId")
    
    # Get order from state
    order = await context.state.get("orders", order_id)
    
    if not order:
        raise Exception(f"Order {order_id} not found")
    
    # Update status
    order["status"] = "paid"
    await context.state.set("orders", order_id, order)
    
    context.logger.info("Payment processed", {"orderId": order_id})
    
    await context.emit({
        "topic": "payment.completed",
        "data": {"orderId": order_id}
    })
```

</Tab>
<Tab value='JavaScript'>

```javascript
const handler = async (input, { state, emit, logger }) => {
  const { orderId } = input
  
  // Get order from state
  const order = await state.get('orders', orderId)
  
  if (!order) {
    throw new Error(`Order ${orderId} not found`)
  }
  
  // Update status
  order.status = 'paid'
  await state.set('orders', orderId, order)
  
  logger.info('Payment processed', { orderId })
  
  await emit({ 
    topic: 'payment.completed', 
    data: { orderId } 
  })
}
  ```

  </Tab>
</Tabs>

**Step 3 - View all orders (Cron job):**

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>
      
  ```typescript
export const handler: Handlers['DailyReport'] = async ({ state, logger }) => {
  // Get all orders
  const allOrders = await state.getGroup<Order>('orders')
  
  const pending = allOrders.filter(o => o.status === 'pending')
  const paid = allOrders.filter(o => o.status === 'paid')
  
  logger.info('Daily order report', {
    total: allOrders.length,
    pending: pending.length,
    paid: paid.length
  })
}
```

  </Tab>
<Tab value='Python'>

```python
async def handler(context):
    # Get all orders
    all_orders = await context.state.get_group("orders")
    
    pending = [o for o in all_orders if o.get("status") == "pending"]
    paid = [o for o in all_orders if o.get("status") == "paid"]
    
    context.logger.info("Daily order report", {
        "total": len(all_orders),
        "pending": len(pending),
        "paid": len(paid)
    })
```

</Tab>
<Tab value='JavaScript'>
    
  ```javascript
const handler = async ({ state, logger }) => {
  // Get all orders
  const allOrders = await state.getGroup('orders')
  
  const pending = allOrders.filter(o => o.status === 'pending')
  const paid = allOrders.filter(o => o.status === 'paid')
  
  logger.info('Daily order report', {
    total: allOrders.length,
    pending: pending.length,
    paid: paid.length
  })
}
```

  </Tab>
</Tabs>

---

## When to Use State

**âœ… Good use cases:**
- **Temporary workflow data** - Data that's only needed during a flow execution
- **API response caching** - Cache expensive API calls that don't change often
- **Sharing data between Steps** - Pass data between Steps without emitting it in events
- **Building up results** - Accumulate data across multiple Steps

**âŒ Better alternatives:**
- **Persistent user data** - Use a database like Postgres or MongoDB
- **File storage** - Use S3 or similar for images, PDFs, documents
- **Real-time updates** - Use Motia Streams for live data to clients
- **Large datasets** - Use a proper database, not state

---

### State Adapters

State adapters control where and how state is stored. Motia provides default adapters that work out of the box, and distributed adapters for production deployments.

#### Default Adapter (File Storage)

No setup needed. State goes to `.motia/motia.state.json`.

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'

export default config({
  // Uses FileStateAdapter by default
  // State stored in .motia/motia.state.json
})
```

<Callout type="info">
The default FileStateAdapter is perfect for single-instance deployments, development, and testing. No configuration needed!
</Callout>

#### Distributed Adapter (Redis)

For production deployments with multiple Motia instances, use Redis to share state across instances:

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'

export default config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
    }),
  },
})
```

<Callout type="warn">
Use distributed adapters (like Redis) when running multiple Motia instances. Without them, each instance has isolated state that isn't shared.
</Callout>

**Your Step code stays the same:**

```typescript
// Works with both file and Redis adapters
export const handler: Handlers['MyStep'] = async (req, { state }) => {
  await state.set('orders', 'order-123', { id: 'order-123' })
  const order = await state.get('orders', 'order-123')
  // ... rest of your code
}
```

The adapter handles the storage backend - your application code doesn't change.

[Learn more about adapters â†’](/docs/development-guide/adapters)

---

## Remember

- Organize data using **groupId** (like `orders`, `users`, `cache`)
- Each item needs a unique **key** within its groupId
- Use `getGroup(groupId)` to retrieve all items in a group
- State works the same across TypeScript, Python, and JavaScript
- Clean up state when you're done with it
- Use databases for permanent data, state for temporary workflow data

---


-   [streams](/docs/development-guide/streams): Documentation for streams.
---
title: Real-time Streams 
description: Push live updates from your backend to connected clients without polling. Perfect for AI responses, chat apps, and long-running tasks.
---

## Why Streams?

Building modern apps means dealing with long-running tasks - AI responses that stream in word by word, file processing that takes time, or chat messages that need to appear instantly.

Without Streams, you'd need to:
- Build polling logic on the frontend
- Set up WebSocket infrastructure manually
- Manage connection states and reconnection
- Handle data synchronization yourself

With Motia Streams, you get all of this out of the box. Just define what data you want to stream, and Motia handles the rest.

## Some Use Cases for Streams

- **AI/LLM responses** â†’ Stream ChatGPT responses as they generate
- **Chat applications** â†’ Real-time messaging and typing indicators
- **Long processes** â†’ Video processing, data exports, batch operations
- **Live dashboards** â†’ Real-time metrics and notifications
- **Collaborative tools** â†’ Real-time updates across multiple users

---

## Creating a Stream

Streams are just files. Create a `.stream.ts` file in your `steps/` folder and export a config.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript title="steps/chat-messages.stream.ts"
import { StreamConfig } from 'motia'
import { z } from 'zod'

export const config: StreamConfig = {
  name: 'chatMessage',
  schema: z.object({
    id: z.string(),
    userId: z.string(),
    message: z.string(),
    timestamp: z.string()
  }),
  baseConfig: {
    storageType: 'default'
  }
}
```

</Tab>
<Tab value='Python'>

```python title="steps/chat_messages_stream.py"
from pydantic import BaseModel

class ChatMessage(BaseModel):
    id: str
    user_id: str
    message: str
    timestamp: str

config = {
    "name": "chatMessage",
    "schema": ChatMessage.model_json_schema(),
    "baseConfig": {"storageType": "default"}
}
```

</Tab>
<Tab value='JavaScript'>

```javascript title="steps/chat-messages.stream.js"
const config = {
  name: 'chatMessage',
  schema: {
    type: 'object',
    properties: {
      id: { type: 'string' },
      userId: { type: 'string' },
      message: { type: 'string' },
      timestamp: { type: 'string' }
    },
    required: ['id', 'userId', 'message', 'timestamp']
  },
  baseConfig: {
    storageType: 'default'
  }
}

module.exports = { config }
```

</Tab>
</Tabs>

ðŸ‘‰ That's it. Motia auto-discovers the stream and makes it available as `context.streams.chatMessage` in all your handlers.

---

## Using Streams in Steps

Once you've defined a stream, you can use it in any Step through `context.streams`.

### Stream Methods

Every stream has these methods:

| Method | What it does |
|--------|-------------|
| `set(groupId, id, data)` | Create or update an item |
| `get(groupId, id)` | Get a single item |
| `delete(groupId, id)` | Remove an item |
| `getGroup(groupId)` | Get all items in a group |
| `send(channel, event)` | Send ephemeral events (typing, reactions, etc.) |

**Think of it like this:**
- `groupId` = Which room/conversation/user
- `id` = Which specific item in that room
- `data` = The actual data matching your schema

---

## Real Example: Todo App with Real-Time Sync

Let's build a todo app where all connected clients see updates instantly.

<Callout type="info">
  This is a real, working example from the [Motia Examples Repository](https://github.com/MotiaDev/motia-examples/tree/main/examples/realtime-todo-app). You can clone it and run it locally!
</Callout>

**Step 1:** Create the stream definition

```typescript title="steps/todo.stream.ts"
import { StreamConfig } from 'motia'
import { z } from 'zod'

const todoSchema = z.object({
  id: z.string(),
  description: z.string(),
  createdAt: z.string(),
  dueDate: z.string().optional(),
  completedAt: z.string().optional()
})

export const config: StreamConfig = {
  name: 'todo',
  schema: todoSchema,
  baseConfig: { storageType: 'default' }
}

export type Todo = z.infer<typeof todoSchema>
```

**Step 2:** Create an API endpoint that uses streams

```typescript title="steps/create-todo.step.ts"
import { ApiRouteConfig, Handlers } from 'motia'
import { z } from 'zod'
import { Todo } from './todo.stream'

export const config: ApiRouteConfig = {
  type: 'api',
  name: 'CreateTodo',
  method: 'POST',
  path: '/todo',
  bodySchema: z.object({
    description: z.string(),
    dueDate: z.string().optional()
  }),
  responseSchema: {
    200: z.object({
      id: z.string(),
      description: z.string(),
      createdAt: z.string(),
      dueDate: z.string().optional(),
      completedAt: z.string().optional()
    }),
    400: z.object({ error: z.string() })
  },
  emits: []
}

export const handler: Handlers['CreateTodo'] = async (req, { logger, streams }) => {
  logger.info('Creating new todo', { body: req.body })

  const { description, dueDate } = req.body
  const todoId = `todo-${Date.now()}-${Math.random().toString(36).substring(2, 9)}`

  if (!description) {
    return { status: 400, body: { error: 'Description is required' } }
  }

  const newTodo: Todo = {
    id: todoId,
    description,
    createdAt: new Date().toISOString(),
    dueDate,
    completedAt: undefined
  }

  // Store in the 'inbox' group - all clients watching this group see the update!
  const todo = await streams.todo.set('inbox', todoId, newTodo)

  logger.info('Todo created successfully', { todoId })

  return { status: 200, body: todo }
}
```

**What happens here:**
1. Client calls `POST /todo` with a description
2. Server creates the todo and calls `streams.todo.set('inbox', todoId, newTodo)`
3. **Instantly**, all clients subscribed to the `inbox` group receive the new todo
4. No polling, no refresh needed

ðŸ‘‰ Every time you call `streams.todo.set()`, connected clients receive the update instantly. No polling needed.

---

## Testing Streams in Workbench

Testing real-time features can be tricky. Workbench makes it easy.

**How to test:**

1. Make sure your API Step returns the stream object:

```typescript
return { status: 200, body: todo } // result from streams.todo.set()
```

2. Open [http://localhost:3000/endpoints](http://localhost:3000/endpoints)
3. Watch the stream update in real-time

![Stream Test in Workbench](./../img/todo-workbench.png)

ðŸ‘‰ Workbench automatically detects stream responses and subscribes to them for you.

---

## Using Streams in Your Frontend

Once you have streams working on the backend, connect them to your React app.

### Install

```bash
npm install @motiadev/stream-client-react
```

### Setup Provider

Wrap your app with the provider:

```tsx title="App.tsx"
import { MotiaStreamProvider } from '@motiadev/stream-client-react'

function App() {
  return (
    <MotiaStreamProvider address="ws://localhost:3000">
      {/* Your app */}
    </MotiaStreamProvider>
  )
}
```

### Subscribe to Stream Updates

```tsx title="App.tsx"
import { useStreamGroup } from '@motiadev/stream-client-react'
import { useTodoEndpoints, type Todo } from './hook/useTodoEndpoints'

function App() {
  const { createTodo, updateTodo, deleteTodo } = useTodoEndpoints()
  
  // Subscribe to all todos in the 'inbox' group
  const { data: todos } = useStreamGroup<Todo>({ 
    groupId: 'inbox', 
    streamName: 'todo' 
  })

  const handleAddTodo = async (description: string) => {
    await createTodo(description)
    // No need to manually update UI - stream does it automatically!
  }

  return (
    <div>
      <h1>Inbox</h1>
      {todos.map((todo) => (
        <div key={todo.id}>{todo.description}</div>
      ))}
    </div>
  )
}
```

**How it works:**
1. `useStreamGroup()` subscribes to all items in the `inbox` group
2. When server calls `streams.todo.set('inbox', todoId, newTodo)`, the `todos` array updates automatically
3. React re-renders with the new data
4. Works across all connected clients!

![Todo App in React](./../img/todo-react.png)

ðŸ‘‰ Every time you call `createTodo()`, connected clients receive the update instantly. No polling needed.

---

## Ephemeral Events

Sometimes you need to send temporary events that don't need to be stored - like typing indicators, reactions, or online status.

Use `streams.<name>.send()` for this:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```typescript
// Send typing indicator
await streams.chatMessage.send(
  { groupId: channelId }, // No id = broadcasts to all subscribers in group
  { type: 'typing', data: { userId: 'user-123', isTyping: true } }
)

// Send reaction to specific message
await streams.chatMessage.send(
  { groupId: channelId, id: messageId }, // With id = only subscribers to this item get it
  { type: 'reaction', data: { emoji: 'ðŸ‘', userId: 'user-123' } }
)
```

</Tab>
<Tab value='Python'>

```python
# Send typing indicator
await context.streams.chatMessage.send(
    {"groupId": channel_id},  # No id = broadcasts to all subscribers in group
    {"type": "typing", "data": {"userId": "user-123", "isTyping": True}}
)

# Send reaction to specific message
await context.streams.chatMessage.send(
    {"groupId": channel_id, "id": message_id},  # With id = only subscribers to this item get it
    {"type": "reaction", "data": {"emoji": "ðŸ‘", "userId": "user-123"}}
)
```

</Tab>
<Tab value='JavaScript'>

```javascript
// Send typing indicator
await streams.chatMessage.send(
  { groupId: channelId }, // No id = broadcasts to all subscribers in group
  { type: 'typing', data: { userId: 'user-123', isTyping: true } }
)

// Send reaction to specific message
await streams.chatMessage.send(
  { groupId: channelId, id: messageId }, // With id = only subscribers to this item get it
  { type: 'reaction', data: { emoji: 'ðŸ‘', userId: 'user-123' } }
)
```

</Tab>
</Tabs>

**Difference from `set()`:**
- `set()` â†’ Stores data, clients sync to it
- `send()` â†’ Fire-and-forget events, not stored

---

## Stream Adapters

Stream adapters control where and how stream data is stored. Motia provides default adapters that work out of the box, and distributed adapters for production deployments with multiple instances.

### Default Adapter (File Storage)

No setup needed. Streams are stored in `.motia/streams/` directory.

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'

export default config({
  // Uses FileStreamAdapter by default
  // Streams stored in .motia/streams/
})
```

<Callout type="info">
The default FileStreamAdapter is perfect for single-instance deployments, development, and testing. Real-time updates work seamlessly within a single instance.
</Callout>

### Distributed Adapter (Redis)

For production deployments with multiple Motia instances, use Redis to synchronize streams across instances. This ensures all connected clients receive updates regardless of which instance handles the request:

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisStreamAdapter } from '@motiadev/adapter-redis-streams'

export default config({
  adapters: {
    streams: new RedisStreamAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
    }),
  },
})
```

<Callout type="warn">
Use distributed stream adapters (like Redis) when running multiple Motia instances. Without them, stream updates are only visible to clients connected to the instance that created them.
</Callout>

**Your Step code stays the same:**

```typescript
// Works with both file and Redis adapters
export const handler: Handlers['Chat'] = async (req, { streams }) => {
  await streams.messages.set('chat-123', 'msg-1', {
    content: 'Hello!',
    userId: 'user-1',
    timestamp: Date.now(),
  })
  // ... rest of your code
}
```

The adapter handles the storage backend and synchronization - your application code doesn't change. All connected clients receive updates in real-time, regardless of which instance processes the request.

[Learn more about adapters â†’](/docs/development-guide/adapters)

---

## Remember

- **Streams = Real-time state** that clients subscribe to
- **Every `set()` call** pushes updates to connected clients instantly
- **Use `send()`** for temporary events like typing indicators
- **Test in Workbench** before building your frontend
- **No polling needed** - WebSocket connection handles everything

---

## What's Next?

<Cards>
  <Card href="/docs/development-guide/state-management" title="ðŸ“¦ State Management">
    Learn about persistent storage across Steps
  </Card>
  
  <Card href="/docs/concepts/steps" title="ðŸ”„ Steps">
    Deep dive into building with Steps
  </Card>
</Cards>

-   [testing](/docs/development-guide/testing): Documentation for testing.
---
title: Testing
description: Test your Motia Backend System - APIs, Events
---

You built an API. You added some event handlers. Everything seems to work. But does it?

Without tests, you're guessing. With tests, you know.

Motia has `@motiadev/test` built in. It helps you:
- Test API triggers (hit endpoints, check responses)
- Test Event triggers (verify events get emitted)
- Mock contexts for unit tests

---

## Install
```bash
npm install @motiadev/test --save-dev
```

```bash
pnpm add @motiadev/test --save-dev
```

---

## Test API Triggers

Here's an API Step that creates a todo and emits an event:

```typescript title="steps/create-todo.step.ts"
export const config: ApiRouteConfig = {
  type: 'api',
  name: 'CreateTodo',
  path: '/todo',
  method: 'POST',
  emits: ['todo.created'],
  bodySchema: z.object({ description: z.string() })
}

export const handler: Handlers['CreateTodo'] = async (req, { emit }) => {
  const todo = { id: '123', description: req.body.description }
  
  await emit({ topic: 'todo.created', data: todo })
  
  return { status: 200, body: todo }
}
```

Now let's test it:

```typescript title="steps/create-todo.step.test.ts"
import { createMotiaTester } from '@motiadev/test'
import { describe, it, expect, afterAll } from 'vitest'

describe('CreateTodo', () => {
  const tester = createMotiaTester()

  afterAll(async () => {
    await tester.close()
  })

  it('should create a todo and return 200', async () => {
    const response = await tester.post('/todo', {
      body: { description: 'Buy milk' }
    })

    expect(response.status).toBe(200)
    expect(response.body).toMatchObject({
      id: expect.any(String),
      description: 'Buy milk'
    })
  })

  it('should emit todo.created event', async () => {
    const watcher = await tester.watch('todo.created')

    await tester.post('/todo', {
      body: { description: 'Buy bread' }
    })

    await tester.waitEvents()

    const events = watcher.getCapturedEvents()
    expect(events).toHaveLength(1)
    expect(events[0].data).toMatchObject({
      description: 'Buy bread'
    })
  })
})
```

**What's happening here:**
- `createMotiaTester()` â†’ Spins up a test version of your app
- `tester.post()` â†’ Hits your API like a real client would
- `tester.watch()` â†’ Captures events that get emitted
- `tester.waitEvents()` â†’ Waits for all async stuff to finish
- Then check if everything worked

---

## Test Event Triggers

Event Steps listen for events and do stuff in the background. Here's how to test them:

```typescript title="steps/process-todo.step.ts"
export const config: EventConfig = {
  type: 'event',
  name: 'ProcessTodo',
  subscribes: ['todo.created'],
  emits: ['todo.processed'],
  input: z.object({ id: z.string(), description: z.string() })
}

export const handler: Handlers['ProcessTodo'] = async (input, { emit, logger }) => {
  logger.info('Processing todo', { id: input.id })
  
  // Do some processing
  const processed = { ...input, processed: true }
  
  await emit({ topic: 'todo.processed', data: processed })
}
```

**The Test:**

```typescript title="steps/process-todo.step.test.ts"
import { createMotiaTester } from '@motiadev/test'
import { describe, it, expect, afterAll } from 'vitest'

describe('ProcessTodo', () => {
  const tester = createMotiaTester()

  afterAll(async () => {
    await tester.close()
  })

  it('should process todo when todo.created is emitted', async () => {
    const watcher = await tester.watch('todo.processed')

    // Manually emit the event that triggers the step
    await tester.emit({
      topic: 'todo.created',
      data: { id: '123', description: 'Test todo' },
      traceId: 'test-trace'
    })

    await tester.waitEvents()

    const events = watcher.getCapturedEvents()
    expect(events).toHaveLength(1)
    expect(events[0].data).toMatchObject({
      id: '123',
      description: 'Test todo',
      processed: true
    })
  })
})
```

ðŸ‘‰ Use `tester.emit()` to manually fire events and test Event triggers without hitting APIs.

---

## Unit Test Handlers

Don't want to spin up the whole app? Test handler functions directly:

```typescript title="steps/calculate-total.step.test.ts"
import { createMockContext } from '@motiadev/test'
import { handler } from './calculate-total.step'
import { describe, it, expect } from 'vitest'

describe('CalculateTotal Handler', () => {
  it('should calculate total correctly', async () => {
    const mockContext = createMockContext()
    
    const input = { items: [{ price: 10 }, { price: 20 }] }
    
    await handler(input, mockContext)
    
    expect(mockContext.emit).toHaveBeenCalledWith({
      topic: 'total.calculated',
      data: { total: 30 }
    })
  })

  it('should log calculation', async () => {
    const mockContext = createMockContext()
    
    await handler({ items: [] }, mockContext)
    
    expect(mockContext.logger.info).toHaveBeenCalledWith(
      expect.stringContaining('Calculating total')
    )
  })
})
```

---

## Run Your Tests

**All tests:**

```bash
npm test
```

```bash
pnpm test
```

**Watch mode** (re-runs when you save files):

```bash
npm test -- --watch
```

```bash
pnpm test --watch
```

**Single test file:**

```bash
npm test -- steps/create-todo.step.test.ts
```

---

## Tester API

### `createMotiaTester()`

Starts a test version of your app.

```typescript
const tester = createMotiaTester()
```

**What you can do with it:**

| Method | What it does |
|--------|-------------|
| `post(path, options)` | Hit a POST endpoint |
| `get(path, options)` | Hit a GET endpoint |
| `emit(event)` | Fire an event manually |
| `watch(topic)` | Catch events on a topic |
| `waitEvents()` | Wait for events to finish |
| `sleep(ms)` | Pause for X milliseconds |
| `close()` | Shut down the tester |

### `createMockContext()`

Mock a context for testing handlers directly.

```typescript
const mockContext = createMockContext({
  logger: customLogger,  // optional
  emit: customEmit,      // optional
  traceId: 'custom-id'   // optional
})
```

**You get:**
- `logger` - Mock logger (Jest spy)
- `emit` - Mock emit (Jest spy)
- `traceId` - Request trace ID
- `state` - Mock state manager

---

## Tips

- âœ… **Start simple** - Test basic stuff first, then edge cases
- âœ… **Test errors** - Make sure your error handling actually works
- âœ… **Watch events** - Don't assume events fired, check them
- âœ… **Always wait** - Call `waitEvents()` or events might not finish
- âœ… **Clean up** - Always `close()` the tester when done
- âœ… **Keep it isolated** - Each test should work on its own
- âœ… **Name tests well** - Say what you're checking, not how

---


-   [adapter-configuration](/docs/examples/adapter-configuration): Documentation for adapter-configuration.
---
title: 'Adapter Configuration'
description: 'Configure distributed adapters for horizontal scaling in production'
---

This guide shows you how to configure distributed adapters for Motia to enable horizontal scaling and production-ready deployments. We'll cover setting up Redis and RabbitMQ adapters for state, streams, events, and cron.

## Why Distributed Adapters?

By default, Motia uses file-based and in-memory adapters that work great for single-instance deployments. However, when you need to:

- Run multiple Motia instances
- Scale horizontally
- Share state/events/streams across instances
- Deploy to production with high availability

You need distributed adapters that use shared infrastructure like Redis or RabbitMQ.

---

## Quick Setup

### 1. Install Adapter Packages

```bash
npm install @motiadev/adapter-redis-state \
            @motiadev/adapter-redis-streams \
            @motiadev/adapter-rabbitmq-events \
            @motiadev/adapter-redis-cron
```

### 2. Configure Adapters

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'
import { RedisStreamAdapterManager } from '@motiadev/adapter-redis-streams'
import { RabbitMQEventAdapter } from '@motiadev/adapter-rabbitmq-events'
import { RedisCronAdapter } from '@motiadev/adapter-redis-cron'

export default config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
    }),
    streams: new RedisStreamAdapterManager({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
    }),
    events: new RabbitMQEventAdapter({
      url: process.env.RABBITMQ_URL || 'amqp://localhost:5672',
      exchangeName: process.env.RABBITMQ_EXCHANGE || 'motia.events',
      exchangeType: 'topic',
    }),
    cron: new RedisCronAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
    }),
  },
})
```

---

## Configuration Options

Each adapter supports additional configuration options for production use:

### Redis State Adapter

```typescript title="motia.config.ts"
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'

export default config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
      password: process.env.REDIS_PASSWORD,
      username: process.env.REDIS_USERNAME,
      database: parseInt(process.env.REDIS_DATABASE || '0'),
      keyPrefix: process.env.STATE_KEY_PREFIX || 'motia:state:',
      ttl: parseInt(process.env.STATE_TTL || '3600'),
      socket: {
        connectTimeout: 10000,
        reconnectStrategy: (retries) => {
          if (retries > 20) {
            return new Error('Too many retries')
          }
          return Math.min(retries * 50, 2000)
        },
      },
    }),
  },
})
```

**Configuration Options:**

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `host` | `string` | `'localhost'` | Redis server host |
| `port` | `number` | `6379` | Redis server port |
| `password` | `string` | `undefined` | Redis authentication password |
| `username` | `string` | `undefined` | Redis authentication username |
| `database` | `number` | `0` | Redis database number |
| `keyPrefix` | `string` | `'motia:state:'` | Prefix for all state keys |
| `ttl` | `number` | `undefined` | Time-to-live in seconds for state entries |
| `socket.reconnectStrategy` | `function` | Auto-retry | Custom reconnection strategy |
| `socket.connectTimeout` | `number` | `10000` | Connection timeout in milliseconds |

### Redis Stream Adapter

```typescript title="motia.config.ts"
import { RedisStreamAdapterManager } from '@motiadev/adapter-redis-streams'

export default config({
  adapters: {
    streams: new RedisStreamAdapterManager({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
      password: process.env.REDIS_PASSWORD,
      username: process.env.REDIS_USERNAME,
      database: parseInt(process.env.REDIS_DATABASE || '0'),
      keyPrefix: process.env.STREAM_KEY_PREFIX || 'motia:stream:',
      socket: {
        connectTimeout: 10000,
        reconnectStrategy: (retries) => {
          if (retries > 20) {
            return new Error('Too many retries')
          }
          return Math.min(retries * 50, 2000)
        },
      },
    }),
  },
})
```

**Configuration Options:**

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `host` | `string` | `'localhost'` | Redis server host |
| `port` | `number` | `6379` | Redis server port |
| `password` | `string` | `undefined` | Redis authentication password |
| `username` | `string` | `undefined` | Redis authentication username |
| `database` | `number` | `0` | Redis database number |
| `keyPrefix` | `string` | `'motia:stream:'` | Prefix for all stream keys |
| `socket.reconnectStrategy` | `function` | Auto-retry | Custom reconnection strategy |
| `socket.connectTimeout` | `number` | `10000` | Connection timeout in milliseconds |

### RabbitMQ Event Adapter

```typescript title="motia.config.ts"
import { RabbitMQEventAdapter } from '@motiadev/adapter-rabbitmq-events'

export default config({
  adapters: {
    events: new RabbitMQEventAdapter({
      url: process.env.RABBITMQ_URL || 'amqp://localhost:5672',
      exchangeName: process.env.RABBITMQ_EXCHANGE || 'motia.events',
      exchangeType: 'topic',
      durable: true,
      autoDelete: false,
      connectionTimeout: 10000,
      reconnectDelay: 5000,
      prefetch: 10,
    }),
  },
})
```

**Configuration Options:**

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `url` | `string` | Required | RabbitMQ connection URL (e.g., `amqp://localhost`) |
| `exchangeName` | `string` | Required | Name of the exchange to use |
| `exchangeType` | `'direct' \| 'topic' \| 'fanout' \| 'headers'` | Required | Type of exchange |
| `durable` | `boolean` | `true` | Whether the exchange should survive broker restarts |
| `autoDelete` | `boolean` | `false` | Whether to delete the exchange when all queues are unbound |
| `connectionTimeout` | `number` | `10000` | Connection timeout in milliseconds |
| `reconnectDelay` | `number` | `5000` | Delay before attempting reconnection in milliseconds |
| `prefetch` | `number` | `10` | Number of messages to prefetch |

### Redis Cron Adapter

```typescript title="motia.config.ts"
import { RedisCronAdapter } from '@motiadev/adapter-redis-cron'

export default config({
  adapters: {
    cron: new RedisCronAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
      password: process.env.REDIS_PASSWORD,
      username: process.env.REDIS_USERNAME,
      database: parseInt(process.env.REDIS_DATABASE || '0'),
      keyPrefix: process.env.CRON_KEY_PREFIX || 'motia:cron:lock:',
      lockTTL: parseInt(process.env.CRON_LOCK_TTL || '300000'),
      lockRetryDelay: 1000,
      lockRetryAttempts: 0,
      instanceId: process.env.INSTANCE_ID,
      enableHealthCheck: true,
      socket: {
        connectTimeout: 10000,
        reconnectStrategy: (retries) => {
          if (retries > 20) {
            return new Error('Too many retries')
          }
          return Math.min(retries * 50, 2000)
        },
      },
    }),
  },
})
```

**Configuration Options:**

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `host` | `string` | `'localhost'` | Redis server host |
| `port` | `number` | `6379` | Redis server port |
| `password` | `string` | `undefined` | Redis authentication password |
| `username` | `string` | `undefined` | Redis authentication username |
| `database` | `number` | `0` | Redis database number |
| `keyPrefix` | `string` | `'motia:cron:lock:'` | Prefix for all lock keys |
| `lockTTL` | `number` | `300000` | Lock time-to-live in milliseconds (5 minutes) |
| `lockRetryDelay` | `number` | `1000` | Delay between lock retry attempts in milliseconds |
| `lockRetryAttempts` | `number` | `0` | Number of times to retry acquiring a lock |
| `instanceId` | `string` | Auto-generated UUID | Unique identifier for this instance |
| `enableHealthCheck` | `boolean` | `true` | Whether to perform periodic health checks |
| `socket.reconnectStrategy` | `function` | Auto-retry | Custom reconnection strategy |
| `socket.connectTimeout` | `number` | `10000` | Connection timeout in milliseconds |

---

## Docker Compose Setup

For local development and production, use Docker Compose to run Redis and RabbitMQ:

```yaml title="docker-compose.yml"
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes

  rabbitmq:
    image: rabbitmq:3-management-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq

volumes:
  redis-data:
  rabbitmq-data:
```

Start the services:

```bash
docker-compose up -d
```

---

## Partial Adapter Configuration

You don't need to configure all adapters. Mix and match based on your needs:

### Only State Adapter

If you only need shared state across instances:

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'

export default config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: 6379,
    }),
    // Streams, events, and cron use defaults
  },
})
```

### Only Event Adapter

If you only need distributed events:

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RabbitMQEventAdapter } from '@motiadev/adapter-rabbitmq-events'

export default config({
  adapters: {
    events: new RabbitMQEventAdapter({
      url: process.env.RABBITMQ_URL || 'amqp://localhost:5672',
      exchangeName: process.env.RABBITMQ_EXCHANGE || 'motia.events',
      exchangeType: 'topic',
    }),
    // State, streams, and cron use defaults
  },
})
```

---

## Production Deployment

### Scaling Multiple Instances

With distributed adapters, you can run multiple Motia instances:

```yaml title="docker-compose.yml"
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  rabbitmq:
    image: rabbitmq:3-management-alpine
    ports:
      - "5672:5672"

  motia-1:
    build: .
    ports:
      - "3000:3000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - RABBITMQ_URL=amqp://rabbitmq:5672
    depends_on:
      - redis
      - rabbitmq

  motia-2:
    build: .
    ports:
      - "3001:3000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - RABBITMQ_URL=amqp://rabbitmq:5672
    depends_on:
      - redis
      - rabbitmq

  motia-3:
    build: .
    ports:
      - "3002:3000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - RABBITMQ_URL=amqp://rabbitmq:5672
    depends_on:
      - redis
      - rabbitmq
```

All instances share the same state, events, and streams.

### Cloud Provider Configuration

For cloud deployments, use managed services:

**AWS ElastiCache (Redis):**
```typescript
state: new RedisStateAdapter({
  host: process.env.REDIS_HOST, // ElastiCache endpoint
  port: 6379,
  password: process.env.REDIS_PASSWORD,
})
```

**CloudAMQP (RabbitMQ):**
```typescript
events: new RabbitMQEventAdapter({
  url: process.env.CLOUDAMQP_URL, // CloudAMQP connection string
  exchangeName: process.env.RABBITMQ_EXCHANGE || 'motia.events',
  exchangeType: 'topic',
})
```

---

## Testing Adapter Configuration

Your application code doesn't change when switching adapters. Test with defaults first:

```typescript
// This works with both file and Redis adapters
export const handler: Handlers['MyStep'] = async (req, { state, streams, emit }) => {
  await state.set('orders', 'order-123', { id: 'order-123' })
  await streams.messages.set('chat-123', 'msg-1', { text: 'Hello' })
  await emit({ topic: 'order.created', data: { orderId: '123' } })
}
```

Then switch to distributed adapters for production without changing your code.

---

## What's Next?

<Cards>
  <Card href="/docs/development-guide/adapters/usage" title="ðŸ“– Using Adapters">
    Learn more about using adapters in your application
  </Card>
  
  <Card href="/docs/development-guide/adapters/creating-adapters" title="ðŸ”§ Creating Adapters">
    Build custom adapters for your infrastructure
  </Card>
  
  <Card href="/docs/deployment-guide/self-hosted" title="ðŸš€ Deployment Guide">
    Learn about deploying Motia to production
  </Card>
</Cards>




## Examples
[adapter-configuration](/docs/examples/adapter-configuration): Code example
---
title: 'Adapter Configuration'
description: 'Configure distributed adapters for horizontal scaling in production'
---

This guide shows you how to configure distributed adapters for Motia to enable horizontal scaling and production-ready deployments. We'll cover setting up Redis and RabbitMQ adapters for state, streams, events, and cron.

## Why Distributed Adapters?

By default, Motia uses file-based and in-memory adapters that work great for single-instance deployments. However, when you need to:

- Run multiple Motia instances
- Scale horizontally
- Share state/events/streams across instances
- Deploy to production with high availability

You need distributed adapters that use shared infrastructure like Redis or RabbitMQ.

---

## Quick Setup

### 1. Install Adapter Packages

```bash
npm install @motiadev/adapter-redis-state \
            @motiadev/adapter-redis-streams \
            @motiadev/adapter-rabbitmq-events \
            @motiadev/adapter-redis-cron
```

### 2. Configure Adapters

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'
import { RedisStreamAdapterManager } from '@motiadev/adapter-redis-streams'
import { RabbitMQEventAdapter } from '@motiadev/adapter-rabbitmq-events'
import { RedisCronAdapter } from '@motiadev/adapter-redis-cron'

export default config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
    }),
    streams: new RedisStreamAdapterManager({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
    }),
    events: new RabbitMQEventAdapter({
      url: process.env.RABBITMQ_URL || 'amqp://localhost:5672',
      exchangeName: process.env.RABBITMQ_EXCHANGE || 'motia.events',
      exchangeType: 'topic',
    }),
    cron: new RedisCronAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
    }),
  },
})
```

---

## Configuration Options

Each adapter supports additional configuration options for production use:

### Redis State Adapter

```typescript title="motia.config.ts"
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'

export default config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
      password: process.env.REDIS_PASSWORD,
      username: process.env.REDIS_USERNAME,
      database: parseInt(process.env.REDIS_DATABASE || '0'),
      keyPrefix: process.env.STATE_KEY_PREFIX || 'motia:state:',
      ttl: parseInt(process.env.STATE_TTL || '3600'),
      socket: {
        connectTimeout: 10000,
        reconnectStrategy: (retries) => {
          if (retries > 20) {
            return new Error('Too many retries')
          }
          return Math.min(retries * 50, 2000)
        },
      },
    }),
  },
})
```

**Configuration Options:**

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `host` | `string` | `'localhost'` | Redis server host |
| `port` | `number` | `6379` | Redis server port |
| `password` | `string` | `undefined` | Redis authentication password |
| `username` | `string` | `undefined` | Redis authentication username |
| `database` | `number` | `0` | Redis database number |
| `keyPrefix` | `string` | `'motia:state:'` | Prefix for all state keys |
| `ttl` | `number` | `undefined` | Time-to-live in seconds for state entries |
| `socket.reconnectStrategy` | `function` | Auto-retry | Custom reconnection strategy |
| `socket.connectTimeout` | `number` | `10000` | Connection timeout in milliseconds |

### Redis Stream Adapter

```typescript title="motia.config.ts"
import { RedisStreamAdapterManager } from '@motiadev/adapter-redis-streams'

export default config({
  adapters: {
    streams: new RedisStreamAdapterManager({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
      password: process.env.REDIS_PASSWORD,
      username: process.env.REDIS_USERNAME,
      database: parseInt(process.env.REDIS_DATABASE || '0'),
      keyPrefix: process.env.STREAM_KEY_PREFIX || 'motia:stream:',
      socket: {
        connectTimeout: 10000,
        reconnectStrategy: (retries) => {
          if (retries > 20) {
            return new Error('Too many retries')
          }
          return Math.min(retries * 50, 2000)
        },
      },
    }),
  },
})
```

**Configuration Options:**

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `host` | `string` | `'localhost'` | Redis server host |
| `port` | `number` | `6379` | Redis server port |
| `password` | `string` | `undefined` | Redis authentication password |
| `username` | `string` | `undefined` | Redis authentication username |
| `database` | `number` | `0` | Redis database number |
| `keyPrefix` | `string` | `'motia:stream:'` | Prefix for all stream keys |
| `socket.reconnectStrategy` | `function` | Auto-retry | Custom reconnection strategy |
| `socket.connectTimeout` | `number` | `10000` | Connection timeout in milliseconds |

### RabbitMQ Event Adapter

```typescript title="motia.config.ts"
import { RabbitMQEventAdapter } from '@motiadev/adapter-rabbitmq-events'

export default config({
  adapters: {
    events: new RabbitMQEventAdapter({
      url: process.env.RABBITMQ_URL || 'amqp://localhost:5672',
      exchangeName: process.env.RABBITMQ_EXCHANGE || 'motia.events',
      exchangeType: 'topic',
      durable: true,
      autoDelete: false,
      connectionTimeout: 10000,
      reconnectDelay: 5000,
      prefetch: 10,
    }),
  },
})
```

**Configuration Options:**

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `url` | `string` | Required | RabbitMQ connection URL (e.g., `amqp://localhost`) |
| `exchangeName` | `string` | Required | Name of the exchange to use |
| `exchangeType` | `'direct' \| 'topic' \| 'fanout' \| 'headers'` | Required | Type of exchange |
| `durable` | `boolean` | `true` | Whether the exchange should survive broker restarts |
| `autoDelete` | `boolean` | `false` | Whether to delete the exchange when all queues are unbound |
| `connectionTimeout` | `number` | `10000` | Connection timeout in milliseconds |
| `reconnectDelay` | `number` | `5000` | Delay before attempting reconnection in milliseconds |
| `prefetch` | `number` | `10` | Number of messages to prefetch |

### Redis Cron Adapter

```typescript title="motia.config.ts"
import { RedisCronAdapter } from '@motiadev/adapter-redis-cron'

export default config({
  adapters: {
    cron: new RedisCronAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: parseInt(process.env.REDIS_PORT || '6379'),
      password: process.env.REDIS_PASSWORD,
      username: process.env.REDIS_USERNAME,
      database: parseInt(process.env.REDIS_DATABASE || '0'),
      keyPrefix: process.env.CRON_KEY_PREFIX || 'motia:cron:lock:',
      lockTTL: parseInt(process.env.CRON_LOCK_TTL || '300000'),
      lockRetryDelay: 1000,
      lockRetryAttempts: 0,
      instanceId: process.env.INSTANCE_ID,
      enableHealthCheck: true,
      socket: {
        connectTimeout: 10000,
        reconnectStrategy: (retries) => {
          if (retries > 20) {
            return new Error('Too many retries')
          }
          return Math.min(retries * 50, 2000)
        },
      },
    }),
  },
})
```

**Configuration Options:**

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `host` | `string` | `'localhost'` | Redis server host |
| `port` | `number` | `6379` | Redis server port |
| `password` | `string` | `undefined` | Redis authentication password |
| `username` | `string` | `undefined` | Redis authentication username |
| `database` | `number` | `0` | Redis database number |
| `keyPrefix` | `string` | `'motia:cron:lock:'` | Prefix for all lock keys |
| `lockTTL` | `number` | `300000` | Lock time-to-live in milliseconds (5 minutes) |
| `lockRetryDelay` | `number` | `1000` | Delay between lock retry attempts in milliseconds |
| `lockRetryAttempts` | `number` | `0` | Number of times to retry acquiring a lock |
| `instanceId` | `string` | Auto-generated UUID | Unique identifier for this instance |
| `enableHealthCheck` | `boolean` | `true` | Whether to perform periodic health checks |
| `socket.reconnectStrategy` | `function` | Auto-retry | Custom reconnection strategy |
| `socket.connectTimeout` | `number` | `10000` | Connection timeout in milliseconds |

---

## Docker Compose Setup

For local development and production, use Docker Compose to run Redis and RabbitMQ:

```yaml title="docker-compose.yml"
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes

  rabbitmq:
    image: rabbitmq:3-management-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq

volumes:
  redis-data:
  rabbitmq-data:
```

Start the services:

```bash
docker-compose up -d
```

---

## Partial Adapter Configuration

You don't need to configure all adapters. Mix and match based on your needs:

### Only State Adapter

If you only need shared state across instances:

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RedisStateAdapter } from '@motiadev/adapter-redis-state'

export default config({
  adapters: {
    state: new RedisStateAdapter({
      host: process.env.REDIS_HOST || 'localhost',
      port: 6379,
    }),
    // Streams, events, and cron use defaults
  },
})
```

### Only Event Adapter

If you only need distributed events:

```typescript title="motia.config.ts"
import { config } from '@motiadev/core'
import { RabbitMQEventAdapter } from '@motiadev/adapter-rabbitmq-events'

export default config({
  adapters: {
    events: new RabbitMQEventAdapter({
      url: process.env.RABBITMQ_URL || 'amqp://localhost:5672',
      exchangeName: process.env.RABBITMQ_EXCHANGE || 'motia.events',
      exchangeType: 'topic',
    }),
    // State, streams, and cron use defaults
  },
})
```

---

## Production Deployment

### Scaling Multiple Instances

With distributed adapters, you can run multiple Motia instances:

```yaml title="docker-compose.yml"
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  rabbitmq:
    image: rabbitmq:3-management-alpine
    ports:
      - "5672:5672"

  motia-1:
    build: .
    ports:
      - "3000:3000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - RABBITMQ_URL=amqp://rabbitmq:5672
    depends_on:
      - redis
      - rabbitmq

  motia-2:
    build: .
    ports:
      - "3001:3000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - RABBITMQ_URL=amqp://rabbitmq:5672
    depends_on:
      - redis
      - rabbitmq

  motia-3:
    build: .
    ports:
      - "3002:3000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - RABBITMQ_URL=amqp://rabbitmq:5672
    depends_on:
      - redis
      - rabbitmq
```

All instances share the same state, events, and streams.

### Cloud Provider Configuration

For cloud deployments, use managed services:

**AWS ElastiCache (Redis):**
```typescript
state: new RedisStateAdapter({
  host: process.env.REDIS_HOST, // ElastiCache endpoint
  port: 6379,
  password: process.env.REDIS_PASSWORD,
})
```

**CloudAMQP (RabbitMQ):**
```typescript
events: new RabbitMQEventAdapter({
  url: process.env.CLOUDAMQP_URL, // CloudAMQP connection string
  exchangeName: process.env.RABBITMQ_EXCHANGE || 'motia.events',
  exchangeType: 'topic',
})
```

---

## Testing Adapter Configuration

Your application code doesn't change when switching adapters. Test with defaults first:

```typescript
// This works with both file and Redis adapters
export const handler: Handlers['MyStep'] = async (req, { state, streams, emit }) => {
  await state.set('orders', 'order-123', { id: 'order-123' })
  await streams.messages.set('chat-123', 'msg-1', { text: 'Hello' })
  await emit({ topic: 'order.created', data: { orderId: '123' } })
}
```

Then switch to distributed adapters for production without changing your code.

---

## What's Next?

<Cards>
  <Card href="/docs/development-guide/adapters/usage" title="ðŸ“– Using Adapters">
    Learn more about using adapters in your application
  </Card>
  
  <Card href="/docs/development-guide/adapters/creating-adapters" title="ðŸ”§ Creating Adapters">
    Build custom adapters for your infrastructure
  </Card>
  
  <Card href="/docs/deployment-guide/self-hosted" title="ðŸš€ Deployment Guide">
    Learn about deploying Motia to production
  </Card>
</Cards>



-   [ai-content-moderation](/docs/examples/ai-content-moderation): Documentation for ai-content-moderation.
---
title: 'AI Content Moderation'
description: 'Intelligent Content Moderation: Building Human-in-the-Loop Systems with Motia'
---

In today's digital landscape, content moderation is crucial for maintaining safe and appropriate user experiences. Whether you're building a social platform, forum, or any user-generated content system, you need intelligent moderation that can scale with your user base while maintaining human oversight for complex decisions.

This comprehensive guide explores how to build a production-ready content moderation system using Motia's event-driven architecture. We'll cover:

1. **AI-Powered Analysis**: Using OpenAI for text toxicity detection and image safety analysis
2. **Confidence-Based Routing**: Automatically handling clear cases while flagging uncertain content for human review
3. **Slack Integration**: Creating interactive moderation workflows within existing team communication tools
4. **Human-in-the-Loop**: Seamlessly integrating human decision-making into automated processes

Let's build a content moderation system that scales intelligently.

---

## Explore the Workbench

<div className="my-8">![AI Content Moderation Workflow](./../img/ai-content-moderation-workflow.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-content-moderation)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Intelligent Content Moderation

At its core, our content moderation system solves a fundamental challenge: how do you efficiently moderate user-generated content at scale while maintaining human oversight for complex decisions? Traditional approaches often involve either fully manual processes that don't scale or fully automated systems that lack nuance.

Our Motia-powered solution combines the best of both worlds through intelligent routing:

- **[OpenAI Integration](https://openai.com/)**: Advanced AI analysis for text toxicity and image safety detection
- **[Confidence-Based Routing](https://en.wikipedia.org/wiki/Confidence_interval)**: Automatic handling of clear cases, human review for uncertain content
- **[Slack Integration](https://api.slack.com/)**: Interactive moderation workflows within existing team communication tools
- **[Motia Framework](https://motia.dev)**: Event-driven orchestration with built-in state management and error handling

Instead of a monolithic moderation system, we get a flexible architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our Content Moderation System

Our application consists of six specialized steps, each handling a specific part of the moderation workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="01-content-submit.step.ts" />
  <File name="02-content-analyzer.step.ts" />
  <File name="03-content-router.step.ts" />
  <File name="04-slack-notifier.step.ts" />
  <File name="05-slack-webhook.step.ts" />
  <File name="06-action-executor.step.ts" />
</Folder>

<Tabs items={['content-submit', 'content-analyzer', 'content-router', 'slack-notifier', 'slack-webhook', 'action-executor']}>
  <Tab value="content-submit">
    The entry point for content moderation. This API endpoint receives user-generated content (text and/or images) and initiates the moderation workflow.

    ```typescript
    import { z } from "zod";
    import { ApiRouteConfig, Handlers } from "motia";

    const ContentSubmitInputSchema = z.object({
      text: z.string().optional(),
      imageUrl: z.string().optional(),
      userId: z.string(),
      platform: z.string(),
    });

    export const config: ApiRouteConfig = {
      type: "api",
      name: "ContentSubmitAPI",
      description: "Receives user-generated content for moderation",
      path: "/content/submit",
      method: "POST",
      bodySchema: ContentSubmitInputSchema,
      emits: ["content.submitted"],
      flows: ["content-moderation"],
    };

    export const handler: Handlers["ContentSubmitAPI"] = async (
      req,
      { logger, emit }
    ) => {
      const { text, imageUrl, userId, platform } = req.body;
      const submissionId = `sub_${Date.now()}_${Math.random()
        .toString(36)
        .slice(2, 11)}`;

      logger.info(`Content submitted for moderation`, {
        submissionId,
        hasText: !!text,
        hasImage: !!imageUrl,
        userId,
        platform,
      });

      await emit({
        topic: "content.submitted",
        data: {
          submissionId,
          text,
          imageUrl,
          userId,
          platform,
          timestamp: new Date().toISOString(),
        },
      });

      return {
        status: 200,
        body: {
          message: "Content submitted for moderation",
          submissionId,
        },
      };
    };
    ```

  </Tab>
  <Tab value="content-analyzer">
    The AI analysis engine that processes both text and image content using OpenAI's advanced models to determine content safety and risk levels.

    ```typescript
    import { z } from "zod";
    import { EventConfig, Handlers } from "motia";
    import OpenAI from "openai";

    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });

    export const config: EventConfig = {
      type: "event",
      name: "ContentAnalyzer",
      description: "Analyzes content using OpenAI for toxicity and safety",
      subscribes: ["content.submitted"],
      emits: ["content.analyzed"],
      input: z.object({
        submissionId: z.string(),
        text: z.string().optional(),
        imageUrl: z.string().optional(),
        userId: z.string(),
        platform: z.string(),
        timestamp: z.string(),
      }),
      flows: ["content-moderation"],
    };

    export const handler: Handlers["ContentAnalyzer"] = async (
      input,
      { logger, emit }
    ) => {
      const { submissionId, text, imageUrl, userId } = input;
      
      logger.info("Starting content analysis", { submissionId, hasText: !!text, hasImage: !!imageUrl });

      let textScore = 0;
      let imageScore = 0;
      let textAnalysis = "";
      let imageAnalysis = "";

      // Analyze text content if present
      if (text) {
        try {
          const textResponse = await openai.chat.completions.create({
            model: "gpt-4",
            messages: [
              {
                role: "system",
                content: `You are a content moderation AI. Analyze the following text for toxicity, hate speech, violence, harassment, or inappropriate content. 
                Respond with a JSON object containing:
                - "score": a number between 0-1 where 0 is completely safe and 1 is extremely harmful
                - "analysis": a brief explanation of your assessment
                - "categories": array of detected issues (e.g., ["hate_speech", "violence"])`
              },
              {
                role: "user",
                content: text
              }
            ],
            temperature: 0.1,
          });

          const textResult = JSON.parse(textResponse.choices[0]?.message?.content || "{}");
          textScore = textResult.score || 0;
          textAnalysis = textResult.analysis || "";
        } catch (error) {
          logger.error("Text analysis failed", { error, submissionId });
        }
      }

      // Analyze image content if present
      if (imageUrl) {
        try {
          const imageResponse = await openai.chat.completions.create({
            model: "gpt-4-vision-preview",
            messages: [
              {
                role: "system",
                content: `You are a content moderation AI. Analyze the following image for inappropriate content, violence, nudity, or harmful material.
                Respond with a JSON object containing:
                - "score": a number between 0-1 where 0 is completely safe and 1 is extremely harmful
                - "analysis": a brief explanation of your assessment
                - "categories": array of detected issues (e.g., ["violence", "inappropriate"])`
              },
              {
                role: "user",
                content: [
                  {
                    type: "text",
                    text: "Analyze this image for content moderation:"
                  },
                  {
                    type: "image_url",
                    image_url: { url: imageUrl }
                  }
                ]
              }
            ],
            temperature: 0.1,
          });

          const imageResult = JSON.parse(imageResponse.choices[0]?.message?.content || "{}");
          imageScore = imageResult.score || 0;
          imageAnalysis = imageResult.analysis || "";
        } catch (error) {
          logger.error("Image analysis failed", { error, submissionId });
        }
      }

      // Calculate overall risk score
      const overallScore = Math.max(textScore, imageScore);
      
      const analysisResult = {
        submissionId,
        userId,
        textScore,
        imageScore,
        overallScore,
        textAnalysis,
        imageAnalysis,
        analyzedAt: new Date().toISOString(),
      };

      logger.info("Content analysis completed", {
        submissionId,
        overallScore,
        textScore,
        imageScore,
      });

      await emit({
        topic: "content.analyzed",
        data: analysisResult,
      });
    };
    ```

  </Tab>
  <Tab value="content-router">
    The intelligent routing system that determines whether content should be automatically approved/rejected or sent for human review based on confidence scores.

    ```typescript
    import { z } from "zod";
    import { EventConfig, Handlers } from "motia";

    export const config: EventConfig = {
      type: "event",
      name: "ContentRouter",
      description: "Routes content based on AI analysis confidence scores",
      subscribes: ["content.analyzed"],
      emits: ["content.auto.approved", "content.auto.rejected", "content.needs.review"],
      input: z.object({
        submissionId: z.string(),
        userId: z.string(),
        textScore: z.number(),
        imageScore: z.number(),
        overallScore: z.number(),
        textAnalysis: z.string(),
        imageAnalysis: z.string(),
        analyzedAt: z.string(),
      }),
      flows: ["content-moderation"],
    };

    export const handler: Handlers["ContentRouter"] = async (
      input,
      { logger, emit }
    ) => {
      const { submissionId, userId, overallScore, textAnalysis, imageAnalysis } = input;
      
      logger.info("Routing content based on analysis", { 
        submissionId, 
        overallScore,
        userId 
      });

      let decision: string;
      let routingData = {
        submissionId,
        userId,
        overallScore,
        textAnalysis,
        imageAnalysis,
        routedAt: new Date().toISOString(),
      };

      // Decision logic based on confidence scores
      if (overallScore <= 0.05) {
        // Very low risk - auto approve
        decision = "approved";
        logger.info("Content auto-approved", { submissionId, overallScore });
        
        await emit({
          topic: "content.auto.approved",
          data: {
            ...routingData,
            decision,
            reason: "Low risk score - automatically approved",
          },
        });
        
      } else if (overallScore >= 0.95) {
        // Very high risk - auto reject
        decision = "rejected";
        logger.info("Content auto-rejected", { submissionId, overallScore });
        
        await emit({
          topic: "content.auto.rejected",
          data: {
            ...routingData,
            decision,
            reason: "High risk score - automatically rejected",
          },
        });
        
      } else {
        // Medium risk - needs human review
        decision = "review";
        logger.info("Content needs human review", { submissionId, overallScore });
        
        await emit({
          topic: "content.needs.review",
          data: {
            ...routingData,
            decision,
            reason: "Medium risk score - requires human review",
            priority: overallScore >= 0.7 ? "high" : overallScore >= 0.5 ? "medium" : "low",
          },
        });
      }
    };
    ```

  </Tab>
  <Tab value="slack-notifier">
    Creates interactive Slack messages for human moderators with approve/reject/escalate buttons and contextual information.

    ```typescript
    import { z } from "zod";
    import { EventConfig, Handlers } from "motia";
    import { WebClient } from "@slack/web-api";

    const slack = new WebClient(process.env.SLACK_BOT_TOKEN);

    export const config: EventConfig = {
      type: "event",
      name: "SlackNotifier",
      description: "Sends interactive Slack messages for human review",
      subscribes: ["content.needs.review"],
      emits: ["slack.notification.sent"],
      input: z.object({
        submissionId: z.string(),
        userId: z.string(),
        overallScore: z.number(),
        textAnalysis: z.string(),
        imageAnalysis: z.string(),
        decision: z.string(),
        reason: z.string(),
        priority: z.enum(["low", "medium", "high"]),
        routedAt: z.string(),
      }),
      flows: ["content-moderation"],
    };

    export const handler: Handlers["SlackNotifier"] = async (
      input,
      { logger, emit }
    ) => {
      const { submissionId, userId, overallScore, textAnalysis, imageAnalysis, priority } = input;
      
      logger.info("Sending Slack notification for review", { 
        submissionId, 
        priority,
        userId 
      });

      // Determine channel based on priority
      let channel: string;
      switch (priority) {
        case "high":
          channel = process.env.SLACK_CHANNEL_URGENT!;
          break;
        case "medium":
          channel = process.env.SLACK_CHANNEL_ESCALATED!;
          break;
        default:
          channel = process.env.SLACK_CHANNEL_MODERATION!;
      }

      // Create interactive message with buttons
      const message = {
        channel,
        text: `Content Moderation Review Required`,
        blocks: [
          {
            type: "header",
            text: {
              type: "plain_text",
              text: `ðŸš¨ Content Review - ${priority.toUpperCase()} Priority`,
            },
          },
          {
            type: "section",
            fields: [
              {
                type: "mrkdwn",
                text: `*Submission ID:*\n${submissionId}`,
              },
              {
                type: "mrkdwn",
                text: `*User ID:*\n${userId}`,
              },
              {
                type: "mrkdwn",
                text: `*Risk Score:*\n${(overallScore * 100).toFixed(1)}%`,
              },
              {
                type: "mrkdwn",
                text: `*Priority:*\n${priority.toUpperCase()}`,
              },
            ],
          },
          {
            type: "section",
            text: {
              type: "mrkdwn",
              text: `*AI Analysis:*\n${textAnalysis || imageAnalysis || "No analysis available"}`,
            },
          },
          {
            type: "actions",
            elements: [
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "âœ… Approve",
                },
                style: "primary",
                action_id: "approve_content",
                value: submissionId,
              },
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "âŒ Reject",
                },
                style: "danger",
                action_id: "reject_content",
                value: submissionId,
              },
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "âš ï¸ Escalate",
                },
                action_id: "escalate_content",
                value: submissionId,
              },
            ],
          },
        ],
      };

      try {
        const result = await slack.chat.postMessage(message);
        
        logger.info("Slack notification sent successfully", {
          submissionId,
          channel,
          messageTs: result.ts,
        });

        await emit({
          topic: "slack.notification.sent",
          data: {
            submissionId,
            userId,
            channel,
            messageTs: result.ts,
            priority,
            sentAt: new Date().toISOString(),
          },
        });

      } catch (error) {
        logger.error("Failed to send Slack notification", {
          error,
          submissionId,
          channel,
        });
        throw error;
      }
    };
    ```

  </Tab>
  <Tab value="slack-webhook">
    Handles interactive button responses from Slack, processing approve/reject/escalate decisions from human moderators.

    ```typescript
    import { z } from "zod";
    import { ApiRouteConfig, Handlers } from "motia";
    import { createHmac } from "crypto";

    export const config: ApiRouteConfig = {
      type: "api",
      name: "SlackWebhook",
      description: "Handles Slack interactive button responses",
      path: "/slack/webhook",
      method: "POST",
      emits: ["slack.decision.received"],
      flows: ["content-moderation"],
    };

    export const handler: Handlers["SlackWebhook"] = async (
      req,
      { logger, emit }
    ) => {
      // Verify Slack signature
      const signature = req.headers["x-slack-signature"] as string;
      const timestamp = req.headers["x-slack-request-timestamp"] as string;
      const body = req.body;

      if (!verifySlackSignature(signature, timestamp, body)) {
        logger.error("Invalid Slack signature");
        return { status: 401, body: { error: "Unauthorized" } };
      }

      const payload = JSON.parse(body.payload);
      const { actions, user, message } = payload;

      if (!actions || actions.length === 0) {
        return { status: 200, body: { text: "No action received" } };
      }

      const action = actions[0];
      const submissionId = action.value;
      const decision = action.action_id.replace("_content", "");
      const moderatorId = user.id;
      const moderatorName = user.name;

      logger.info("Slack decision received", {
        submissionId,
        decision,
        moderatorId,
        moderatorName,
      });

      await emit({
        topic: "slack.decision.received",
        data: {
          submissionId,
          decision,
          moderatorId,
          moderatorName,
          messageTs: message.ts,
          decidedAt: new Date().toISOString(),
        },
      });

      // Update the original message to show decision
      const responseMessage = `âœ… Decision recorded: ${decision.toUpperCase()} by ${moderatorName}`;
      
      return {
        status: 200,
        body: {
          text: responseMessage,
          replace_original: false,
        },
      };
    };

    function verifySlackSignature(signature: string, timestamp: string, body: string): boolean {
      const signingSecret = process.env.SLACK_SIGNING_SECRET!;
      const baseString = `v0:${timestamp}:${body}`;
      const expectedSignature = `v0=${createHmac("sha256", signingSecret)
        .update(baseString)
        .digest("hex")}`;
      
      return signature === expectedSignature;
    }
    ```

  </Tab>
  <Tab value="action-executor">
    Executes the final moderation decisions, handling both automated and human-reviewed content with comprehensive logging and state management.

    ```typescript
    import { z } from "zod";
    import { EventConfig, Handlers } from "motia";

    export const config: EventConfig = {
      type: "event",
      name: "ActionExecutor",
      description: "Executes final moderation decisions",
      subscribes: ["content.auto.approved", "content.auto.rejected", "slack.decision.received"],
      emits: ["content.moderation.completed"],
      input: z.object({
        submissionId: z.string(),
        decision: z.enum(["approved", "rejected", "escalated"]),
        reason: z.string(),
        moderatorId: z.string().optional(),
        moderatorName: z.string().optional(),
        decidedAt: z.string(),
      }),
      flows: ["content-moderation"],
    };

    export const handler: Handlers["ActionExecutor"] = async (
      input,
      { logger, emit, state }
    ) => {
      const { submissionId, decision, reason, moderatorId, moderatorName, decidedAt } = input;
      
      logger.info("Executing moderation decision", {
        submissionId,
        decision,
        moderatorId,
        moderatorName,
      });

      // Store the final decision in state
      const moderationRecord = {
        submissionId,
        decision,
        reason,
        moderatorId,
        moderatorName,
        decidedAt,
        executedAt: new Date().toISOString(),
      };

      await state.set("moderation", submissionId, moderationRecord);

      // Execute the appropriate action based on decision
      switch (decision) {
        case "approved":
          logger.info("Content approved", { submissionId });
          // Here you would typically:
          // - Make content visible to users
          // - Send approval notification to user
          // - Update content status in database
          break;

        case "rejected":
          logger.info("Content rejected", { submissionId });
          // Here you would typically:
          // - Hide or remove content
          // - Send rejection notification to user
          // - Log for potential user action
          break;

        case "escalated":
          logger.info("Content escalated", { submissionId });
          // Here you would typically:
          // - Send to higher-level moderators
          // - Create support ticket
          // - Flag for additional review
          break;
      }

      await emit({
        topic: "content.moderation.completed",
        data: moderationRecord,
      });

      logger.info("Moderation decision executed successfully", {
        submissionId,
        decision,
        moderatorId,
      });
    };
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your content moderation pipeline, making it easy to understand the flow and monitor moderation decisions in real-time.

<div className="my-8">![AI Content Moderation Workflow](./../img/ai-content-moderation-workflow.png)</div>

You can monitor real-time content analysis, view Slack notifications, and trace the execution of each moderation decision directly in the Workbench interface. This makes development and debugging significantly easier compared to traditional monolithic moderation systems.

## Human-in-the-Loop Workflow Demo

Let's see the complete human-in-the-loop process in action using a real example. We'll submit problematic content and watch it flow through the moderation pipeline.

### Step 1: Submit Content for Moderation

Submit the sample content that should trigger human review:

```shell
curl -X POST http://localhost:3000/content/submit \
  -H "Content-Type: application/json" \
  -d '{
    "text": "I hate this stupid garbage, it\'s complete trash and makes me want to hurt someone",
    "userId": "user456",
    "platform": "web"
  }'
```

### Step 2: AI Analysis & Routing

The system will:
1. **Analyze the content** using OpenAI's GPT-4 for toxicity detection
2. **Calculate risk scores** based on detected harmful content
3. **Route for human review** since the content contains hate speech and violence references

You'll see logs like:
```
Content submitted for moderation: submissionId=sub_123, hasText=true, userId=user456
Starting content analysis: submissionId=sub_123, hasText=true
Content analysis completed: submissionId=sub_123, overallScore=0.87, textScore=0.87
Content needs human review: submissionId=sub_123, overallScore=0.87
```

### Step 3: Slack Notification for Human Review

The system automatically sends an interactive message to your moderation team in Slack:

<div className="my-8">![AI Content Moderation Slack Output](./../img/ai-content-moderation-slack-output.png)</div>

The Slack message includes:
- **Risk score**: 87% confidence of harmful content
- **Priority level**: HIGH (since score â‰¥ 70%)
- **AI analysis**: Detailed breakdown of detected issues
- **Interactive buttons**: Approve, Reject, or Escalate options

### Step 4: Human Decision & Execution

When a moderator clicks a button in Slack:
1. **Decision is recorded** with moderator attribution
2. **Content is processed** according to the decision
3. **User is notified** of the moderation outcome
4. **Audit trail is maintained** for compliance

The complete workflow demonstrates how AI handles the initial analysis while humans provide the final judgment for nuanced decisions.

---

## Key Features & Benefits

### ðŸ¤– **AI-Powered Analysis**
Advanced OpenAI integration for both text toxicity detection and image safety analysis with confidence scoring.

### ðŸŽ¯ **Intelligent Routing**
Confidence-based decision making that automatically handles clear cases while flagging uncertain content for human review.

### ðŸ’¬ **Slack Integration**
Interactive moderation workflows within existing team communication tools - no custom dashboard required.

### ðŸ‘¥ **Human-in-the-Loop**
Seamless integration of human decision-making with approve/reject/escalate buttons and contextual information.

### ðŸ“Š **Priority-Based Routing**
Content is routed to different Slack channels based on risk level and urgency.

### ðŸ”’ **Security & Compliance**
Built-in signature verification, audit trails, and comprehensive logging for compliance requirements.

---

## Getting Started

Ready to build your own intelligent content moderation system? Here's how to set it up and run it.

<Steps>

### 1. Install Dependencies

Install the necessary npm packages and set up the development environment.

```shell
npm install
```

### 2. Configure Environment Variables

Create a `.env` file with your API keys and Slack configuration:

```shell
# Required: OpenAI API key for content analysis
OPENAI_API_KEY="sk-..."

# Required: Slack bot configuration
SLACK_BOT_TOKEN="xoxb-your-bot-token"
SLACK_SIGNING_SECRET="your-signing-secret"

# Required: Slack channels for different priority levels
SLACK_CHANNEL_MODERATION="C1234567890"  # Normal priority
SLACK_CHANNEL_URGENT="C0987654321"      # High priority
SLACK_CHANNEL_ESCALATED="C1122334455"   # Escalated content
```

### 3. Set Up Slack Integration

1. Create a Slack app with the following permissions:
   - `chat:write` - Send messages to channels
   - `channels:read` - Access channel information
2. Enable Interactive Components and set webhook URL to: `https://your-domain.com/slack/webhook`
3. Install the app to your workspace
4. Copy the bot token and signing secret to your `.env` file

### 4. Run the Moderation System

Start the Motia development server to begin processing content.

```shell
npm run dev
```

</Steps>

---

## Advanced Configuration

### Adjusting Confidence Thresholds

Modify the decision thresholds in the content router step:

```typescript
// In 03-content-router.step.ts
if (overallScore <= 0.05) {
  decision = "approved"; // Auto-approve threshold (5%)
} else if (overallScore >= 0.95) {
  decision = "rejected"; // Auto-reject threshold (95%)
} else {
  decision = "review"; // Human review range (5-95%)
}
```

### Custom Channel Routing

Implement custom routing logic based on content type or user behavior:

```typescript
// Route based on user history or content type
const channel = getChannelForContent(contentType, userHistory, riskScore);
```

### Integration with External Systems

Extend the action executor to integrate with your existing systems:

```typescript
// In 06-action-executor.step.ts
case "approved":
  await publishContent(submissionId);
  await notifyUser(userId, "Your content has been approved");
  break;
```

---

## ðŸ’» Dive into the Code

Want to explore the complete content moderation implementation? Check out the full source code, including all steps, Slack integration, and production-ready configuration:

<div className="not-prose">
  <div className="bg-gradient-to-r from-purple-50 to-pink-50 border border-purple-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-purple-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete Content Moderation System</h3>
        <p className="text-gray-600 mb-4">Access the full implementation with AI analysis, Slack integration, and human-in-the-loop workflows.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-content-moderation" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Content Moderation Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Intelligent Content Moderation at Scale

This content moderation system demonstrates the power of combining AI analysis with human oversight in an event-driven architecture. By breaking down moderation into discrete, specialized components, we've created a system that's not only intelligent but also flexible and maintainable.

The human-in-the-loop approach means you can:
- **Scale efficiently**: Automatically handle 80-90% of content while maintaining quality
- **Adapt quickly**: Adjust thresholds and routing logic without system changes
- **Maintain oversight**: Human moderators focus on complex cases that require judgment
- **Integrate seamlessly**: Use existing team communication tools like Slack

Key architectural benefits:
- **Intelligent routing**: Confidence-based decisions reduce human workload
- **Flexible integration**: Works with any team communication platform
- **Audit compliance**: Complete decision trails and moderator attribution
- **Scalable architecture**: Each component can be scaled independently

From here, you can extend the system by:
- Adding support for video content moderation
- Implementing custom AI models for specific content types
- Building analytics dashboards for moderation insights
- Integrating with user management and content management systems
- Adding escalation policies and moderator workflows

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing moderation pipeline.

Ready to build content moderation that scales with your platform? Start building with Motia today!



## Examples
[ai-content-moderation](/docs/examples/ai-content-moderation): Code example
---
title: 'AI Content Moderation'
description: 'Intelligent Content Moderation: Building Human-in-the-Loop Systems with Motia'
---

In today's digital landscape, content moderation is crucial for maintaining safe and appropriate user experiences. Whether you're building a social platform, forum, or any user-generated content system, you need intelligent moderation that can scale with your user base while maintaining human oversight for complex decisions.

This comprehensive guide explores how to build a production-ready content moderation system using Motia's event-driven architecture. We'll cover:

1. **AI-Powered Analysis**: Using OpenAI for text toxicity detection and image safety analysis
2. **Confidence-Based Routing**: Automatically handling clear cases while flagging uncertain content for human review
3. **Slack Integration**: Creating interactive moderation workflows within existing team communication tools
4. **Human-in-the-Loop**: Seamlessly integrating human decision-making into automated processes

Let's build a content moderation system that scales intelligently.

---

## Explore the Workbench

<div className="my-8">![AI Content Moderation Workflow](./../img/ai-content-moderation-workflow.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-content-moderation)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Intelligent Content Moderation

At its core, our content moderation system solves a fundamental challenge: how do you efficiently moderate user-generated content at scale while maintaining human oversight for complex decisions? Traditional approaches often involve either fully manual processes that don't scale or fully automated systems that lack nuance.

Our Motia-powered solution combines the best of both worlds through intelligent routing:

- **[OpenAI Integration](https://openai.com/)**: Advanced AI analysis for text toxicity and image safety detection
- **[Confidence-Based Routing](https://en.wikipedia.org/wiki/Confidence_interval)**: Automatic handling of clear cases, human review for uncertain content
- **[Slack Integration](https://api.slack.com/)**: Interactive moderation workflows within existing team communication tools
- **[Motia Framework](https://motia.dev)**: Event-driven orchestration with built-in state management and error handling

Instead of a monolithic moderation system, we get a flexible architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our Content Moderation System

Our application consists of six specialized steps, each handling a specific part of the moderation workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="01-content-submit.step.ts" />
  <File name="02-content-analyzer.step.ts" />
  <File name="03-content-router.step.ts" />
  <File name="04-slack-notifier.step.ts" />
  <File name="05-slack-webhook.step.ts" />
  <File name="06-action-executor.step.ts" />
</Folder>

<Tabs items={['content-submit', 'content-analyzer', 'content-router', 'slack-notifier', 'slack-webhook', 'action-executor']}>
  <Tab value="content-submit">
    The entry point for content moderation. This API endpoint receives user-generated content (text and/or images) and initiates the moderation workflow.

    ```typescript
    import { z } from "zod";
    import { ApiRouteConfig, Handlers } from "motia";

    const ContentSubmitInputSchema = z.object({
      text: z.string().optional(),
      imageUrl: z.string().optional(),
      userId: z.string(),
      platform: z.string(),
    });

    export const config: ApiRouteConfig = {
      type: "api",
      name: "ContentSubmitAPI",
      description: "Receives user-generated content for moderation",
      path: "/content/submit",
      method: "POST",
      bodySchema: ContentSubmitInputSchema,
      emits: ["content.submitted"],
      flows: ["content-moderation"],
    };

    export const handler: Handlers["ContentSubmitAPI"] = async (
      req,
      { logger, emit }
    ) => {
      const { text, imageUrl, userId, platform } = req.body;
      const submissionId = `sub_${Date.now()}_${Math.random()
        .toString(36)
        .slice(2, 11)}`;

      logger.info(`Content submitted for moderation`, {
        submissionId,
        hasText: !!text,
        hasImage: !!imageUrl,
        userId,
        platform,
      });

      await emit({
        topic: "content.submitted",
        data: {
          submissionId,
          text,
          imageUrl,
          userId,
          platform,
          timestamp: new Date().toISOString(),
        },
      });

      return {
        status: 200,
        body: {
          message: "Content submitted for moderation",
          submissionId,
        },
      };
    };
    ```

  </Tab>
  <Tab value="content-analyzer">
    The AI analysis engine that processes both text and image content using OpenAI's advanced models to determine content safety and risk levels.

    ```typescript
    import { z } from "zod";
    import { EventConfig, Handlers } from "motia";
    import OpenAI from "openai";

    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });

    export const config: EventConfig = {
      type: "event",
      name: "ContentAnalyzer",
      description: "Analyzes content using OpenAI for toxicity and safety",
      subscribes: ["content.submitted"],
      emits: ["content.analyzed"],
      input: z.object({
        submissionId: z.string(),
        text: z.string().optional(),
        imageUrl: z.string().optional(),
        userId: z.string(),
        platform: z.string(),
        timestamp: z.string(),
      }),
      flows: ["content-moderation"],
    };

    export const handler: Handlers["ContentAnalyzer"] = async (
      input,
      { logger, emit }
    ) => {
      const { submissionId, text, imageUrl, userId } = input;
      
      logger.info("Starting content analysis", { submissionId, hasText: !!text, hasImage: !!imageUrl });

      let textScore = 0;
      let imageScore = 0;
      let textAnalysis = "";
      let imageAnalysis = "";

      // Analyze text content if present
      if (text) {
        try {
          const textResponse = await openai.chat.completions.create({
            model: "gpt-4",
            messages: [
              {
                role: "system",
                content: `You are a content moderation AI. Analyze the following text for toxicity, hate speech, violence, harassment, or inappropriate content. 
                Respond with a JSON object containing:
                - "score": a number between 0-1 where 0 is completely safe and 1 is extremely harmful
                - "analysis": a brief explanation of your assessment
                - "categories": array of detected issues (e.g., ["hate_speech", "violence"])`
              },
              {
                role: "user",
                content: text
              }
            ],
            temperature: 0.1,
          });

          const textResult = JSON.parse(textResponse.choices[0]?.message?.content || "{}");
          textScore = textResult.score || 0;
          textAnalysis = textResult.analysis || "";
        } catch (error) {
          logger.error("Text analysis failed", { error, submissionId });
        }
      }

      // Analyze image content if present
      if (imageUrl) {
        try {
          const imageResponse = await openai.chat.completions.create({
            model: "gpt-4-vision-preview",
            messages: [
              {
                role: "system",
                content: `You are a content moderation AI. Analyze the following image for inappropriate content, violence, nudity, or harmful material.
                Respond with a JSON object containing:
                - "score": a number between 0-1 where 0 is completely safe and 1 is extremely harmful
                - "analysis": a brief explanation of your assessment
                - "categories": array of detected issues (e.g., ["violence", "inappropriate"])`
              },
              {
                role: "user",
                content: [
                  {
                    type: "text",
                    text: "Analyze this image for content moderation:"
                  },
                  {
                    type: "image_url",
                    image_url: { url: imageUrl }
                  }
                ]
              }
            ],
            temperature: 0.1,
          });

          const imageResult = JSON.parse(imageResponse.choices[0]?.message?.content || "{}");
          imageScore = imageResult.score || 0;
          imageAnalysis = imageResult.analysis || "";
        } catch (error) {
          logger.error("Image analysis failed", { error, submissionId });
        }
      }

      // Calculate overall risk score
      const overallScore = Math.max(textScore, imageScore);
      
      const analysisResult = {
        submissionId,
        userId,
        textScore,
        imageScore,
        overallScore,
        textAnalysis,
        imageAnalysis,
        analyzedAt: new Date().toISOString(),
      };

      logger.info("Content analysis completed", {
        submissionId,
        overallScore,
        textScore,
        imageScore,
      });

      await emit({
        topic: "content.analyzed",
        data: analysisResult,
      });
    };
    ```

  </Tab>
  <Tab value="content-router">
    The intelligent routing system that determines whether content should be automatically approved/rejected or sent for human review based on confidence scores.

    ```typescript
    import { z } from "zod";
    import { EventConfig, Handlers } from "motia";

    export const config: EventConfig = {
      type: "event",
      name: "ContentRouter",
      description: "Routes content based on AI analysis confidence scores",
      subscribes: ["content.analyzed"],
      emits: ["content.auto.approved", "content.auto.rejected", "content.needs.review"],
      input: z.object({
        submissionId: z.string(),
        userId: z.string(),
        textScore: z.number(),
        imageScore: z.number(),
        overallScore: z.number(),
        textAnalysis: z.string(),
        imageAnalysis: z.string(),
        analyzedAt: z.string(),
      }),
      flows: ["content-moderation"],
    };

    export const handler: Handlers["ContentRouter"] = async (
      input,
      { logger, emit }
    ) => {
      const { submissionId, userId, overallScore, textAnalysis, imageAnalysis } = input;
      
      logger.info("Routing content based on analysis", { 
        submissionId, 
        overallScore,
        userId 
      });

      let decision: string;
      let routingData = {
        submissionId,
        userId,
        overallScore,
        textAnalysis,
        imageAnalysis,
        routedAt: new Date().toISOString(),
      };

      // Decision logic based on confidence scores
      if (overallScore <= 0.05) {
        // Very low risk - auto approve
        decision = "approved";
        logger.info("Content auto-approved", { submissionId, overallScore });
        
        await emit({
          topic: "content.auto.approved",
          data: {
            ...routingData,
            decision,
            reason: "Low risk score - automatically approved",
          },
        });
        
      } else if (overallScore >= 0.95) {
        // Very high risk - auto reject
        decision = "rejected";
        logger.info("Content auto-rejected", { submissionId, overallScore });
        
        await emit({
          topic: "content.auto.rejected",
          data: {
            ...routingData,
            decision,
            reason: "High risk score - automatically rejected",
          },
        });
        
      } else {
        // Medium risk - needs human review
        decision = "review";
        logger.info("Content needs human review", { submissionId, overallScore });
        
        await emit({
          topic: "content.needs.review",
          data: {
            ...routingData,
            decision,
            reason: "Medium risk score - requires human review",
            priority: overallScore >= 0.7 ? "high" : overallScore >= 0.5 ? "medium" : "low",
          },
        });
      }
    };
    ```

  </Tab>
  <Tab value="slack-notifier">
    Creates interactive Slack messages for human moderators with approve/reject/escalate buttons and contextual information.

    ```typescript
    import { z } from "zod";
    import { EventConfig, Handlers } from "motia";
    import { WebClient } from "@slack/web-api";

    const slack = new WebClient(process.env.SLACK_BOT_TOKEN);

    export const config: EventConfig = {
      type: "event",
      name: "SlackNotifier",
      description: "Sends interactive Slack messages for human review",
      subscribes: ["content.needs.review"],
      emits: ["slack.notification.sent"],
      input: z.object({
        submissionId: z.string(),
        userId: z.string(),
        overallScore: z.number(),
        textAnalysis: z.string(),
        imageAnalysis: z.string(),
        decision: z.string(),
        reason: z.string(),
        priority: z.enum(["low", "medium", "high"]),
        routedAt: z.string(),
      }),
      flows: ["content-moderation"],
    };

    export const handler: Handlers["SlackNotifier"] = async (
      input,
      { logger, emit }
    ) => {
      const { submissionId, userId, overallScore, textAnalysis, imageAnalysis, priority } = input;
      
      logger.info("Sending Slack notification for review", { 
        submissionId, 
        priority,
        userId 
      });

      // Determine channel based on priority
      let channel: string;
      switch (priority) {
        case "high":
          channel = process.env.SLACK_CHANNEL_URGENT!;
          break;
        case "medium":
          channel = process.env.SLACK_CHANNEL_ESCALATED!;
          break;
        default:
          channel = process.env.SLACK_CHANNEL_MODERATION!;
      }

      // Create interactive message with buttons
      const message = {
        channel,
        text: `Content Moderation Review Required`,
        blocks: [
          {
            type: "header",
            text: {
              type: "plain_text",
              text: `ðŸš¨ Content Review - ${priority.toUpperCase()} Priority`,
            },
          },
          {
            type: "section",
            fields: [
              {
                type: "mrkdwn",
                text: `*Submission ID:*\n${submissionId}`,
              },
              {
                type: "mrkdwn",
                text: `*User ID:*\n${userId}`,
              },
              {
                type: "mrkdwn",
                text: `*Risk Score:*\n${(overallScore * 100).toFixed(1)}%`,
              },
              {
                type: "mrkdwn",
                text: `*Priority:*\n${priority.toUpperCase()}`,
              },
            ],
          },
          {
            type: "section",
            text: {
              type: "mrkdwn",
              text: `*AI Analysis:*\n${textAnalysis || imageAnalysis || "No analysis available"}`,
            },
          },
          {
            type: "actions",
            elements: [
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "âœ… Approve",
                },
                style: "primary",
                action_id: "approve_content",
                value: submissionId,
              },
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "âŒ Reject",
                },
                style: "danger",
                action_id: "reject_content",
                value: submissionId,
              },
              {
                type: "button",
                text: {
                  type: "plain_text",
                  text: "âš ï¸ Escalate",
                },
                action_id: "escalate_content",
                value: submissionId,
              },
            ],
          },
        ],
      };

      try {
        const result = await slack.chat.postMessage(message);
        
        logger.info("Slack notification sent successfully", {
          submissionId,
          channel,
          messageTs: result.ts,
        });

        await emit({
          topic: "slack.notification.sent",
          data: {
            submissionId,
            userId,
            channel,
            messageTs: result.ts,
            priority,
            sentAt: new Date().toISOString(),
          },
        });

      } catch (error) {
        logger.error("Failed to send Slack notification", {
          error,
          submissionId,
          channel,
        });
        throw error;
      }
    };
    ```

  </Tab>
  <Tab value="slack-webhook">
    Handles interactive button responses from Slack, processing approve/reject/escalate decisions from human moderators.

    ```typescript
    import { z } from "zod";
    import { ApiRouteConfig, Handlers } from "motia";
    import { createHmac } from "crypto";

    export const config: ApiRouteConfig = {
      type: "api",
      name: "SlackWebhook",
      description: "Handles Slack interactive button responses",
      path: "/slack/webhook",
      method: "POST",
      emits: ["slack.decision.received"],
      flows: ["content-moderation"],
    };

    export const handler: Handlers["SlackWebhook"] = async (
      req,
      { logger, emit }
    ) => {
      // Verify Slack signature
      const signature = req.headers["x-slack-signature"] as string;
      const timestamp = req.headers["x-slack-request-timestamp"] as string;
      const body = req.body;

      if (!verifySlackSignature(signature, timestamp, body)) {
        logger.error("Invalid Slack signature");
        return { status: 401, body: { error: "Unauthorized" } };
      }

      const payload = JSON.parse(body.payload);
      const { actions, user, message } = payload;

      if (!actions || actions.length === 0) {
        return { status: 200, body: { text: "No action received" } };
      }

      const action = actions[0];
      const submissionId = action.value;
      const decision = action.action_id.replace("_content", "");
      const moderatorId = user.id;
      const moderatorName = user.name;

      logger.info("Slack decision received", {
        submissionId,
        decision,
        moderatorId,
        moderatorName,
      });

      await emit({
        topic: "slack.decision.received",
        data: {
          submissionId,
          decision,
          moderatorId,
          moderatorName,
          messageTs: message.ts,
          decidedAt: new Date().toISOString(),
        },
      });

      // Update the original message to show decision
      const responseMessage = `âœ… Decision recorded: ${decision.toUpperCase()} by ${moderatorName}`;
      
      return {
        status: 200,
        body: {
          text: responseMessage,
          replace_original: false,
        },
      };
    };

    function verifySlackSignature(signature: string, timestamp: string, body: string): boolean {
      const signingSecret = process.env.SLACK_SIGNING_SECRET!;
      const baseString = `v0:${timestamp}:${body}`;
      const expectedSignature = `v0=${createHmac("sha256", signingSecret)
        .update(baseString)
        .digest("hex")}`;
      
      return signature === expectedSignature;
    }
    ```

  </Tab>
  <Tab value="action-executor">
    Executes the final moderation decisions, handling both automated and human-reviewed content with comprehensive logging and state management.

    ```typescript
    import { z } from "zod";
    import { EventConfig, Handlers } from "motia";

    export const config: EventConfig = {
      type: "event",
      name: "ActionExecutor",
      description: "Executes final moderation decisions",
      subscribes: ["content.auto.approved", "content.auto.rejected", "slack.decision.received"],
      emits: ["content.moderation.completed"],
      input: z.object({
        submissionId: z.string(),
        decision: z.enum(["approved", "rejected", "escalated"]),
        reason: z.string(),
        moderatorId: z.string().optional(),
        moderatorName: z.string().optional(),
        decidedAt: z.string(),
      }),
      flows: ["content-moderation"],
    };

    export const handler: Handlers["ActionExecutor"] = async (
      input,
      { logger, emit, state }
    ) => {
      const { submissionId, decision, reason, moderatorId, moderatorName, decidedAt } = input;
      
      logger.info("Executing moderation decision", {
        submissionId,
        decision,
        moderatorId,
        moderatorName,
      });

      // Store the final decision in state
      const moderationRecord = {
        submissionId,
        decision,
        reason,
        moderatorId,
        moderatorName,
        decidedAt,
        executedAt: new Date().toISOString(),
      };

      await state.set("moderation", submissionId, moderationRecord);

      // Execute the appropriate action based on decision
      switch (decision) {
        case "approved":
          logger.info("Content approved", { submissionId });
          // Here you would typically:
          // - Make content visible to users
          // - Send approval notification to user
          // - Update content status in database
          break;

        case "rejected":
          logger.info("Content rejected", { submissionId });
          // Here you would typically:
          // - Hide or remove content
          // - Send rejection notification to user
          // - Log for potential user action
          break;

        case "escalated":
          logger.info("Content escalated", { submissionId });
          // Here you would typically:
          // - Send to higher-level moderators
          // - Create support ticket
          // - Flag for additional review
          break;
      }

      await emit({
        topic: "content.moderation.completed",
        data: moderationRecord,
      });

      logger.info("Moderation decision executed successfully", {
        submissionId,
        decision,
        moderatorId,
      });
    };
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your content moderation pipeline, making it easy to understand the flow and monitor moderation decisions in real-time.

<div className="my-8">![AI Content Moderation Workflow](./../img/ai-content-moderation-workflow.png)</div>

You can monitor real-time content analysis, view Slack notifications, and trace the execution of each moderation decision directly in the Workbench interface. This makes development and debugging significantly easier compared to traditional monolithic moderation systems.

## Human-in-the-Loop Workflow Demo

Let's see the complete human-in-the-loop process in action using a real example. We'll submit problematic content and watch it flow through the moderation pipeline.

### Step 1: Submit Content for Moderation

Submit the sample content that should trigger human review:

```shell
curl -X POST http://localhost:3000/content/submit \
  -H "Content-Type: application/json" \
  -d '{
    "text": "I hate this stupid garbage, it\'s complete trash and makes me want to hurt someone",
    "userId": "user456",
    "platform": "web"
  }'
```

### Step 2: AI Analysis & Routing

The system will:
1. **Analyze the content** using OpenAI's GPT-4 for toxicity detection
2. **Calculate risk scores** based on detected harmful content
3. **Route for human review** since the content contains hate speech and violence references

You'll see logs like:
```
Content submitted for moderation: submissionId=sub_123, hasText=true, userId=user456
Starting content analysis: submissionId=sub_123, hasText=true
Content analysis completed: submissionId=sub_123, overallScore=0.87, textScore=0.87
Content needs human review: submissionId=sub_123, overallScore=0.87
```

### Step 3: Slack Notification for Human Review

The system automatically sends an interactive message to your moderation team in Slack:

<div className="my-8">![AI Content Moderation Slack Output](./../img/ai-content-moderation-slack-output.png)</div>

The Slack message includes:
- **Risk score**: 87% confidence of harmful content
- **Priority level**: HIGH (since score â‰¥ 70%)
- **AI analysis**: Detailed breakdown of detected issues
- **Interactive buttons**: Approve, Reject, or Escalate options

### Step 4: Human Decision & Execution

When a moderator clicks a button in Slack:
1. **Decision is recorded** with moderator attribution
2. **Content is processed** according to the decision
3. **User is notified** of the moderation outcome
4. **Audit trail is maintained** for compliance

The complete workflow demonstrates how AI handles the initial analysis while humans provide the final judgment for nuanced decisions.

---

## Key Features & Benefits

### ðŸ¤– **AI-Powered Analysis**
Advanced OpenAI integration for both text toxicity detection and image safety analysis with confidence scoring.

### ðŸŽ¯ **Intelligent Routing**
Confidence-based decision making that automatically handles clear cases while flagging uncertain content for human review.

### ðŸ’¬ **Slack Integration**
Interactive moderation workflows within existing team communication tools - no custom dashboard required.

### ðŸ‘¥ **Human-in-the-Loop**
Seamless integration of human decision-making with approve/reject/escalate buttons and contextual information.

### ðŸ“Š **Priority-Based Routing**
Content is routed to different Slack channels based on risk level and urgency.

### ðŸ”’ **Security & Compliance**
Built-in signature verification, audit trails, and comprehensive logging for compliance requirements.

---

## Getting Started

Ready to build your own intelligent content moderation system? Here's how to set it up and run it.

<Steps>

### 1. Install Dependencies

Install the necessary npm packages and set up the development environment.

```shell
npm install
```

### 2. Configure Environment Variables

Create a `.env` file with your API keys and Slack configuration:

```shell
# Required: OpenAI API key for content analysis
OPENAI_API_KEY="sk-..."

# Required: Slack bot configuration
SLACK_BOT_TOKEN="xoxb-your-bot-token"
SLACK_SIGNING_SECRET="your-signing-secret"

# Required: Slack channels for different priority levels
SLACK_CHANNEL_MODERATION="C1234567890"  # Normal priority
SLACK_CHANNEL_URGENT="C0987654321"      # High priority
SLACK_CHANNEL_ESCALATED="C1122334455"   # Escalated content
```

### 3. Set Up Slack Integration

1. Create a Slack app with the following permissions:
   - `chat:write` - Send messages to channels
   - `channels:read` - Access channel information
2. Enable Interactive Components and set webhook URL to: `https://your-domain.com/slack/webhook`
3. Install the app to your workspace
4. Copy the bot token and signing secret to your `.env` file

### 4. Run the Moderation System

Start the Motia development server to begin processing content.

```shell
npm run dev
```

</Steps>

---

## Advanced Configuration

### Adjusting Confidence Thresholds

Modify the decision thresholds in the content router step:

```typescript
// In 03-content-router.step.ts
if (overallScore <= 0.05) {
  decision = "approved"; // Auto-approve threshold (5%)
} else if (overallScore >= 0.95) {
  decision = "rejected"; // Auto-reject threshold (95%)
} else {
  decision = "review"; // Human review range (5-95%)
}
```

### Custom Channel Routing

Implement custom routing logic based on content type or user behavior:

```typescript
// Route based on user history or content type
const channel = getChannelForContent(contentType, userHistory, riskScore);
```

### Integration with External Systems

Extend the action executor to integrate with your existing systems:

```typescript
// In 06-action-executor.step.ts
case "approved":
  await publishContent(submissionId);
  await notifyUser(userId, "Your content has been approved");
  break;
```

---

## ðŸ’» Dive into the Code

Want to explore the complete content moderation implementation? Check out the full source code, including all steps, Slack integration, and production-ready configuration:

<div className="not-prose">
  <div className="bg-gradient-to-r from-purple-50 to-pink-50 border border-purple-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-purple-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete Content Moderation System</h3>
        <p className="text-gray-600 mb-4">Access the full implementation with AI analysis, Slack integration, and human-in-the-loop workflows.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-content-moderation" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Content Moderation Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Intelligent Content Moderation at Scale

This content moderation system demonstrates the power of combining AI analysis with human oversight in an event-driven architecture. By breaking down moderation into discrete, specialized components, we've created a system that's not only intelligent but also flexible and maintainable.

The human-in-the-loop approach means you can:
- **Scale efficiently**: Automatically handle 80-90% of content while maintaining quality
- **Adapt quickly**: Adjust thresholds and routing logic without system changes
- **Maintain oversight**: Human moderators focus on complex cases that require judgment
- **Integrate seamlessly**: Use existing team communication tools like Slack

Key architectural benefits:
- **Intelligent routing**: Confidence-based decisions reduce human workload
- **Flexible integration**: Works with any team communication platform
- **Audit compliance**: Complete decision trails and moderator attribution
- **Scalable architecture**: Each component can be scaled independently

From here, you can extend the system by:
- Adding support for video content moderation
- Implementing custom AI models for specific content types
- Building analytics dashboards for moderation insights
- Integrating with user management and content management systems
- Adding escalation policies and moderator workflows

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing moderation pipeline.

Ready to build content moderation that scales with your platform? Start building with Motia today!


-   [ai-deep-research-agent](/docs/examples/ai-deep-research-agent): Documentation for ai-deep-research-agent.
---
title: 'AI Research Agent'
description: A powerful research assistant that leverages the Motia Framework to perform comprehensive web research on any topic and any question.
---

import { CodeFetcher } from '../../../components/CodeFetcher'

---

## Explore the Workbench

<div className="my-8">![AI Deep Research Agent](./../img/ai-deep-research-agent.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-deep-research-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a AI Deep Research Agent that:

- **Deep Web Research**: Automatically searches the web, extracts content, and synthesizes findings
- **Iterative Research Process**: Supports multiple layers of research depth for comprehensive exploration
- **Event-Driven Architecture**: Built using Motia Framework's event system for robust workflow management
- **Parallel Processing**: Efficiently processes search results and content extraction
- **API Endpoints**: REST API access for initiating research and retrieving reports
- **Stateful Processing**: Maintains research state throughout the entire process

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-content.step.ts" />
  <File name="compile-report.step.ts" />
  <File name="extract-content.step.ts" />
  <File name="follow-up-research.step.ts" />
  <File name="generate-queries.step.ts" />
  <File name="report-api.step.ts" />
  <File name="research-api.step.ts" />
  <File name="search-web.step.ts" />
  <File name="status-api.step.ts" />
</Folder>

<Tabs items={['analyze-content', 'compile-report', 'extract-content', 'follow-up-research', 'generate-queries', 'report-api', 'research-api', 'search-web', 'status-api']}>
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="analyze-content" value="analyze-content" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="compile-report" value="compile-report" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="extract-content" value="extract-content" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="follow-up-research" value="follow-up-research" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="generate-queries" value="generate-queries" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="report-api" value="report-api" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="research-api" value="research-api" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="search-web" value="search-web" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="status-api" value="status-api" />
</Tabs>

## ðŸš€ Features

- **Deep Web Research**: Automatically searches the web, extracts content, and synthesizes findings
- **Iterative Research Process**: Supports multiple layers of research depth for comprehensive exploration
- **Event-Driven Architecture**: Built using Motia Framework's event system for robust workflow management
- **Parallel Processing**: Efficiently processes search results and content extraction
- **API Endpoints**: REST API access for initiating research and retrieving reports
- **Stateful Processing**: Maintains research state throughout the entire process

## ðŸ“‹ Prerequisites

- Node.js v18 or later
- npm or pnpm
- API keys for:
  - [OpenAI](https://platform.openai.com/) (AI analysis)
  - [Firecrawl](https://www.firecrawl.dev/) (Web Crawler)

## ðŸ› ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/ai-deep-research-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   # Required
   OPENAI_API_KEY=your-openai-api-key-here
   FIRECRAWL_API_KEY=your-firecrawl-api-key-here

   # Optional
   # OPENAI_MODEL=gpt-4o
   # FIRECRAWL_BASE_URL=http://your-firecrawl-instance-url
   ```

## ðŸ—ï¸ Architecture

![AI Deep Research Agent](../img/ai-deep-research-agent.png)


## ðŸš¦ API Endpoints

### Start Research

```
POST /research
Content-Type: application/json

{
  "query": "The research topic or question",
  "breadth": 4,  // Number of search queries to generate (1-10)
  "depth": 2     // Depth of research iterations (1-5)
}
```

Response:
```json
{
  "message": "Research process started",
  "requestId": "unique-trace-id"
}
```

### Check Research Status

```
GET /research/status?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research status retrieved successfully",
  "requestId": "unique-trace-id",
  "originalQuery": "The research topic or question",
  "status": "in-progress",
  "progress": {
    "currentDepth": 1,
    "totalDepth": 2,
    "percentComplete": 50
  },
  "reportAvailable": false
}
```

### Get Research Report

```
GET /research/report?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research report retrieved successfully",
  "report": {
    "title": "Research Report Title",
    "overview": "Executive summary...",
    "sections": [
      {
        "title": "Section Title",
        "content": "Section content..."
      }
    ],
    "keyTakeaways": [
      "Key takeaway 1",
      "Key takeaway 2"
    ],
    "sources": [
      {
        "title": "Source Title",
        "url": "Source URL"
      }
    ],
    "originalQuery": "The research topic or question",
    "metadata": {
      "depthUsed": 2,
      "completedAt": "2025-03-18T16:45:30Z"
    }
  },
  "requestId": "unique-trace-id"
}
```

## ðŸƒâ€â™‚ï¸ Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Access the Motia Workbench:
   ```
   http://localhost:3000
   ```

3. Make a test request:
   ```bash
   curl --request POST \
   --url http://localhost:3000/research \
   --header 'Content-Type: application/json' \
   --data '{
      "query": "Advancements in renewable energy storage",
      "depth": 1,
      "breadth": 1
   }'
   ```
## ðŸ™ Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [OpenAI](https://platform.openai.com/) for AI analysis 
- [Firecrawl](https://www.firecrawl.dev/) for Web search and content extraction API


## Examples
[ai-deep-research-agent](/docs/examples/ai-deep-research-agent): Code example
---
title: 'AI Research Agent'
description: A powerful research assistant that leverages the Motia Framework to perform comprehensive web research on any topic and any question.
---

import { CodeFetcher } from '../../../components/CodeFetcher'

---

## Explore the Workbench

<div className="my-8">![AI Deep Research Agent](./../img/ai-deep-research-agent.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/ai-deep-research-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a AI Deep Research Agent that:

- **Deep Web Research**: Automatically searches the web, extracts content, and synthesizes findings
- **Iterative Research Process**: Supports multiple layers of research depth for comprehensive exploration
- **Event-Driven Architecture**: Built using Motia Framework's event system for robust workflow management
- **Parallel Processing**: Efficiently processes search results and content extraction
- **API Endpoints**: REST API access for initiating research and retrieving reports
- **Stateful Processing**: Maintains research state throughout the entire process

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-content.step.ts" />
  <File name="compile-report.step.ts" />
  <File name="extract-content.step.ts" />
  <File name="follow-up-research.step.ts" />
  <File name="generate-queries.step.ts" />
  <File name="report-api.step.ts" />
  <File name="research-api.step.ts" />
  <File name="search-web.step.ts" />
  <File name="status-api.step.ts" />
</Folder>

<Tabs items={['analyze-content', 'compile-report', 'extract-content', 'follow-up-research', 'generate-queries', 'report-api', 'research-api', 'search-web', 'status-api']}>
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="analyze-content" value="analyze-content" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="compile-report" value="compile-report" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="extract-content" value="extract-content" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="follow-up-research" value="follow-up-research" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="generate-queries" value="generate-queries" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="report-api" value="report-api" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="research-api" value="research-api" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="search-web" value="search-web" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="status-api" value="status-api" />
</Tabs>

## ðŸš€ Features

- **Deep Web Research**: Automatically searches the web, extracts content, and synthesizes findings
- **Iterative Research Process**: Supports multiple layers of research depth for comprehensive exploration
- **Event-Driven Architecture**: Built using Motia Framework's event system for robust workflow management
- **Parallel Processing**: Efficiently processes search results and content extraction
- **API Endpoints**: REST API access for initiating research and retrieving reports
- **Stateful Processing**: Maintains research state throughout the entire process

## ðŸ“‹ Prerequisites

- Node.js v18 or later
- npm or pnpm
- API keys for:
  - [OpenAI](https://platform.openai.com/) (AI analysis)
  - [Firecrawl](https://www.firecrawl.dev/) (Web Crawler)

## ðŸ› ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/ai-deep-research-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   # Required
   OPENAI_API_KEY=your-openai-api-key-here
   FIRECRAWL_API_KEY=your-firecrawl-api-key-here

   # Optional
   # OPENAI_MODEL=gpt-4o
   # FIRECRAWL_BASE_URL=http://your-firecrawl-instance-url
   ```

## ðŸ—ï¸ Architecture

![AI Deep Research Agent](../img/ai-deep-research-agent.png)


## ðŸš¦ API Endpoints

### Start Research

```
POST /research
Content-Type: application/json

{
  "query": "The research topic or question",
  "breadth": 4,  // Number of search queries to generate (1-10)
  "depth": 2     // Depth of research iterations (1-5)
}
```

Response:
```json
{
  "message": "Research process started",
  "requestId": "unique-trace-id"
}
```

### Check Research Status

```
GET /research/status?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research status retrieved successfully",
  "requestId": "unique-trace-id",
  "originalQuery": "The research topic or question",
  "status": "in-progress",
  "progress": {
    "currentDepth": 1,
    "totalDepth": 2,
    "percentComplete": 50
  },
  "reportAvailable": false
}
```

### Get Research Report

```
GET /research/report?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research report retrieved successfully",
  "report": {
    "title": "Research Report Title",
    "overview": "Executive summary...",
    "sections": [
      {
        "title": "Section Title",
        "content": "Section content..."
      }
    ],
    "keyTakeaways": [
      "Key takeaway 1",
      "Key takeaway 2"
    ],
    "sources": [
      {
        "title": "Source Title",
        "url": "Source URL"
      }
    ],
    "originalQuery": "The research topic or question",
    "metadata": {
      "depthUsed": 2,
      "completedAt": "2025-03-18T16:45:30Z"
    }
  },
  "requestId": "unique-trace-id"
}
```

## ðŸƒâ€â™‚ï¸ Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Access the Motia Workbench:
   ```
   http://localhost:3000
   ```

3. Make a test request:
   ```bash
   curl --request POST \
   --url http://localhost:3000/research \
   --header 'Content-Type: application/json' \
   --data '{
      "query": "Advancements in renewable energy storage",
      "depth": 1,
      "breadth": 1
   }'
   ```
## ðŸ™ Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [OpenAI](https://platform.openai.com/) for AI analysis 
- [Firecrawl](https://www.firecrawl.dev/) for Web search and content extraction API

-   [finance-agent](/docs/examples/finance-agent): Documentation for finance-agent.
---
title: 'Finance Agent'
description: A powerful event-driven financial analysis workflow that combines web search, financial data, and AI analysis to provide comprehensive investment insights.
---

import { CodeFetcher } from '../../../components/CodeFetcher'

---

## Explore the Workbench

<div className="my-8">![Finance Agent](./../img/finance-agent.gif)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/finance-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a finance agent that:

- Real-time Financial Analysis: Combines multiple data sources for comprehensive insights
- AI-Powered Insights: Leverages OpenAI GPT-4 for intelligent market analysis
- Web Search Integration: Aggregates latest market news and analysis
- Financial Data Integration: Real-time stock and company information

## The Steps

<Folder name="steps" defaultOpen>
  <File name="finance-data.step.ts" />
  <File name="openai-analysis.step.ts" />
  <File name="query-api.step.ts" />
  <File name="response-coordinator.step.ts" />
  <File name="result-api.step.ts" />
  <File name="save-result.step.ts" />
  <File name="web-search.step.ts" />
</Folder>

<Tabs items={['finance-data', 'openai-analysis', 'query-api', 'response-coordinator', 'result-api', 'save-result', 'web-search']}>
  <CodeFetcher path="examples/finance-agent/steps" tab="finance-data" value="finance-data" />
  <CodeFetcher path="examples/finance-agent/steps" tab="openai-analysis" value="openai-analysis" />
  <CodeFetcher path="examples/finance-agent/steps" tab="query-api" value="query-api" />
  <CodeFetcher path="examples/finance-agent/steps" tab="response-coordinator" value="response-coordinator" />
  <CodeFetcher path="examples/finance-agent/steps" tab="result-api" value="result-api" />
  <CodeFetcher path="examples/finance-agent/steps" tab="save-result" value="save-result" />
  <CodeFetcher path="examples/finance-agent/steps" tab="web-search" value="web-search" />
</Tabs>

## ðŸš€ Features

- **Real-time Financial Analysis**: Combines multiple data sources for comprehensive insights
- **AI-Powered Insights**: Leverages OpenAI GPT-4 for intelligent market analysis
- **Event-Driven Architecture**: Built on Motia's robust event system for reliable processing
- **Web Search Integration**: Aggregates latest market news and analysis
- **Financial Data Integration**: Real-time stock and company information
- **Persistent Storage**: Stores analysis results for future reference
- **RESTful API**: Easy integration with existing systems

## ðŸ“‹ Prerequisites

- Node.js v16+
- npm or pnpm
- API keys for:
  - [Alpha Vantage](https://www.alphavantage.co/) (financial data)
  - [SerperDev](https://serper.dev/) (web search)
  - [OpenAI](https://platform.openai.com/) (AI analysis)

## ðŸ› ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/finance-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   ALPHA_VANTAGE_API_KEY=your_alpha_vantage_api_key_here
   SERPER_API_KEY=your_serper_api_key_here
   OPENAI_API_KEY=your_openai_api_key_here
   ```

## ðŸ—ï¸ Architecture

The workflow consists of several specialized steps that work together to provide comprehensive financial analysis:

![Finance Agent](../img/finance-agent.gif)


## ðŸš¦ API Endpoints

### Query Endpoint

```http
POST /finance-query
Content-Type: application/json

{
  "query": "Latest information about AAPL and MSFT"
}
```

Response:
```json
{
  "message": "Query received and processing started",
  "traceId": "abc123def456"
}
```

### Results Endpoint

```http
GET /finance-result/:traceId
```

Response:
```json
{
  "query": "Latest information about AAPL and MSFT",
  "timestamp": "2023-06-15T12:34:56.789Z",
  "response": {
    "summary": "Results for \"Latest information about AAPL and MSFT\"",
    "webResources": [...],
    "financialData": [...],
    "aiAnalysis": {...}
  },
  "status": "success"
}
```

## ðŸƒâ€â™‚ï¸ Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Access the Motia Workbench:
   ```
   http://localhost:3000
   ```

3. Make a test request:
   ```bash
   curl -X POST http://localhost:3000/finance-query \
     -H "Content-Type: application/json" \
     -d '{"query": "Latest information about AAPL and MSFT"}'
   ```
## ðŸ™ Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [Alpha Vantage](https://www.alphavantage.co/) for financial data
- [SerperDev](https://serper.dev/) for web search capabilities
- [OpenAI](https://platform.openai.com/) for AI analysis 


## Examples
[finance-agent](/docs/examples/finance-agent): Code example
---
title: 'Finance Agent'
description: A powerful event-driven financial analysis workflow that combines web search, financial data, and AI analysis to provide comprehensive investment insights.
---

import { CodeFetcher } from '../../../components/CodeFetcher'

---

## Explore the Workbench

<div className="my-8">![Finance Agent](./../img/finance-agent.gif)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/finance-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a finance agent that:

- Real-time Financial Analysis: Combines multiple data sources for comprehensive insights
- AI-Powered Insights: Leverages OpenAI GPT-4 for intelligent market analysis
- Web Search Integration: Aggregates latest market news and analysis
- Financial Data Integration: Real-time stock and company information

## The Steps

<Folder name="steps" defaultOpen>
  <File name="finance-data.step.ts" />
  <File name="openai-analysis.step.ts" />
  <File name="query-api.step.ts" />
  <File name="response-coordinator.step.ts" />
  <File name="result-api.step.ts" />
  <File name="save-result.step.ts" />
  <File name="web-search.step.ts" />
</Folder>

<Tabs items={['finance-data', 'openai-analysis', 'query-api', 'response-coordinator', 'result-api', 'save-result', 'web-search']}>
  <CodeFetcher path="examples/finance-agent/steps" tab="finance-data" value="finance-data" />
  <CodeFetcher path="examples/finance-agent/steps" tab="openai-analysis" value="openai-analysis" />
  <CodeFetcher path="examples/finance-agent/steps" tab="query-api" value="query-api" />
  <CodeFetcher path="examples/finance-agent/steps" tab="response-coordinator" value="response-coordinator" />
  <CodeFetcher path="examples/finance-agent/steps" tab="result-api" value="result-api" />
  <CodeFetcher path="examples/finance-agent/steps" tab="save-result" value="save-result" />
  <CodeFetcher path="examples/finance-agent/steps" tab="web-search" value="web-search" />
</Tabs>

## ðŸš€ Features

- **Real-time Financial Analysis**: Combines multiple data sources for comprehensive insights
- **AI-Powered Insights**: Leverages OpenAI GPT-4 for intelligent market analysis
- **Event-Driven Architecture**: Built on Motia's robust event system for reliable processing
- **Web Search Integration**: Aggregates latest market news and analysis
- **Financial Data Integration**: Real-time stock and company information
- **Persistent Storage**: Stores analysis results for future reference
- **RESTful API**: Easy integration with existing systems

## ðŸ“‹ Prerequisites

- Node.js v16+
- npm or pnpm
- API keys for:
  - [Alpha Vantage](https://www.alphavantage.co/) (financial data)
  - [SerperDev](https://serper.dev/) (web search)
  - [OpenAI](https://platform.openai.com/) (AI analysis)

## ðŸ› ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/finance-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   ALPHA_VANTAGE_API_KEY=your_alpha_vantage_api_key_here
   SERPER_API_KEY=your_serper_api_key_here
   OPENAI_API_KEY=your_openai_api_key_here
   ```

## ðŸ—ï¸ Architecture

The workflow consists of several specialized steps that work together to provide comprehensive financial analysis:

![Finance Agent](../img/finance-agent.gif)


## ðŸš¦ API Endpoints

### Query Endpoint

```http
POST /finance-query
Content-Type: application/json

{
  "query": "Latest information about AAPL and MSFT"
}
```

Response:
```json
{
  "message": "Query received and processing started",
  "traceId": "abc123def456"
}
```

### Results Endpoint

```http
GET /finance-result/:traceId
```

Response:
```json
{
  "query": "Latest information about AAPL and MSFT",
  "timestamp": "2023-06-15T12:34:56.789Z",
  "response": {
    "summary": "Results for \"Latest information about AAPL and MSFT\"",
    "webResources": [...],
    "financialData": [...],
    "aiAnalysis": {...}
  },
  "status": "success"
}
```

## ðŸƒâ€â™‚ï¸ Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Access the Motia Workbench:
   ```
   http://localhost:3000
   ```

3. Make a test request:
   ```bash
   curl -X POST http://localhost:3000/finance-query \
     -H "Content-Type: application/json" \
     -d '{"query": "Latest information about AAPL and MSFT"}'
   ```
## ðŸ™ Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [Alpha Vantage](https://www.alphavantage.co/) for financial data
- [SerperDev](https://serper.dev/) for web search capabilities
- [OpenAI](https://platform.openai.com/) for AI analysis 

-   [github-integration-workflow](/docs/examples/github-integration-workflow): Documentation for github-integration-workflow.
---
title: 'GitHub Integration'
description: Build an automated GitHub issue and PR management system with AI-powered classification and routing
---

---

## Explore the Workbench

<div className="my-8">![GitHub Issue Workflow](./../img/github-issue-workflow.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a GitHub automation system that:

1. Automatically triages and classifies new issues
2. Intelligently assigns labels based on content
3. Suggests appropriate assignees and reviewers
4. Monitors PR test status
5. Generates contextual comments

## Workflow Structure

The GitHub integration workflow is organized into two main components:

- **Issue Triage**: Handles the management of GitHub issues
- **PR Classifier**: Manages pull request workflows

## The Steps

<Folder name="steps" defaultOpen>
  <Folder name="issue-triage" defaultOpen>
    <File name="github-webhook.step.ts" />
    <File name="issue-classifier.step.ts" />
    <File name="label-assigner.step.ts" />
    <File name="assignee-selector.step.ts" />
    <File name="handle-new-issue.step.ts" />
    <File name="handle-issue-update.step.ts" />
    <File name="handle-issue-closure.step.ts" />
  </Folder>
  <Folder name="pr-classifier" defaultOpen>
    <File name="pr-webhook.step.ts" />
    <File name="pr-classifier.step.ts" />
    <File name="pr-label-assigner.step.ts" />
    <File name="pr-reviewer-assigner.step.ts" />
    <File name="pr-test-monitor.step.ts" />
  </Folder>
</Folder>

<Tabs items={['issue-webhook', 'issue-classifier', 'label-assigner', 'assignee-selector']}>
  <GitHubWorkflowTab tab="issue-webhook" value="github-webhook" folder="issue-triage" />
  <GitHubWorkflowTab tab="issue-classifier" value="issue-classifier" folder="issue-triage" />
  <GitHubWorkflowTab tab="label-assigner" value="label-assigner" folder="issue-triage" />
  <GitHubWorkflowTab tab="assignee-selector" value="assignee-selector" folder="issue-triage" />
</Tabs>

<Tabs items={['pr-webhook', 'pr-classifier', 'pr-reviewer', 'pr-monitor']}>
  <GitHubWorkflowTab tab="pr-webhook" value="pr-webhook" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-classifier" value="pr-classifier" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-reviewer" value="pr-reviewer-assigner" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-monitor" value="pr-test-monitor" folder="pr-classifier" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: GitHub Issue Workflow](../img/github-issue-workflow.png)</div>
<div className="my-8">![Flow: GitHub PR Workflow](../img/github-pr-workflow.png)</div>

1. **Webhook Reception** â†’ Captures GitHub events
2. **Issue/PR Classification** â†’ Analyzes content with AI
3. **Automated Labeling** â†’ Applies appropriate labels
4. **Smart Assignment** â†’ Suggests reviewers and assignees
5. **Status Monitoring** â†’ Tracks PR test status

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- GitHub account with personal access token
- Node.js installed
- OpenAI API key (for AI classification)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/github-integration-workflow
```

### Install Dependencies

```bash
npm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
GITHUB_TOKEN=your_github_token_here
OPENAI_API_KEY=your_openai_api_key
```

### Set Up GitHub Webhook

1. Go to your GitHub repository settings
2. Navigate to Webhooks and add a new webhook
3. Set the Payload URL to your Motia server endpoint
4. Select content type as `application/json`
5. Choose which events to trigger the webhook (Issues, Pull requests)
6. Save the webhook

### Run the Application

```bash
npm run dev
```

### Test the Flow

1. Create a new issue in your GitHub repository
2. Watch as it gets automatically classified and labeled
3. Create a new PR to see the reviewer assignment in action
4. Check the PR comments for test status updates

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow).
</Callout> 


## Examples
[github-integration-workflow](/docs/examples/github-integration-workflow): Code example
---
title: 'GitHub Integration'
description: Build an automated GitHub issue and PR management system with AI-powered classification and routing
---

---

## Explore the Workbench

<div className="my-8">![GitHub Issue Workflow](./../img/github-issue-workflow.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a GitHub automation system that:

1. Automatically triages and classifies new issues
2. Intelligently assigns labels based on content
3. Suggests appropriate assignees and reviewers
4. Monitors PR test status
5. Generates contextual comments

## Workflow Structure

The GitHub integration workflow is organized into two main components:

- **Issue Triage**: Handles the management of GitHub issues
- **PR Classifier**: Manages pull request workflows

## The Steps

<Folder name="steps" defaultOpen>
  <Folder name="issue-triage" defaultOpen>
    <File name="github-webhook.step.ts" />
    <File name="issue-classifier.step.ts" />
    <File name="label-assigner.step.ts" />
    <File name="assignee-selector.step.ts" />
    <File name="handle-new-issue.step.ts" />
    <File name="handle-issue-update.step.ts" />
    <File name="handle-issue-closure.step.ts" />
  </Folder>
  <Folder name="pr-classifier" defaultOpen>
    <File name="pr-webhook.step.ts" />
    <File name="pr-classifier.step.ts" />
    <File name="pr-label-assigner.step.ts" />
    <File name="pr-reviewer-assigner.step.ts" />
    <File name="pr-test-monitor.step.ts" />
  </Folder>
</Folder>

<Tabs items={['issue-webhook', 'issue-classifier', 'label-assigner', 'assignee-selector']}>
  <GitHubWorkflowTab tab="issue-webhook" value="github-webhook" folder="issue-triage" />
  <GitHubWorkflowTab tab="issue-classifier" value="issue-classifier" folder="issue-triage" />
  <GitHubWorkflowTab tab="label-assigner" value="label-assigner" folder="issue-triage" />
  <GitHubWorkflowTab tab="assignee-selector" value="assignee-selector" folder="issue-triage" />
</Tabs>

<Tabs items={['pr-webhook', 'pr-classifier', 'pr-reviewer', 'pr-monitor']}>
  <GitHubWorkflowTab tab="pr-webhook" value="pr-webhook" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-classifier" value="pr-classifier" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-reviewer" value="pr-reviewer-assigner" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-monitor" value="pr-test-monitor" folder="pr-classifier" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: GitHub Issue Workflow](../img/github-issue-workflow.png)</div>
<div className="my-8">![Flow: GitHub PR Workflow](../img/github-pr-workflow.png)</div>

1. **Webhook Reception** â†’ Captures GitHub events
2. **Issue/PR Classification** â†’ Analyzes content with AI
3. **Automated Labeling** â†’ Applies appropriate labels
4. **Smart Assignment** â†’ Suggests reviewers and assignees
5. **Status Monitoring** â†’ Tracks PR test status

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- GitHub account with personal access token
- Node.js installed
- OpenAI API key (for AI classification)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/github-integration-workflow
```

### Install Dependencies

```bash
npm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
GITHUB_TOKEN=your_github_token_here
OPENAI_API_KEY=your_openai_api_key
```

### Set Up GitHub Webhook

1. Go to your GitHub repository settings
2. Navigate to Webhooks and add a new webhook
3. Set the Payload URL to your Motia server endpoint
4. Select content type as `application/json`
5. Choose which events to trigger the webhook (Issues, Pull requests)
6. Save the webhook

### Run the Application

```bash
npm run dev
```

### Test the Flow

1. Create a new issue in your GitHub repository
2. Watch as it gets automatically classified and labeled
3. Create a new PR to see the reviewer assignment in action
4. Check the PR comments for test status updates

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow).
</Callout> 

-   [github-stars-counter](/docs/examples/github-stars-counter): Documentation for github-stars-counter.
---
title: 'GitHub Stars Counter'
description: 'Real-Time GitHub Stars Counter: Building Live Updates with Motia Streams'
---

In today's social-driven development world, real-time metrics and live updates are essential for building engaging applications. Whether you're creating a portfolio site, an open-source project showcase, or a developer dashboard, you need systems that can display live data without complex infrastructure.

This comprehensive guide explores how to build a production-ready, real-time GitHub stars counter using Motia's event-driven architecture and streaming capabilities. We'll cover:

1. **Real-Time Streams**: How Motia's streams enable effortless live data synchronization
2. **Secure Webhooks**: Production-ready webhook signature verification and event handling
3. **Minimal Architecture**: Building powerful real-time features with just two components
4. **Live Integration**: How this exact counter powers the live star count on the Motia website

Let's build a stars counter that updates in real-time across all connected clients.

---

<div className="my-8">![GitHub Stars Counter Demo](./../img/gitstars-workbench.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/github-stars-counter)

---

## ðŸ­ Production-Grade Example

**This is not a tutorial project** - this is battle-tested, production-ready code that handles real traffic at scale. Every aspect has been designed for enterprise use:

- **ðŸ” Enterprise Security**: HMAC webhook verification, timing-safe comparisons, comprehensive input validation
- **âš¡ High Performance**: Handles thousands of concurrent connections with automatic scaling
- **ðŸ“Š Full Observability**: Structured logging, error tracking, and comprehensive monitoring
- **ðŸ›¡ï¸ Error Resilience**: Graceful degradation, retry logic, and fault tolerance
- **ðŸŒ Global Scale**: Production deployment on Motia Cloud with worldwide CDN
- **ðŸ’° Cost Efficient**: Serverless architecture that scales to zero when not in use

---

## Live Proof: Powering Motia.dev Header

**This isn't just a demo** - this exact code powers the live GitHub star counter you can see right now in the header of [Motia.dev](https://motia.dev)! 

Look at the top-right corner of the Motia website and you'll see:
- **ðŸ  Motia** logo on the left
- **ðŸ“‘ Blog, Docs, Manifesto** navigation 
- **â­ GitHub** icon with a **live star count** (currently showing 7953+ stars)
- **ðŸš€ Vercel OSS 2025** badge

That live-updating number next to the GitHub icon? That's this exact implementation in production, processing real webhook events and streaming updates to thousands of visitors in real-time!

---

## The Power of Real-Time Simplicity

At its core, our GitHub stars counter solves a fundamental challenge: how do you display live, real-time metrics without complex WebSocket infrastructure or manual state management? Traditional approaches often involve intricate server-side event handling, client connection management, and complex state synchronization.

Our Motia-powered solution breaks this down into just two simple components:

- **[GitHub Webhooks](https://docs.github.com/en/webhooks)**: Instant notifications when repository stars change
- **[Motia Streams](https://motia.dev)**: Real-time data synchronization with automatic state management
- **[Production Security](https://docs.github.com/en/webhooks/securing)**: Built-in webhook signature verification

ðŸŽ¯ **Live in Action**: This exact implementation powers the real-time star counter visible in the header of [Motia.dev](https://motia.dev) (look for the GitHub icon with live count), updating instantly whenever developers star the repository!

Instead of complex infrastructure, we get a resilient real-time system where data flows effortlessly from GitHub events to live client updates.

---

## The Anatomy of Our Real-Time Counter

Our application consists of just two specialized components, each handling a specific part of the real-time data flow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="00-repository-stars.stream.ts" />
  <File name="01-github-webhook.step.ts" />
</Folder>

<Folder name="utils" defaultOpen>
  <File name="verify-webhook-signature.ts" />
  <File name="check-user-profile.ts" />
</Folder>

<Tabs items={['stream-config', 'webhook-handler', 'signature-verification', 'user-profile']}>
  <Tab value="stream-config">
    The real-time data stream that holds our repository star counts. This stream automatically synchronizes data to all connected clients with zero configuration.

    ```typescript
    import { StreamConfig } from 'motia'
    import { z } from 'zod'

    const RepositoryStarsSchema = z.object({
      stars: z.number(),
      name: z.string(),
      fullName: z.string(),
      organization: z.string(),
      lastUpdated: z.string(),
    })

    export type RepositoryStars = z.infer<typeof RepositoryStarsSchema>

    export const config: StreamConfig = {
      name: 'stars',
      schema: RepositoryStarsSchema,
      baseConfig: { storageType: 'default' },
    }
    ```

  </Tab>
  <Tab value="webhook-handler">
    The secure webhook endpoint that receives GitHub star events, verifies their authenticity, and updates the real-time stream with new star counts.

    ```typescript
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'
    import { verifyWebhookSignature } from '../utils/verify-webhook-signature'
    import { checkUserProfile } from '../utils/check-user-profile'

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'GitHubStarWebhook',
      description: 'Process GitHub star webhook events with signature verification',
      method: 'POST',
      path: '/webhooks/github/star',
      bodySchema: z.object({
        action: z.enum(['created', 'deleted']),
        starred_at: z.string().optional(),
        repository: z.object({
          name: z.string(),
          full_name: z.string(),
          stargazers_count: z.number(),
          owner: z.object({ login: z.string() }),
        }),
        sender: z.object({
          login: z.string(),
          name: z.string(),
          avatar_url: z.string().optional(),
          html_url: z.string(),
          url: z.string({ description: 'API URL' }),
        }),
      }),
      responseSchema: {
        200: z.object({
          message: z.string(),
          event: z.string(),
          processed: z.boolean(),
        }),
        400: z.object({ error: z.string() }),
        401: z.object({ error: z.string() }),
        500: z.object({ error: z.string() }),
      },
      emits: [],
      flows: ['github-star-processing'],
    }

    export const handler: Handlers['GitHubStarWebhook'] = async (
      req,
      { logger, streams, state, traceId }
    ) => {
      try {
        // Extract and validate GitHub headers
        const githubEvent = req.headers['x-github-event'] as string
        const githubDelivery = req.headers['x-github-delivery'] as string
        const githubSignature = req.headers['x-hub-signature-256'] as string
        const githubSignatureSha1 = req.headers['x-hub-signature'] as string

        // Only process star events
        if (githubEvent !== 'star') {
          logger.info('Ignoring non-star event', { githubEvent, githubDelivery })

          return {
            status: 200,
            body: {
              message: 'Event ignored - only processing star events',
              event: githubEvent,
              processed: false,
            },
          }
        }

        // Verify webhook signature if secret is configured
        const webhookSecret = process.env.GITHUB_WEBHOOK_SECRET

        if (webhookSecret) {
          logger.info('Verifying webhook signature', {
            delivery: githubDelivery,
            event: githubEvent,
          })

          const isValidSignature = verifyWebhookSignature({
            payload: JSON.stringify(req.body),
            signature: githubSignature || githubSignatureSha1,
            secret: webhookSecret,
            algorithm: githubSignature ? 'sha256' : 'sha1',
          })

          if (!isValidSignature) {
            logger.warn('Invalid webhook signature', {
              delivery: githubDelivery,
              event: githubEvent,
            })

            return {
              status: 401,
              body: { error: 'Invalid webhook signature' },
            }
          }
        }

        // Extract repository and user data
        const repository = {
          fullName: req.body.repository.full_name,
          name: req.body.repository.name,
          organization: req.body.repository.owner.login,
        }

        const sender = {
          name: req.body.sender.name,
          login: req.body.sender.login,
          avatarUrl: req.body.sender.avatar_url,
          url: req.body.sender.html_url,
          apiUrl: req.body.sender.url,
        }

        // Prepare star data for stream
        const webhookData = {
          fullName: repository.fullName,
          name: repository.name,
          organization: repository.organization,
          lastUpdated: req.body.starred_at || new Date().toISOString(),
          stars: req.body.repository.stargazers_count,
        }

        // Update real-time stream - this automatically propagates to all clients!
        await streams.stars.set(repository.organization, repository.name, webhookData)

        logger.info('GitHub star webhook processed successfully', { ...webhookData, sender })

        // Optional: Fetch additional user profile data
        if (sender.apiUrl) {
          try {
            logger.info('Getting GitHub user profile', { apiUrl: sender.apiUrl })
            const userProfile = await checkUserProfile(sender.apiUrl)
            await state.set(repository.fullName, traceId, userProfile)
            logger.info('GitHub user profile', { userProfile })
          } catch (error: any) {
            logger.error('Failed to get GitHub user profile', { error: error.message })
          }
        }

        return {
          status: 200,
          body: {
            message: 'Star webhook processed successfully',
            event: githubEvent,
            processed: true,
          },
        }
      } catch (error: any) {
        logger.error('GitHub star webhook processing failed', {
          error: error.message,
          stack: error.stack,
        })

        return {
          status: 500,
          body: { error: 'Star webhook processing failed' },
        }
      }
    }
    ```

  </Tab>
  <Tab value="signature-verification">
    Production-ready webhook security that verifies GitHub webhook signatures using HMAC cryptographic validation to ensure requests are authentic.

    ```typescript
    import crypto from 'crypto'

    type Args = {
      payload: string
      signature: string
      secret: string
      algorithm: 'sha1' | 'sha256'
    }

    export function verifyWebhookSignature(args: Args): boolean {
      const { payload, signature, secret, algorithm = 'sha256' } = args

      try {
        if (!signature) return false

        // Generate expected signature using HMAC
        const expectedSignature =
          algorithm === 'sha256'
            ? `sha256=${crypto.createHmac('sha256', secret).update(payload, 'utf8').digest('hex')}`
            : `sha1=${crypto.createHmac('sha1', secret).update(payload, 'utf8').digest('hex')}`

        // Use timing-safe comparison to prevent timing attacks
        return crypto.timingSafeEqual(Buffer.from(signature), Buffer.from(expectedSignature))
      } catch (error) {
        return false
      }
    }
    ```

  </Tab>
  <Tab value="user-profile">
    Optional GitHub user profile fetching that enriches webhook events with additional user information for analytics and user insights.

    ```typescript
    export interface GitHubUserProfile {
      login: string
      id: number
      node_id: string
      avatar_url: string
      gravatar_id: string
      url: string
      html_url: string
      followers_url: string
      following_url: string
      gists_url: string
      starred_url: string
      subscriptions_url: string
      organizations_url: string
      repos_url: string
      events_url: string
      received_events_url: string
      type: string
      user_view_type: string
      site_admin: boolean
      name: string | null
      company: string | null
      blog: string
      location: string | null
      email: string | null
      hireable: boolean | null
      bio: string | null
      twitter_username: string | null
      public_repos: number
      public_gists: number
      followers: number
      following: number
      created_at: string
      updated_at: string
    }

    export interface GitHubUserProfileResponse {
      followers: number
      bio: string | null
      email: string | null
      htmlUrl: string
      name: string | null
      login: string
      location: string | null
    }

    export const checkUserProfile = async (apiUrl: string): Promise<GitHubUserProfileResponse> => {
      const response = await fetch(apiUrl)
      const data = (await response.json()) as GitHubUserProfile

      return {
        followers: data.followers,
        bio: data.bio,
        email: data.email,
        htmlUrl: data.html_url,
        name: data.name,
        login: data.login,
        location: data.location,
      }
    }
    ```

  </Tab>
</Tabs>

---

## Real-Time Data Flow

The beauty of this architecture lies in its simplicity. Here's how real-time updates flow through the system:

1. **GitHub Event** â†’ User stars/unstars your repository
2. **Webhook Delivery** â†’ GitHub sends POST request to your endpoint  
3. **Security Validation** â†’ Signature verification ensures request authenticity
4. **Stream Update** â†’ Data is written to Motia stream with `streams.stars.set()`
5. **Live Propagation** â†’ All connected clients automatically receive the update
6. **UI Updates** â†’ Client applications re-render with new star count

**No manual WebSocket management, no connection handling, no state synchronization code required!**

---

## Key Features & Benefits

### âš¡ **Instant Real-Time Updates**
Stars update across all connected clients the moment GitHub sends the webhook - no polling, no delays.

### ðŸ” **Production-Ready Security**  
HMAC signature verification with timing-safe comparison prevents unauthorized webhook requests.

### ðŸ§© **Minimal Architecture**
Just two components handle the complete real-time functionality - no complex infrastructure required.

### ðŸ“Š **Automatic State Management**
Motia streams handle data persistence, synchronization, and client updates automatically.

### ðŸŽ¯ **Type-Safe Development**
Full TypeScript integration with Zod validation ensures zero runtime surprises.

### ðŸŒ **Live Production Usage**
This exact implementation powers the real-time counter visible in the Motia website header - go check it out now!

### ðŸš€ **Production-Grade Architecture**
Built for enterprise scale with proper error handling, security, monitoring, and deployment automation.

---

## Trying It Out

Ready to build your own real-time GitHub stars counter? Let's get it running.

<Steps>

### Clone and Install

Start by getting the project locally and installing dependencies.

```shell
git clone https://github.com/MotiaDev/github-stars-counter.git
cd github-stars-counter
npm install
```

### Configure GitHub Webhook (Optional)

Set up webhook security with a secret for production use. This is optional for testing but essential for production deployments.

```shell
# Generate a secure random secret
export GITHUB_WEBHOOK_SECRET=$(openssl rand -hex 32)
echo "GITHUB_WEBHOOK_SECRET=$GITHUB_WEBHOOK_SECRET" >> .env
```

### Start Development Server

Launch the Motia development server to begin receiving webhook events.

```shell
npm run dev
```

Your webhook endpoint will be available at: `http://localhost:3000/webhooks/github/star`

### Set Up GitHub Webhook

Configure GitHub to send star events to your endpoint:

1. Go to your GitHub repository settings
2. Navigate to **Settings** â†’ **Webhooks**  
3. Click **Add webhook**
4. Set **Payload URL** to your endpoint (use ngrok for local testing)
5. Set **Content type** to `application/json`
6. Add your webhook secret if configured
7. Select **Individual events** â†’ **Stars**
8. Click **Add webhook**

### Test the Real-Time Updates

Test your webhook by starring/unstarring your repository:

1. **Star your repository** on GitHub
2. **Check the logs** - you should see webhook processing
3. **Access the stream** - query `/api/streams/stars` to see current data
4. **Watch real-time updates** in the Motia Workbench

### Access Real-Time Data

Your star data is now available via the Motia streams API:

```shell
# Get all repository star counts
curl http://localhost:3000/api/streams/stars

# Get specific repository star count  
curl http://localhost:3000/api/streams/stars/{org}/{repo}
```

The response includes live star counts that update automatically whenever GitHub sends webhook events.

### Deploy to Production

Once your counter is working locally, deploy it to production with Motia Cloud:

**Option 1: CLI Deployment**
```shell
# Deploy with version and API key
motia cloud deploy --api-key your-api-key --version-name 1.0.0

# Deploy with environment variables
motia cloud deploy --api-key your-api-key \
  --version-name 1.0.0 \
  --env-file .env.production \
  --environment-id your-env-id
```

**Option 2: One-Click Web Deployment**
1. Ensure your local project is running (`npm run dev`)
2. Go to [Motia Cloud -> Import from Workbench](https://motia.cloud)
3. Select your local project port
4. Choose project and environment name
5. Upload environment variables (optional)
6. Click **Deploy** and watch the magic happen! âœ¨

</Steps>

---

## ðŸš€ Production Deployment Guide

### Environment Variables

Configure these environment variables for production security and functionality:

```shell
# Required: GitHub webhook secret for security
GITHUB_WEBHOOK_SECRET="your-secure-random-secret"

# Optional: GitHub personal access token for enhanced API limits
GITHUB_TOKEN="ghp_your_github_token"
```

### Security Best Practices

For production deployments, ensure you:

1. **Generate secure webhook secrets**: 
   ```shell
   # Generate a cryptographically secure secret
   openssl rand -hex 32
   ```

2. **Store secrets securely**: Use environment variables, never commit to code

3. **Monitor webhook signatures**: The handler automatically verifies signatures when `GITHUB_WEBHOOK_SECRET` is set

4. **Enable logging**: Monitor for signature verification failures and unauthorized requests

### Scaling Considerations

This architecture scales automatically with your traffic:

- **Multiple repositories**: Each repo gets its own stream key (`org/repo`)
- **High concurrency**: Motia streams handle thousands of concurrent connections
- **Global distribution**: Deploy to multiple regions for worldwide performance
- **Cost optimization**: Pay only for actual usage with serverless scaling

---

## ðŸ’» Dive into the Code

Want to explore the complete real-time implementation? Check out the full source code and see how simple real-time features can be with Motia:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Live GitHub Stars Counter</h3>
        <p className="text-gray-600 mb-4">Access the complete implementation with webhook security, real-time streams, and production deployment configurations. See exactly how the Motia website's live counter works!</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/github-stars-counter" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Stars Counter Code
          </a>
          <a 
            href="https://motia.dev" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            See It Live in Header â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Real-Time Made Simple

This GitHub stars counter demonstrates how Motia transforms complex real-time development into simple, manageable components. With just two files and minimal configuration, we've built a production-ready system that handles webhook security, real-time synchronization, and live client updates.

The beauty of this approach is its scalability and extensibility:
- **Add more repositories**: Each gets its own stream automatically
- **Enhance with analytics**: Track starring patterns and user insights
- **Multiple notification channels**: Slack, Discord, email alerts for milestones
- **Rich frontend integrations**: React, Vue, vanilla JS - all work seamlessly

Key architectural benefits:
- **No WebSocket complexity**: Streams handle all real-time synchronization automatically
- **Built-in security**: Production-ready webhook verification out of the box
- **Type safety**: Full TypeScript support prevents runtime errors
- **Zero configuration**: Real-time features work with no additional setup

This exact implementation powers the live star counter you see in the header of [Motia.dev](https://motia.dev) - that 7953+ count updating in real-time? It's this code in action, proven at enterprise scale with thousands of daily visitors.

**Production Metrics:**
- Handles 10,000+ webhook events per day
- Sub-50ms response times globally  
- 99.9% uptime with automatic failover
- Zero maintenance serverless architecture

Ready to add enterprise-grade real-time features to your applications? Deploy production-ready code with Motia today!




## Examples
[github-stars-counter](/docs/examples/github-stars-counter): Code example
---
title: 'GitHub Stars Counter'
description: 'Real-Time GitHub Stars Counter: Building Live Updates with Motia Streams'
---

In today's social-driven development world, real-time metrics and live updates are essential for building engaging applications. Whether you're creating a portfolio site, an open-source project showcase, or a developer dashboard, you need systems that can display live data without complex infrastructure.

This comprehensive guide explores how to build a production-ready, real-time GitHub stars counter using Motia's event-driven architecture and streaming capabilities. We'll cover:

1. **Real-Time Streams**: How Motia's streams enable effortless live data synchronization
2. **Secure Webhooks**: Production-ready webhook signature verification and event handling
3. **Minimal Architecture**: Building powerful real-time features with just two components
4. **Live Integration**: How this exact counter powers the live star count on the Motia website

Let's build a stars counter that updates in real-time across all connected clients.

---

<div className="my-8">![GitHub Stars Counter Demo](./../img/gitstars-workbench.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/github-stars-counter)

---

## ðŸ­ Production-Grade Example

**This is not a tutorial project** - this is battle-tested, production-ready code that handles real traffic at scale. Every aspect has been designed for enterprise use:

- **ðŸ” Enterprise Security**: HMAC webhook verification, timing-safe comparisons, comprehensive input validation
- **âš¡ High Performance**: Handles thousands of concurrent connections with automatic scaling
- **ðŸ“Š Full Observability**: Structured logging, error tracking, and comprehensive monitoring
- **ðŸ›¡ï¸ Error Resilience**: Graceful degradation, retry logic, and fault tolerance
- **ðŸŒ Global Scale**: Production deployment on Motia Cloud with worldwide CDN
- **ðŸ’° Cost Efficient**: Serverless architecture that scales to zero when not in use

---

## Live Proof: Powering Motia.dev Header

**This isn't just a demo** - this exact code powers the live GitHub star counter you can see right now in the header of [Motia.dev](https://motia.dev)! 

Look at the top-right corner of the Motia website and you'll see:
- **ðŸ  Motia** logo on the left
- **ðŸ“‘ Blog, Docs, Manifesto** navigation 
- **â­ GitHub** icon with a **live star count** (currently showing 7953+ stars)
- **ðŸš€ Vercel OSS 2025** badge

That live-updating number next to the GitHub icon? That's this exact implementation in production, processing real webhook events and streaming updates to thousands of visitors in real-time!

---

## The Power of Real-Time Simplicity

At its core, our GitHub stars counter solves a fundamental challenge: how do you display live, real-time metrics without complex WebSocket infrastructure or manual state management? Traditional approaches often involve intricate server-side event handling, client connection management, and complex state synchronization.

Our Motia-powered solution breaks this down into just two simple components:

- **[GitHub Webhooks](https://docs.github.com/en/webhooks)**: Instant notifications when repository stars change
- **[Motia Streams](https://motia.dev)**: Real-time data synchronization with automatic state management
- **[Production Security](https://docs.github.com/en/webhooks/securing)**: Built-in webhook signature verification

ðŸŽ¯ **Live in Action**: This exact implementation powers the real-time star counter visible in the header of [Motia.dev](https://motia.dev) (look for the GitHub icon with live count), updating instantly whenever developers star the repository!

Instead of complex infrastructure, we get a resilient real-time system where data flows effortlessly from GitHub events to live client updates.

---

## The Anatomy of Our Real-Time Counter

Our application consists of just two specialized components, each handling a specific part of the real-time data flow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="00-repository-stars.stream.ts" />
  <File name="01-github-webhook.step.ts" />
</Folder>

<Folder name="utils" defaultOpen>
  <File name="verify-webhook-signature.ts" />
  <File name="check-user-profile.ts" />
</Folder>

<Tabs items={['stream-config', 'webhook-handler', 'signature-verification', 'user-profile']}>
  <Tab value="stream-config">
    The real-time data stream that holds our repository star counts. This stream automatically synchronizes data to all connected clients with zero configuration.

    ```typescript
    import { StreamConfig } from 'motia'
    import { z } from 'zod'

    const RepositoryStarsSchema = z.object({
      stars: z.number(),
      name: z.string(),
      fullName: z.string(),
      organization: z.string(),
      lastUpdated: z.string(),
    })

    export type RepositoryStars = z.infer<typeof RepositoryStarsSchema>

    export const config: StreamConfig = {
      name: 'stars',
      schema: RepositoryStarsSchema,
      baseConfig: { storageType: 'default' },
    }
    ```

  </Tab>
  <Tab value="webhook-handler">
    The secure webhook endpoint that receives GitHub star events, verifies their authenticity, and updates the real-time stream with new star counts.

    ```typescript
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'
    import { verifyWebhookSignature } from '../utils/verify-webhook-signature'
    import { checkUserProfile } from '../utils/check-user-profile'

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'GitHubStarWebhook',
      description: 'Process GitHub star webhook events with signature verification',
      method: 'POST',
      path: '/webhooks/github/star',
      bodySchema: z.object({
        action: z.enum(['created', 'deleted']),
        starred_at: z.string().optional(),
        repository: z.object({
          name: z.string(),
          full_name: z.string(),
          stargazers_count: z.number(),
          owner: z.object({ login: z.string() }),
        }),
        sender: z.object({
          login: z.string(),
          name: z.string(),
          avatar_url: z.string().optional(),
          html_url: z.string(),
          url: z.string({ description: 'API URL' }),
        }),
      }),
      responseSchema: {
        200: z.object({
          message: z.string(),
          event: z.string(),
          processed: z.boolean(),
        }),
        400: z.object({ error: z.string() }),
        401: z.object({ error: z.string() }),
        500: z.object({ error: z.string() }),
      },
      emits: [],
      flows: ['github-star-processing'],
    }

    export const handler: Handlers['GitHubStarWebhook'] = async (
      req,
      { logger, streams, state, traceId }
    ) => {
      try {
        // Extract and validate GitHub headers
        const githubEvent = req.headers['x-github-event'] as string
        const githubDelivery = req.headers['x-github-delivery'] as string
        const githubSignature = req.headers['x-hub-signature-256'] as string
        const githubSignatureSha1 = req.headers['x-hub-signature'] as string

        // Only process star events
        if (githubEvent !== 'star') {
          logger.info('Ignoring non-star event', { githubEvent, githubDelivery })

          return {
            status: 200,
            body: {
              message: 'Event ignored - only processing star events',
              event: githubEvent,
              processed: false,
            },
          }
        }

        // Verify webhook signature if secret is configured
        const webhookSecret = process.env.GITHUB_WEBHOOK_SECRET

        if (webhookSecret) {
          logger.info('Verifying webhook signature', {
            delivery: githubDelivery,
            event: githubEvent,
          })

          const isValidSignature = verifyWebhookSignature({
            payload: JSON.stringify(req.body),
            signature: githubSignature || githubSignatureSha1,
            secret: webhookSecret,
            algorithm: githubSignature ? 'sha256' : 'sha1',
          })

          if (!isValidSignature) {
            logger.warn('Invalid webhook signature', {
              delivery: githubDelivery,
              event: githubEvent,
            })

            return {
              status: 401,
              body: { error: 'Invalid webhook signature' },
            }
          }
        }

        // Extract repository and user data
        const repository = {
          fullName: req.body.repository.full_name,
          name: req.body.repository.name,
          organization: req.body.repository.owner.login,
        }

        const sender = {
          name: req.body.sender.name,
          login: req.body.sender.login,
          avatarUrl: req.body.sender.avatar_url,
          url: req.body.sender.html_url,
          apiUrl: req.body.sender.url,
        }

        // Prepare star data for stream
        const webhookData = {
          fullName: repository.fullName,
          name: repository.name,
          organization: repository.organization,
          lastUpdated: req.body.starred_at || new Date().toISOString(),
          stars: req.body.repository.stargazers_count,
        }

        // Update real-time stream - this automatically propagates to all clients!
        await streams.stars.set(repository.organization, repository.name, webhookData)

        logger.info('GitHub star webhook processed successfully', { ...webhookData, sender })

        // Optional: Fetch additional user profile data
        if (sender.apiUrl) {
          try {
            logger.info('Getting GitHub user profile', { apiUrl: sender.apiUrl })
            const userProfile = await checkUserProfile(sender.apiUrl)
            await state.set(repository.fullName, traceId, userProfile)
            logger.info('GitHub user profile', { userProfile })
          } catch (error: any) {
            logger.error('Failed to get GitHub user profile', { error: error.message })
          }
        }

        return {
          status: 200,
          body: {
            message: 'Star webhook processed successfully',
            event: githubEvent,
            processed: true,
          },
        }
      } catch (error: any) {
        logger.error('GitHub star webhook processing failed', {
          error: error.message,
          stack: error.stack,
        })

        return {
          status: 500,
          body: { error: 'Star webhook processing failed' },
        }
      }
    }
    ```

  </Tab>
  <Tab value="signature-verification">
    Production-ready webhook security that verifies GitHub webhook signatures using HMAC cryptographic validation to ensure requests are authentic.

    ```typescript
    import crypto from 'crypto'

    type Args = {
      payload: string
      signature: string
      secret: string
      algorithm: 'sha1' | 'sha256'
    }

    export function verifyWebhookSignature(args: Args): boolean {
      const { payload, signature, secret, algorithm = 'sha256' } = args

      try {
        if (!signature) return false

        // Generate expected signature using HMAC
        const expectedSignature =
          algorithm === 'sha256'
            ? `sha256=${crypto.createHmac('sha256', secret).update(payload, 'utf8').digest('hex')}`
            : `sha1=${crypto.createHmac('sha1', secret).update(payload, 'utf8').digest('hex')}`

        // Use timing-safe comparison to prevent timing attacks
        return crypto.timingSafeEqual(Buffer.from(signature), Buffer.from(expectedSignature))
      } catch (error) {
        return false
      }
    }
    ```

  </Tab>
  <Tab value="user-profile">
    Optional GitHub user profile fetching that enriches webhook events with additional user information for analytics and user insights.

    ```typescript
    export interface GitHubUserProfile {
      login: string
      id: number
      node_id: string
      avatar_url: string
      gravatar_id: string
      url: string
      html_url: string
      followers_url: string
      following_url: string
      gists_url: string
      starred_url: string
      subscriptions_url: string
      organizations_url: string
      repos_url: string
      events_url: string
      received_events_url: string
      type: string
      user_view_type: string
      site_admin: boolean
      name: string | null
      company: string | null
      blog: string
      location: string | null
      email: string | null
      hireable: boolean | null
      bio: string | null
      twitter_username: string | null
      public_repos: number
      public_gists: number
      followers: number
      following: number
      created_at: string
      updated_at: string
    }

    export interface GitHubUserProfileResponse {
      followers: number
      bio: string | null
      email: string | null
      htmlUrl: string
      name: string | null
      login: string
      location: string | null
    }

    export const checkUserProfile = async (apiUrl: string): Promise<GitHubUserProfileResponse> => {
      const response = await fetch(apiUrl)
      const data = (await response.json()) as GitHubUserProfile

      return {
        followers: data.followers,
        bio: data.bio,
        email: data.email,
        htmlUrl: data.html_url,
        name: data.name,
        login: data.login,
        location: data.location,
      }
    }
    ```

  </Tab>
</Tabs>

---

## Real-Time Data Flow

The beauty of this architecture lies in its simplicity. Here's how real-time updates flow through the system:

1. **GitHub Event** â†’ User stars/unstars your repository
2. **Webhook Delivery** â†’ GitHub sends POST request to your endpoint  
3. **Security Validation** â†’ Signature verification ensures request authenticity
4. **Stream Update** â†’ Data is written to Motia stream with `streams.stars.set()`
5. **Live Propagation** â†’ All connected clients automatically receive the update
6. **UI Updates** â†’ Client applications re-render with new star count

**No manual WebSocket management, no connection handling, no state synchronization code required!**

---

## Key Features & Benefits

### âš¡ **Instant Real-Time Updates**
Stars update across all connected clients the moment GitHub sends the webhook - no polling, no delays.

### ðŸ” **Production-Ready Security**  
HMAC signature verification with timing-safe comparison prevents unauthorized webhook requests.

### ðŸ§© **Minimal Architecture**
Just two components handle the complete real-time functionality - no complex infrastructure required.

### ðŸ“Š **Automatic State Management**
Motia streams handle data persistence, synchronization, and client updates automatically.

### ðŸŽ¯ **Type-Safe Development**
Full TypeScript integration with Zod validation ensures zero runtime surprises.

### ðŸŒ **Live Production Usage**
This exact implementation powers the real-time counter visible in the Motia website header - go check it out now!

### ðŸš€ **Production-Grade Architecture**
Built for enterprise scale with proper error handling, security, monitoring, and deployment automation.

---

## Trying It Out

Ready to build your own real-time GitHub stars counter? Let's get it running.

<Steps>

### Clone and Install

Start by getting the project locally and installing dependencies.

```shell
git clone https://github.com/MotiaDev/github-stars-counter.git
cd github-stars-counter
npm install
```

### Configure GitHub Webhook (Optional)

Set up webhook security with a secret for production use. This is optional for testing but essential for production deployments.

```shell
# Generate a secure random secret
export GITHUB_WEBHOOK_SECRET=$(openssl rand -hex 32)
echo "GITHUB_WEBHOOK_SECRET=$GITHUB_WEBHOOK_SECRET" >> .env
```

### Start Development Server

Launch the Motia development server to begin receiving webhook events.

```shell
npm run dev
```

Your webhook endpoint will be available at: `http://localhost:3000/webhooks/github/star`

### Set Up GitHub Webhook

Configure GitHub to send star events to your endpoint:

1. Go to your GitHub repository settings
2. Navigate to **Settings** â†’ **Webhooks**  
3. Click **Add webhook**
4. Set **Payload URL** to your endpoint (use ngrok for local testing)
5. Set **Content type** to `application/json`
6. Add your webhook secret if configured
7. Select **Individual events** â†’ **Stars**
8. Click **Add webhook**

### Test the Real-Time Updates

Test your webhook by starring/unstarring your repository:

1. **Star your repository** on GitHub
2. **Check the logs** - you should see webhook processing
3. **Access the stream** - query `/api/streams/stars` to see current data
4. **Watch real-time updates** in the Motia Workbench

### Access Real-Time Data

Your star data is now available via the Motia streams API:

```shell
# Get all repository star counts
curl http://localhost:3000/api/streams/stars

# Get specific repository star count  
curl http://localhost:3000/api/streams/stars/{org}/{repo}
```

The response includes live star counts that update automatically whenever GitHub sends webhook events.

### Deploy to Production

Once your counter is working locally, deploy it to production with Motia Cloud:

**Option 1: CLI Deployment**
```shell
# Deploy with version and API key
motia cloud deploy --api-key your-api-key --version-name 1.0.0

# Deploy with environment variables
motia cloud deploy --api-key your-api-key \
  --version-name 1.0.0 \
  --env-file .env.production \
  --environment-id your-env-id
```

**Option 2: One-Click Web Deployment**
1. Ensure your local project is running (`npm run dev`)
2. Go to [Motia Cloud -> Import from Workbench](https://motia.cloud)
3. Select your local project port
4. Choose project and environment name
5. Upload environment variables (optional)
6. Click **Deploy** and watch the magic happen! âœ¨

</Steps>

---

## ðŸš€ Production Deployment Guide

### Environment Variables

Configure these environment variables for production security and functionality:

```shell
# Required: GitHub webhook secret for security
GITHUB_WEBHOOK_SECRET="your-secure-random-secret"

# Optional: GitHub personal access token for enhanced API limits
GITHUB_TOKEN="ghp_your_github_token"
```

### Security Best Practices

For production deployments, ensure you:

1. **Generate secure webhook secrets**: 
   ```shell
   # Generate a cryptographically secure secret
   openssl rand -hex 32
   ```

2. **Store secrets securely**: Use environment variables, never commit to code

3. **Monitor webhook signatures**: The handler automatically verifies signatures when `GITHUB_WEBHOOK_SECRET` is set

4. **Enable logging**: Monitor for signature verification failures and unauthorized requests

### Scaling Considerations

This architecture scales automatically with your traffic:

- **Multiple repositories**: Each repo gets its own stream key (`org/repo`)
- **High concurrency**: Motia streams handle thousands of concurrent connections
- **Global distribution**: Deploy to multiple regions for worldwide performance
- **Cost optimization**: Pay only for actual usage with serverless scaling

---

## ðŸ’» Dive into the Code

Want to explore the complete real-time implementation? Check out the full source code and see how simple real-time features can be with Motia:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Live GitHub Stars Counter</h3>
        <p className="text-gray-600 mb-4">Access the complete implementation with webhook security, real-time streams, and production deployment configurations. See exactly how the Motia website's live counter works!</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/github-stars-counter" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Stars Counter Code
          </a>
          <a 
            href="https://motia.dev" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            See It Live in Header â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Real-Time Made Simple

This GitHub stars counter demonstrates how Motia transforms complex real-time development into simple, manageable components. With just two files and minimal configuration, we've built a production-ready system that handles webhook security, real-time synchronization, and live client updates.

The beauty of this approach is its scalability and extensibility:
- **Add more repositories**: Each gets its own stream automatically
- **Enhance with analytics**: Track starring patterns and user insights
- **Multiple notification channels**: Slack, Discord, email alerts for milestones
- **Rich frontend integrations**: React, Vue, vanilla JS - all work seamlessly

Key architectural benefits:
- **No WebSocket complexity**: Streams handle all real-time synchronization automatically
- **Built-in security**: Production-ready webhook verification out of the box
- **Type safety**: Full TypeScript support prevents runtime errors
- **Zero configuration**: Real-time features work with no additional setup

This exact implementation powers the live star counter you see in the header of [Motia.dev](https://motia.dev) - that 7953+ count updating in real-time? It's this code in action, proven at enterprise scale with thousands of daily visitors.

**Production Metrics:**
- Handles 10,000+ webhook events per day
- Sub-50ms response times globally  
- 99.9% uptime with automatic failover
- Zero maintenance serverless architecture

Ready to add enterprise-grade real-time features to your applications? Deploy production-ready code with Motia today!



-   [gmail-automation](/docs/examples/gmail-automation): Documentation for gmail-automation.
---
title: 'Gmail Automation'
description: Build an automated email system with smart labeling, auto-responses, and AI-powered filtering
---

import { GmailTab } from '../../../components/GmailCodeFetcher'

---

## Explore the Workbench

<div className="my-8">![Gmail Automation](./../img/gmail-automation.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/gmail-flow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a Gmail automation system that:

- ðŸ“Š Smart email classification by category (work, personal, social, promotion, spam, update)
- ðŸš¨ Urgency detection (high, medium, low) with prioritization
- ðŸ’¬ Intelligent automated responses based on email context
- ðŸ·ï¸ Automatic email organization (labeling, archiving)
- ðŸ“ˆ Daily summary reports via Discord
- ðŸ”’ Secure Gmail API integration with OAuth2 authentication flow
- âš¡ Real-time email monitoring with webhook notifications

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-email.step.py" />
  <File name="auto-responder.step.ts" />
  <File name="daily-summary.step.ts" />
  <File name="fetch-email.step.ts" />
  <File name="gmail-webhook.step.ts" />
  <File name="organize-email.step.ts" />
</Folder>

<Tabs items={['webhook', 'analyze-email', 'auto-responder', 'daily-summary', 'fetch-email', 'organize-email']}>
  <GmailTab tab="webhook" value="gmail-webhook" />
  <GmailTab tab="analyze-email" value="analyze-email" fileExtension="py" />
  <GmailTab tab="auto-responder" value="auto-responder" />
  <GmailTab tab="daily-summary" value="daily-summary" />
  <GmailTab tab="fetch-email" value="fetch-email" />
  <GmailTab tab="organize-email" value="organize-email" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Gmail Automation Steps](../img/gmail-automation.png)</div>

## ðŸŒŠ Workflow Architecture

The Gmail Account Manager workflow consists of the following steps:

### 1. Gmail Authentication (Multi-Step Flow)
- **Files**: 
  - `steps/gmail-get-auth-url.step.ts`: Generates OAuth2 authorization URL
  - `steps/gmail-auth.step.ts`: Handles authorization code exchange
  - `steps/gmail-token-status.step.ts`: Checks token validity and refreshes if needed

### 2. Gmail Webhook (API Step)
- **File**: `steps/gmail-webhook.step.ts`
- **Purpose**: Receives notifications from Gmail when new emails arrive
- **Emits**: `gmail.new_email` event with message details
- **Endpoint**: `POST /api/gmail-webhook`

### 3. Gmail Watch (API Step)
- **File**: `steps/gmail-watch.step.ts`
- **Purpose**: Sets up push notifications for the Gmail account
- **Endpoint**: `GET /api/watch`

### 4. Fetch Email (Event Step)
- **File**: `steps/fetch-email.step.ts`
- **Purpose**: Retrieves the full email content from Gmail API
- **Subscribes to**: `gmail.email.received`
- **Emits**: `gmail.email.fetched` with complete email data
- **Key Functions**: Authenticates with Gmail API, fetches message content, parses attachments

### 5. Analyze Email (Event Step)
- **File**: `steps/analyze-email.step.py`
- **Purpose**: Uses Hugging Face models to analyze email content
- **Subscribes to**: `gmail.email.fetched`
- **Emits**: `gmail.email.analyzed` with analysis results
- **Analysis Performed**: 
  - Category classification
  - Urgency detection
  - Sentiment analysis
  - Key information extraction

### 6. Organize Email (Event Step)
- **File**: `steps/organize-email.step.ts`
- **Purpose**: Applies labels and organization based on analysis
- **Subscribes to**: `gmail.email.analyzed`
- **Emits**: `[gmail.email.organized, gmail.email.archived]`
- **Actions**: Creates/applies labels, archives certain emails, marks importance

### 7. Auto-Respond to Email (Event Step)
- **File**: `steps/auto-responder.step.ts`
- **Purpose**: Generates and sends appropriate responses for certain emails
- **Subscribes to**: `gmail.email.analyzed`
- **Emits**: `gmail.email.responded`
- **Features**: 
  - Template selection based on email context
  - Personalization of responses
  - Auto-reply for urgent messages
  - Follow-up scheduling

### 8. Daily Summary (Cron Step)
- **File**: `steps/daily-summary.step.ts`
- **Purpose**: Compiles and sends daily email activity summary
- **Schedule**: Runs daily at 6:00 PM
- **Emits**: `gmail.summary.sent`
- **Delivery**: Sends report to Discord via webhook

## Try It Out

<Steps>
## ðŸ“‹ Prerequisites

- **Node.js** (v18+)
- **Python** (v3.8+)
- **Gmail API credentials** (client_id and client_secret)
- **Google Cloud project** with Pub/Sub API enabled
- **Hugging Face API token**
- **Discord webhook URL** (for daily summaries)

## ðŸš€ Quick Start

1. **Clone this repository**
   ```bash
   git clone https://github.com/yourusername/gmail-flow.git
   cd gmail-flow
   ```

2. **Install Node.js dependencies**
   ```bash
   pnpm install
   ```

3. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   cp .env.example .env
   ```
   Then edit the `.env` file with your credentials (see setup sections below).

5. **Start the development server**
   ```bash
   pnpm dev
   ```

6. **Open the Motia Workbench**
   
   Navigate to [http://localhost:3000](http://localhost:3000) to access the workflow UI.

## ðŸ”§ Detailed Setup

### Setting up Google Cloud Project and Gmail API

Before you can use the Gmail Account Manager, you need to set up a Google Cloud project with the Gmail API and Pub/Sub:

1. **Create a Google Cloud Project**:
   - Go to [Google Cloud Console](https://console.cloud.google.com/)
   - Click on "New Project" and follow the steps to create a new project
   - Note your project ID for later use

2. **Enable the Gmail API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Gmail API" and click on it
   - Click "Enable"

3. **Enable the Pub/Sub API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Cloud Pub/Sub API" and click on it
   - Click "Enable"

4. **Create OAuth Credentials**:
   - Go to "APIs & Services" > "Credentials"
   - Click "Create Credentials" > "OAuth client ID"
   - Set the application type to "Desktop app"
   - Click "Create"
   - Note your Client ID and Client Secret for your `.env` file:
     ```
     GOOGLE_CLIENT_ID=your_client_id
     GOOGLE_CLIENT_SECRET=your_client_secret
     ```

### Setting up Google Pub/Sub for Gmail Notifications

To enable real-time email notifications, you need to set up a Google Cloud Pub/Sub topic and subscription:

1. **Create a Pub/Sub Topic**:
   - In your Google Cloud Console, go to "Pub/Sub" > "Topics"
   - Click "Create Topic"
   - Name your topic (e.g., `gmail-notifications`)
   - Add the service account `gmail-api-push@system.gserviceaccount.com` as a Topic Publisher to allow Gmail to publish notifications
   - Click "Create"
   - Note the full topic name (usually `projects/your-project-id/topics/gmail-notifications`) for your `.env` file:
     ```
     GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications
     ```

2. **Create a Pub/Sub Subscription**:
   - Once your topic is created, click "Create Subscription"
   - Name your subscription (e.g., `gmail-notifications-push`)
   - Set the Delivery Type to "Push"
   - Set the Endpoint URL to your webhook URL (e.g., `https://your-domain.com/api/gmail-webhook`)
     - For local development, you'll need to use a tool like ngrok to expose your local server
   - Click "Create"

3. **Set up Domain Verification** (if needed):
   - If you're using a custom domain for your webhook endpoint, you may need to verify domain ownership
   - Follow the instructions in Google Cloud Console for domain verification

### Gmail API Authentication

This project includes a complete OAuth2 authentication flow for the Gmail API:

1. Start the development server: `pnpm dev`
2. Navigate to the authentication workflow in the Motia Workbench
3. The workflow will generate an authorization URL
4. Open the URL in your browser and authorize the application
5. The application will receive and store your authentication tokens

### Discord Webhook Configuration

To receive daily email summaries in Discord, follow these steps to set up a webhook:

1. **Create a Discord Server** (skip if you already have one):
   - Open Discord and click the "+" icon on the left sidebar
   - Select "Create My Own" and follow the setup wizard

2. **Create a Channel for Notifications**:
   - Right-click on your server name and select "Server Settings"
   - Go to "Channels" and click "Create Channel"
   - Name it (e.g., "email-summaries") and click "Create"

3. **Create a Webhook**:
   - Right-click on your new channel and select "Edit Channel"
   - Go to "Integrations" tab
   - Click "Create Webhook"
   - Give it a name (e.g., "Gmail Summary Bot")
   - Optionally, customize the avatar
   - Click "Copy Webhook URL"

4. **Add Webhook URL to Environment Variables**:
   - Open your `.env` file
   - Add or update the Discord webhook URL:
     ```
     DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url
     ```

5. **Test the Webhook**:
   - You can test if your webhook is working correctly with this curl command:
     ```bash
     curl -X POST -H "Content-Type: application/json" \
     -d '{"content": "Testing Gmail Account Manager webhook"}' \
     https://discord.com/api/webhooks/your-webhook-url
     ```
   - You should see the message appear in your Discord channel

### Hugging Face Setup

1. **Create a Hugging Face Account**:
   - Sign up at [Hugging Face](https://huggingface.co/join)

2. **Generate an API Token**:
   - Go to your [Hugging Face account settings](https://huggingface.co/settings/tokens)
   - Create a new API token
   - Copy the token to your `.env` file:
     ```
     HUGGINGFACE_API_TOKEN=your_api_token
     ```

</Steps>

## ðŸ“ Project Structure

- `steps/` - Contains all workflow steps
  - `gmail-get-auth-url.step.ts` - Generates OAuth2 URL
  - `gmail-auth.step.ts` - Handles OAuth2 flow
  - `gmail-token-status.step.ts` - Manages token refresh
  - `gmail-webhook.step.ts` - Webhook endpoint for Gmail notifications
  - `gmail-watch.step.ts` - Sets up Gmail push notifications
  - `fetch-email.step.ts` - Fetches email content from Gmail API
  - `analyze-email.step.py` - Python step for email analysis using Hugging Face
  - `organize-email.step.ts` - Organizes emails (labels, archives)
  - `auto-responder.step.ts` - Generates appropriate responses
  - `daily-summary.step.ts` - Sends daily summary to Discord
- `services/` - Shared service modules
- `config/` - Configuration files
- `.motia/` - Motia framework configuration

## ðŸ“¦ Dependencies

### Node.js Dependencies
- **@motiadev/core**, **@motiadev/workbench**, **motia**: Motia framework
- **googleapis**, **google-auth-library**: Google API integration
- **gmail-api-parse-message-ts**: Gmail message parsing
- **axios**: HTTP client
- **zod**: Schema validation
- **react**: UI components

### Python Dependencies
- **transformers**, **torch**: Machine learning models
- **scikit-learn**, **numpy**, **pandas**: Data processing
- **huggingface_hub**: Access to Hugging Face models
- **python-dotenv**: Environment variable loading

## ðŸ› ï¸ Troubleshooting

- **Python Module Errors**: Ensure you've installed all required Python packages with `pip install -r requirements.txt`
- **Authentication Errors**: Verify your API credentials and follow the authentication flow
- **Webhook Issues**: Make sure the webhook endpoint is publicly accessible or properly configured for testing
- **Token Refresh Errors**: Check that your OAuth tokens are valid and that the refresh flow is working properly
- **Pub/Sub Not Working**: Verify that your Pub/Sub topic and subscription are properly configured and that your service account has the necessary permissions

## ðŸ“ Environment Variables

Create a `.env` file with the following variables:

```
# Google API Configuration
GOOGLE_CLIENT_ID=your_client_id
GOOGLE_CLIENT_SECRET=your_client_secret
GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications

# HuggingFace Configuration
HUGGINGFACE_API_TOKEN=your_huggingface_token

# Discord Integration
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url

# Auto-Responder Configuration
AUTO_RESPONDER_NAME=Your Name
AUTO_RESPONDER_EMAIL=your-email@example.com
```



## Examples
[gmail-automation](/docs/examples/gmail-automation): Code example
---
title: 'Gmail Automation'
description: Build an automated email system with smart labeling, auto-responses, and AI-powered filtering
---

import { GmailTab } from '../../../components/GmailCodeFetcher'

---

## Explore the Workbench

<div className="my-8">![Gmail Automation](./../img/gmail-automation.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/gmail-flow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a Gmail automation system that:

- ðŸ“Š Smart email classification by category (work, personal, social, promotion, spam, update)
- ðŸš¨ Urgency detection (high, medium, low) with prioritization
- ðŸ’¬ Intelligent automated responses based on email context
- ðŸ·ï¸ Automatic email organization (labeling, archiving)
- ðŸ“ˆ Daily summary reports via Discord
- ðŸ”’ Secure Gmail API integration with OAuth2 authentication flow
- âš¡ Real-time email monitoring with webhook notifications

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-email.step.py" />
  <File name="auto-responder.step.ts" />
  <File name="daily-summary.step.ts" />
  <File name="fetch-email.step.ts" />
  <File name="gmail-webhook.step.ts" />
  <File name="organize-email.step.ts" />
</Folder>

<Tabs items={['webhook', 'analyze-email', 'auto-responder', 'daily-summary', 'fetch-email', 'organize-email']}>
  <GmailTab tab="webhook" value="gmail-webhook" />
  <GmailTab tab="analyze-email" value="analyze-email" fileExtension="py" />
  <GmailTab tab="auto-responder" value="auto-responder" />
  <GmailTab tab="daily-summary" value="daily-summary" />
  <GmailTab tab="fetch-email" value="fetch-email" />
  <GmailTab tab="organize-email" value="organize-email" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Gmail Automation Steps](../img/gmail-automation.png)</div>

## ðŸŒŠ Workflow Architecture

The Gmail Account Manager workflow consists of the following steps:

### 1. Gmail Authentication (Multi-Step Flow)
- **Files**: 
  - `steps/gmail-get-auth-url.step.ts`: Generates OAuth2 authorization URL
  - `steps/gmail-auth.step.ts`: Handles authorization code exchange
  - `steps/gmail-token-status.step.ts`: Checks token validity and refreshes if needed

### 2. Gmail Webhook (API Step)
- **File**: `steps/gmail-webhook.step.ts`
- **Purpose**: Receives notifications from Gmail when new emails arrive
- **Emits**: `gmail.new_email` event with message details
- **Endpoint**: `POST /api/gmail-webhook`

### 3. Gmail Watch (API Step)
- **File**: `steps/gmail-watch.step.ts`
- **Purpose**: Sets up push notifications for the Gmail account
- **Endpoint**: `GET /api/watch`

### 4. Fetch Email (Event Step)
- **File**: `steps/fetch-email.step.ts`
- **Purpose**: Retrieves the full email content from Gmail API
- **Subscribes to**: `gmail.email.received`
- **Emits**: `gmail.email.fetched` with complete email data
- **Key Functions**: Authenticates with Gmail API, fetches message content, parses attachments

### 5. Analyze Email (Event Step)
- **File**: `steps/analyze-email.step.py`
- **Purpose**: Uses Hugging Face models to analyze email content
- **Subscribes to**: `gmail.email.fetched`
- **Emits**: `gmail.email.analyzed` with analysis results
- **Analysis Performed**: 
  - Category classification
  - Urgency detection
  - Sentiment analysis
  - Key information extraction

### 6. Organize Email (Event Step)
- **File**: `steps/organize-email.step.ts`
- **Purpose**: Applies labels and organization based on analysis
- **Subscribes to**: `gmail.email.analyzed`
- **Emits**: `[gmail.email.organized, gmail.email.archived]`
- **Actions**: Creates/applies labels, archives certain emails, marks importance

### 7. Auto-Respond to Email (Event Step)
- **File**: `steps/auto-responder.step.ts`
- **Purpose**: Generates and sends appropriate responses for certain emails
- **Subscribes to**: `gmail.email.analyzed`
- **Emits**: `gmail.email.responded`
- **Features**: 
  - Template selection based on email context
  - Personalization of responses
  - Auto-reply for urgent messages
  - Follow-up scheduling

### 8. Daily Summary (Cron Step)
- **File**: `steps/daily-summary.step.ts`
- **Purpose**: Compiles and sends daily email activity summary
- **Schedule**: Runs daily at 6:00 PM
- **Emits**: `gmail.summary.sent`
- **Delivery**: Sends report to Discord via webhook

## Try It Out

<Steps>
## ðŸ“‹ Prerequisites

- **Node.js** (v18+)
- **Python** (v3.8+)
- **Gmail API credentials** (client_id and client_secret)
- **Google Cloud project** with Pub/Sub API enabled
- **Hugging Face API token**
- **Discord webhook URL** (for daily summaries)

## ðŸš€ Quick Start

1. **Clone this repository**
   ```bash
   git clone https://github.com/yourusername/gmail-flow.git
   cd gmail-flow
   ```

2. **Install Node.js dependencies**
   ```bash
   pnpm install
   ```

3. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   cp .env.example .env
   ```
   Then edit the `.env` file with your credentials (see setup sections below).

5. **Start the development server**
   ```bash
   pnpm dev
   ```

6. **Open the Motia Workbench**
   
   Navigate to [http://localhost:3000](http://localhost:3000) to access the workflow UI.

## ðŸ”§ Detailed Setup

### Setting up Google Cloud Project and Gmail API

Before you can use the Gmail Account Manager, you need to set up a Google Cloud project with the Gmail API and Pub/Sub:

1. **Create a Google Cloud Project**:
   - Go to [Google Cloud Console](https://console.cloud.google.com/)
   - Click on "New Project" and follow the steps to create a new project
   - Note your project ID for later use

2. **Enable the Gmail API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Gmail API" and click on it
   - Click "Enable"

3. **Enable the Pub/Sub API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Cloud Pub/Sub API" and click on it
   - Click "Enable"

4. **Create OAuth Credentials**:
   - Go to "APIs & Services" > "Credentials"
   - Click "Create Credentials" > "OAuth client ID"
   - Set the application type to "Desktop app"
   - Click "Create"
   - Note your Client ID and Client Secret for your `.env` file:
     ```
     GOOGLE_CLIENT_ID=your_client_id
     GOOGLE_CLIENT_SECRET=your_client_secret
     ```

### Setting up Google Pub/Sub for Gmail Notifications

To enable real-time email notifications, you need to set up a Google Cloud Pub/Sub topic and subscription:

1. **Create a Pub/Sub Topic**:
   - In your Google Cloud Console, go to "Pub/Sub" > "Topics"
   - Click "Create Topic"
   - Name your topic (e.g., `gmail-notifications`)
   - Add the service account `gmail-api-push@system.gserviceaccount.com` as a Topic Publisher to allow Gmail to publish notifications
   - Click "Create"
   - Note the full topic name (usually `projects/your-project-id/topics/gmail-notifications`) for your `.env` file:
     ```
     GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications
     ```

2. **Create a Pub/Sub Subscription**:
   - Once your topic is created, click "Create Subscription"
   - Name your subscription (e.g., `gmail-notifications-push`)
   - Set the Delivery Type to "Push"
   - Set the Endpoint URL to your webhook URL (e.g., `https://your-domain.com/api/gmail-webhook`)
     - For local development, you'll need to use a tool like ngrok to expose your local server
   - Click "Create"

3. **Set up Domain Verification** (if needed):
   - If you're using a custom domain for your webhook endpoint, you may need to verify domain ownership
   - Follow the instructions in Google Cloud Console for domain verification

### Gmail API Authentication

This project includes a complete OAuth2 authentication flow for the Gmail API:

1. Start the development server: `pnpm dev`
2. Navigate to the authentication workflow in the Motia Workbench
3. The workflow will generate an authorization URL
4. Open the URL in your browser and authorize the application
5. The application will receive and store your authentication tokens

### Discord Webhook Configuration

To receive daily email summaries in Discord, follow these steps to set up a webhook:

1. **Create a Discord Server** (skip if you already have one):
   - Open Discord and click the "+" icon on the left sidebar
   - Select "Create My Own" and follow the setup wizard

2. **Create a Channel for Notifications**:
   - Right-click on your server name and select "Server Settings"
   - Go to "Channels" and click "Create Channel"
   - Name it (e.g., "email-summaries") and click "Create"

3. **Create a Webhook**:
   - Right-click on your new channel and select "Edit Channel"
   - Go to "Integrations" tab
   - Click "Create Webhook"
   - Give it a name (e.g., "Gmail Summary Bot")
   - Optionally, customize the avatar
   - Click "Copy Webhook URL"

4. **Add Webhook URL to Environment Variables**:
   - Open your `.env` file
   - Add or update the Discord webhook URL:
     ```
     DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url
     ```

5. **Test the Webhook**:
   - You can test if your webhook is working correctly with this curl command:
     ```bash
     curl -X POST -H "Content-Type: application/json" \
     -d '{"content": "Testing Gmail Account Manager webhook"}' \
     https://discord.com/api/webhooks/your-webhook-url
     ```
   - You should see the message appear in your Discord channel

### Hugging Face Setup

1. **Create a Hugging Face Account**:
   - Sign up at [Hugging Face](https://huggingface.co/join)

2. **Generate an API Token**:
   - Go to your [Hugging Face account settings](https://huggingface.co/settings/tokens)
   - Create a new API token
   - Copy the token to your `.env` file:
     ```
     HUGGINGFACE_API_TOKEN=your_api_token
     ```

</Steps>

## ðŸ“ Project Structure

- `steps/` - Contains all workflow steps
  - `gmail-get-auth-url.step.ts` - Generates OAuth2 URL
  - `gmail-auth.step.ts` - Handles OAuth2 flow
  - `gmail-token-status.step.ts` - Manages token refresh
  - `gmail-webhook.step.ts` - Webhook endpoint for Gmail notifications
  - `gmail-watch.step.ts` - Sets up Gmail push notifications
  - `fetch-email.step.ts` - Fetches email content from Gmail API
  - `analyze-email.step.py` - Python step for email analysis using Hugging Face
  - `organize-email.step.ts` - Organizes emails (labels, archives)
  - `auto-responder.step.ts` - Generates appropriate responses
  - `daily-summary.step.ts` - Sends daily summary to Discord
- `services/` - Shared service modules
- `config/` - Configuration files
- `.motia/` - Motia framework configuration

## ðŸ“¦ Dependencies

### Node.js Dependencies
- **@motiadev/core**, **@motiadev/workbench**, **motia**: Motia framework
- **googleapis**, **google-auth-library**: Google API integration
- **gmail-api-parse-message-ts**: Gmail message parsing
- **axios**: HTTP client
- **zod**: Schema validation
- **react**: UI components

### Python Dependencies
- **transformers**, **torch**: Machine learning models
- **scikit-learn**, **numpy**, **pandas**: Data processing
- **huggingface_hub**: Access to Hugging Face models
- **python-dotenv**: Environment variable loading

## ðŸ› ï¸ Troubleshooting

- **Python Module Errors**: Ensure you've installed all required Python packages with `pip install -r requirements.txt`
- **Authentication Errors**: Verify your API credentials and follow the authentication flow
- **Webhook Issues**: Make sure the webhook endpoint is publicly accessible or properly configured for testing
- **Token Refresh Errors**: Check that your OAuth tokens are valid and that the refresh flow is working properly
- **Pub/Sub Not Working**: Verify that your Pub/Sub topic and subscription are properly configured and that your service account has the necessary permissions

## ðŸ“ Environment Variables

Create a `.env` file with the following variables:

```
# Google API Configuration
GOOGLE_CLIENT_ID=your_client_id
GOOGLE_CLIENT_SECRET=your_client_secret
GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications

# HuggingFace Configuration
HUGGINGFACE_API_TOKEN=your_huggingface_token

# Discord Integration
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url

# Auto-Responder Configuration
AUTO_RESPONDER_NAME=Your Name
AUTO_RESPONDER_EMAIL=your-email@example.com
```


-   [Examples](/docs/examples): Documentation for Examples.
---
title: Examples
---

We have curated examples to help you learn Motia, organized by complexity from basic concepts to production-ready implementations.

## ðŸ“š Basic Examples
Start here to learn core Motia concepts with straightforward implementations.

<Cards>
  <Card
    title="Sentiment Analysis"
    href="/docs/examples/sentiment-analysis"
    description="Learn dynamic workflows with LLM-driven decision making and event routing"
  />
  <Card
    title="Multi-Language Processing"
    href="/docs/examples/multi-language-data-processing"
    description="Combine TypeScript, Python, and JavaScript in unified data pipelines"
  />
</Cards>

## ðŸ”§ Intermediate Examples
Build more complex workflows with integrations and advanced patterns.

<Cards>
  <Card
    title="AI Content Moderation"
    href="/docs/examples/ai-content-moderation"
    description="Human-in-the-loop content moderation with AI analysis and Slack integration"
  />
  <Card
    title="RAG PDF Analyzer"
    href="/docs/examples/rag-docling-weaviate"
    description="Intelligent document processing with Docling and Weaviate vector database"
  />
  <Card
    title="Trello Automation"
    href="/docs/examples/trello-automation"
    description="Automated card progression system with AI-powered summaries and notifications"
  />
</Cards>

## ðŸ­ Production Examples
Enterprise-ready implementations handling real traffic at scale.

<Cards>
  <Card
    title="Uptime Monitor"
    href="/docs/examples/uptime-discord-monitor"
    description="Complete monitoring system with smart alerting and Discord integration"
  />
  <Card
    title="GitHub Stars Counter"
    href="/docs/examples/github-stars-counter"
    description="Real-time stars counter with secure webhooks and live streaming"
  />
  <Card
    title="GitHub Integration"
    href="/docs/examples/github-integration-workflow"
    description="Automated issue and PR management with AI-powered classification and routing"
  />
  <Card
    title="Gmail Automation"
    href="/docs/examples/gmail-automation"
    description="Smart email classification, auto-responses, and AI-powered filtering with OAuth2"
  />
  <Card
    title="Finance Agent"
    href="/docs/examples/finance-agent"
    description="Event-driven financial analysis with web search and real-time market data"
  />
  <Card
    title="AI Research Agent"
    href="/docs/examples/ai-deep-research-agent"
    description="Comprehensive web research assistant with iterative depth and parallel processing"
  />
</Cards>


<br/>

## ðŸ’» Explore the Source Code

All examples include complete, runnable source code with configuration files, setup instructions, and production-ready implementations:

<div className="not-prose">
  <div className="bg-gradient-to-r from-indigo-50 to-purple-50 border border-indigo-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-indigo-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Motia Examples Repository</h3>
        <p className="text-gray-600 mb-4">Access complete implementations, step-by-step tutorials, and production-ready configurations for all our examples. Perfect for learning, experimentation, and building your own applications.</p>
        <div className="grid grid-cols-1 sm:grid-cols-3 gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Repository
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            RAG Example â†’
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Monitor Example â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

## Contribute

We welcome contributions to the examples. Please submit a PR to the [examples repository](https://github.com/motiadev/motia-examples).



## Examples
[Examples](/docs/examples): Code example
---
title: Examples
---

We have curated examples to help you learn Motia, organized by complexity from basic concepts to production-ready implementations.

## ðŸ“š Basic Examples
Start here to learn core Motia concepts with straightforward implementations.

<Cards>
  <Card
    title="Sentiment Analysis"
    href="/docs/examples/sentiment-analysis"
    description="Learn dynamic workflows with LLM-driven decision making and event routing"
  />
  <Card
    title="Multi-Language Processing"
    href="/docs/examples/multi-language-data-processing"
    description="Combine TypeScript, Python, and JavaScript in unified data pipelines"
  />
</Cards>

## ðŸ”§ Intermediate Examples
Build more complex workflows with integrations and advanced patterns.

<Cards>
  <Card
    title="AI Content Moderation"
    href="/docs/examples/ai-content-moderation"
    description="Human-in-the-loop content moderation with AI analysis and Slack integration"
  />
  <Card
    title="RAG PDF Analyzer"
    href="/docs/examples/rag-docling-weaviate"
    description="Intelligent document processing with Docling and Weaviate vector database"
  />
  <Card
    title="Trello Automation"
    href="/docs/examples/trello-automation"
    description="Automated card progression system with AI-powered summaries and notifications"
  />
</Cards>

## ðŸ­ Production Examples
Enterprise-ready implementations handling real traffic at scale.

<Cards>
  <Card
    title="Uptime Monitor"
    href="/docs/examples/uptime-discord-monitor"
    description="Complete monitoring system with smart alerting and Discord integration"
  />
  <Card
    title="GitHub Stars Counter"
    href="/docs/examples/github-stars-counter"
    description="Real-time stars counter with secure webhooks and live streaming"
  />
  <Card
    title="GitHub Integration"
    href="/docs/examples/github-integration-workflow"
    description="Automated issue and PR management with AI-powered classification and routing"
  />
  <Card
    title="Gmail Automation"
    href="/docs/examples/gmail-automation"
    description="Smart email classification, auto-responses, and AI-powered filtering with OAuth2"
  />
  <Card
    title="Finance Agent"
    href="/docs/examples/finance-agent"
    description="Event-driven financial analysis with web search and real-time market data"
  />
  <Card
    title="AI Research Agent"
    href="/docs/examples/ai-deep-research-agent"
    description="Comprehensive web research assistant with iterative depth and parallel processing"
  />
</Cards>


<br/>

## ðŸ’» Explore the Source Code

All examples include complete, runnable source code with configuration files, setup instructions, and production-ready implementations:

<div className="not-prose">
  <div className="bg-gradient-to-r from-indigo-50 to-purple-50 border border-indigo-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-indigo-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Motia Examples Repository</h3>
        <p className="text-gray-600 mb-4">Access complete implementations, step-by-step tutorials, and production-ready configurations for all our examples. Perfect for learning, experimentation, and building your own applications.</p>
        <div className="grid grid-cols-1 sm:grid-cols-3 gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Repository
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            RAG Example â†’
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Monitor Example â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

## Contribute

We welcome contributions to the examples. Please submit a PR to the [examples repository](https://github.com/motiadev/motia-examples).


-   [multi-language-data-processing](/docs/examples/multi-language-data-processing): Documentation for multi-language-data-processing.
---
title: 'Multi-Language Processing'
description: 'Multi-Language Data Processing: Building a Unified Pipeline with Motia'
---

Modern backend development often requires combining the strengths of different programming languages. TypeScript for APIs, Python for data processing and AI, JavaScript for rapid prototyping. Traditional approaches involve complex microservices architectures with intricate communication patterns.

This comprehensive guide explores how to build a unified multi-language data processing pipeline using Motia's **step** primitive. We'll cover:

1. **Steps as Core Primitive**: How steps unify different languages under a single abstraction.
2. **Building the Pipeline**: A step-by-step guide to creating a cohesive multi-language data processing workflow.
3. **Unified Execution Model**: How steps enable seamless communication between different runtime environments.
4. **Hands-On Development**: How to build, run, and observe your unified multi-language pipeline.

Let's build a production-ready data processing system where steps unify TypeScript, Python, and JavaScript into a single cohesive workflow.

---

## Explore the Workbench

<div className="my-8">![Multi-Language Data Processing in Motia Workbench](/docs-images/motia-build-your-app-2.gif)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/multi-language-data-processing)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Steps: A Unified Multi-Language Primitive

At its core, our data processing pipeline demonstrates how **steps** solve the fundamental challenge of multi-language systems: unifying different programming languages under a single, coherent abstraction. Traditional polyglot architectures require complex inter-process communication and deployment coordination. Motia's **step** primitive unifies everything.

**Steps enable true language unification:**

- **[TypeScript](https://www.typescriptlang.org/)** steps: Strong typing and excellent tooling for APIs and orchestration
- **[Python](https://www.python.org/)** steps: Rich ecosystem for data processing, ML, and scientific computing  
- **[JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)** steps: Dynamic processing and rapid development
- **[Motia's Step Primitive](https://motia.dev)**: The unifying abstraction that makes all languages work as a single system

Instead of managing multiple services, **steps** provide a single programming model. Whether written in TypeScript, Python, or JavaScript, every step follows the same pattern: receive data, process it, emit events. This unification is what makes multi-language development straightforward.

---

## The Anatomy of Our Multi-Language Pipeline

Our application consists of six specialized steps, each leveraging the optimal language for its specific task. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="01-starter.step.ts" />
  <File name="02-bridge.step.ts" />
  <File name="simple-python_step.py" />
  <File name="notify.step.ts" />
  <File name="04-final.step.ts" />
  <File name="05-summary.step.js" />
</Folder>

<Folder name="types" defaultOpen>
  <File name="index.ts" />
</Folder>

<Tabs items={['api-starter', 'bridge-step', 'python-processor', 'notification-handler', 'finalizer', 'summary-generator']}>
  <Tab value="api-starter">
    The entry point for our multi-language workflow. This TypeScript API endpoint receives data, validates it with Zod schemas, and kicks off the processing pipeline.

```typescript
import { z } from 'zod'

const bodySchema = z.object({
  data: z.record(z.unknown()).optional(),
  message: z.string().optional()
})

// API endpoint to start the multi-language pipeline
export const config = {
  type: 'api',
  name: 'AppStarter',
  description: 'Start the multi-language app pipeline',

  method: 'POST',
  path: '/start-app',

  bodySchema,
  responseSchema: {
    200: z.object({
      message: z.string(),
      appId: z.number(),
      traceId: z.string()
    })
  },

  emits: ['app.started'],
  flows: ['data-processing']
} as const

export const handler = async (req: any, { logger, emit, traceId }: any) => {
  logger.info('ðŸš€ Starting multi-language app', { body: req.body, traceId })
  
  const appData = {
    id: Date.now(),
    input: req.body.data || {},
    started_at: new Date().toISOString(),
    traceId
  }

  // Emit to next step
  await emit({
    topic: 'app.started',
    data: appData
  })

  logger.info('âœ… App started successfully', { 
    appId: appData.id,
    traceId 
  })

  return {
    status: 200,
    body: {
      message: 'Multi-language app started successfully',
      appId: appData.id,
      traceId
    }
  }
}
```

  </Tab>
  <Tab value="bridge-step">
    A TypeScript bridge that receives the app start event, processes the data, and forwards it to the Python processing step with proper type transformation.

```typescript
import { z } from 'zod'

// Bridge step to connect app starter to Python processing
export const config = {
  type: 'event',
  name: 'AppBridge',
  description: 'Bridge between app start and Python processing',
  subscribes: ['app.started'],
  emits: ['data.processed'],
  input: z.object({
    id: z.number(),
    input: z.record(z.unknown()),
    started_at: z.string(),
    traceId: z.string()
  }),
  flows: ['data-processing']
} as const

export const handler = async (input: any, { logger, emit }: any) => {
  logger.info('ðŸŒ‰ Processing app data and sending to Python', { appId: input.id })
  
  // Process data for Python step
  const processedResult = {
    original_id: input.id,
    processed_at: input.started_at,
    result: `Processed: ${JSON.stringify(input.input)}`,
    confidence: 0.95,
    model_version: '1.0'
  }

  // Send to Python processing
  await emit({
    topic: 'data.processed', 
    data: processedResult
  })

  logger.info('âœ… Data sent to Python processing', { 
    originalId: input.id
  })
}
```

  </Tab>
  <Tab value="python-processor">
    The core data processor written in Python, demonstrating how Python steps integrate seamlessly with the TypeScript workflow while maintaining access to Python's rich ecosystem. Note the `_step.py` naming convention.

```python
import time
from datetime import datetime

# Python processing step configuration
config = {
    "type": "event",
    "name": "ProcessDataPython",
    "description": "Process data using Python capabilities",
    "subscribes": ["data.processed"],
    "emits": ["python.done"],
    "flows": ["data-processing"]
}

async def handler(input_data, ctx):
    """
    Python step that processes data and demonstrates Python capabilities
    """
    logger = ctx.logger
    emit = ctx.emit
    
    # Extract data from input
    original_id = input_data.get("original_id")
    result = input_data.get("result", "")
    
    logger.info(f"ðŸ Python processing data for ID: {original_id}")
    
    start_time = time.time()
    
    # Simulate Python data processing
    processed_message = f"Python processed: {result}"
    
    # Add some Python-specific processing
    data_analysis = {
        "word_count": len(result.split()) if isinstance(result, str) else 0,
        "character_count": len(result) if isinstance(result, str) else 0,
        "processed_timestamp": datetime.now().isoformat(),
        "processing_language": "Python 3.x"
    }
    
    processing_time = (time.time() - start_time) * 1000  # Convert to milliseconds
    
    # Create result object
    python_result = {
        "id": original_id,
        "python_message": processed_message,
        "processed_by": ["appStarter", "appBridge", "ProcessDataPython"],
        "processing_time": processing_time,
        "analysis": data_analysis
    }
    
    # Emit to next step
    await emit({
        "topic": "python.done",
        "data": python_result
    })
    
    logger.info(f"âœ… Python processing completed in {processing_time:.2f}ms")
```

  </Tab>
  <Tab value="notification-handler">
    A TypeScript notification handler that processes the Python results and sends notifications, showing seamless data flow between Python and TypeScript.

```typescript
import { z } from 'zod'

export const config = {
  type: 'event',
  name: 'NotificationHandler',
  description: 'Send notifications after Python processing',
  subscribes: ['python.done'],
  emits: ['notification.sent'],
  input: z.object({
    id: z.number(),
    python_message: z.string(),
    processed_by: z.array(z.string()),
    processing_time: z.number(),
    analysis: z.record(z.unknown()).optional()
  }),
  flows: ['data-processing']
} as const

export const handler = async (input: any, { logger, emit }: any) => {
  logger.info('ðŸ“§ Sending notifications after Python processing', { id: input.id })
  
  // Simulate sending notifications (email, slack, etc.)
  const notification = {
    id: input.id,
    message: `Notification: ${input.python_message}`,
    processed_by: input.processed_by,
    sent_at: new Date().toISOString()
  }

  // Send notification data to final step
  await emit({
    topic: 'notification.sent',
    data: {
      ...notification,
      processing_time: input.processing_time
    }
  })

  logger.info('âœ… Notifications sent successfully', { id: input.id })
}
```

  </Tab>
  <Tab value="finalizer">
    A TypeScript finalizer that aggregates all the processing results and prepares the final summary data before handing off to JavaScript for metrics generation.

```typescript
import { z } from 'zod'

// Final step to complete the app - TypeScript
export const config = {
  type: 'event',
  name: 'AppFinalizer',
  description: 'Complete the basic app and log final results',
  subscribes: ['notification.sent'],
  emits: ['app.completed'],
  input: z.object({
    id: z.number(),
    message: z.string(),
    processed_by: z.array(z.string()),
    sent_at: z.string(),
    processing_time: z.number()
  }),
  flows: ['data-processing']
} as const

export const handler = async (input: any, { logger, emit }: any) => {
  logger.info('ðŸ Finalizing app', { 
    notificationId: input.id,
    message: input.message 
  })
  
  // Create final app summary
  const summary = {
    appId: input.id,
    status: 'completed',
    completed_at: new Date().toISOString(),
    steps_executed: [
      'app-starter',
      'app-bridge', 
      'python-processor',
      'notification-handler',
      'app-finalizer'
    ],
    result: input.message
  }

  // Send to JavaScript summary generator
  await emit({
    topic: 'app.completed',
    data: {
      ...summary,
      total_processing_time: input.processing_time
    }
  })

  logger.info('âœ… App finalized successfully', { 
    appId: input.id,
    totalSteps: summary.steps_executed.length
  })
}
```

  </Tab>
  <Tab value="summary-generator">
    The final step uses JavaScript for dynamic summary generation and metrics calculation, showcasing how all three languages work together in a single workflow.

```javascript
// Final summary step - JavaScript
export const config = {
  type: 'event',
  name: 'summaryGenerator',
  description: 'Generate final summary in JavaScript',
  subscribes: ['app.completed'],
  emits: [], // Final step - no further processing needed
  flows: ['data-processing']
}

export const handler = async (input, { logger }) => {
  logger.info('ðŸ“Š Generating final summary in JavaScript', { 
    appId: input.appId,
    status: input.status 
  })
  
  // Calculate processing metrics
  const processingTime = input.total_processing_time || 0
  const stepsCount = input.steps_executed ? input.steps_executed.length : 0
  
  // Create comprehensive summary
  const summary = {
    appId: input.appId,
    finalStatus: input.status,
    totalSteps: stepsCount,
    processingTimeMs: processingTime,
    languages: ['TypeScript', 'Python', 'JavaScript'],
    summary: `Multi-language app completed successfully with ${stepsCount} steps`,
    result: input.result,
    completedAt: new Date().toISOString(),
    generatedBy: 'javascript-summary-step'
  }
  
  // Log final summary (final step - no emit needed)
  logger.info('âœ¨ Final summary generated successfully', summary)
  
  return summary
}
```

  </Tab>
</Tabs>

---

## Type Definitions

Our unified system uses shared TypeScript types to ensure type safety across the multi-language pipeline:

```typescript
// types/index.ts
export interface AppData {
  id: number
  input: Record<string, unknown>
  started_at: string
  traceId: string
}

export interface ProcessedResult {
  original_id: number
  processed_at: string
  result: string
  confidence: number
  model_version: string
}

export interface PythonResult {
  id: number
  python_message: string
  processed_by: string[]
  processing_time: number
}

export interface NotificationData {
  id: number
  message: string
  processed_by: string[]
  sent_at: string
}

export interface AppSummary {
  appId: number
  status: string
  completed_at: string
  steps_executed: string[]
  result: string
}
```

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your multi-language pipeline, making it easy to trace data flow between TypeScript, Python, and JavaScript steps.

<div className="my-8">![Multi-Language Workflow in Motia Workbench](/docs-images/motia-build-your-app-2.gif)</div>

You can monitor real-time execution, view logs from all languages in a unified interface, and trace the complete data flow from the TypeScript API through Python processing to JavaScript summary generation.

---

## Event Flow Architecture

The pipeline follows a clear event-driven flow that connects all languages seamlessly:

1. **`app.started`** - TypeScript API â†’ TypeScript Bridge
2. **`data.processed`** - TypeScript Bridge â†’ Python Processor  
3. **`python.done`** - Python Processor â†’ TypeScript Notification Handler
4. **`notification.sent`** - TypeScript Notification â†’ TypeScript Finalizer
5. **`app.completed`** - TypeScript Finalizer â†’ JavaScript Summary Generator

Each step only needs to know the events it subscribes to and emits, creating loose coupling while maintaining strong data flow guarantees.

---

## Key Features & Benefits

### ðŸ§© **Step as Universal Primitive**
Every piece of logicâ€”whether TypeScript, Python, or JavaScriptâ€”follows the same step pattern, creating true unification.

### ðŸŒ **Seamless Language Integration**
Steps eliminate the complexity of multi-language systems by providing a unified programming model.

### ðŸ“Š **Unified Development Experience**
Write, debug, and monitor all languages through a single interface and shared execution model.

### âš¡ **Hot Reload Across Languages**
Edit any step in any language and see changes instantly across the entire pipeline.

### ðŸ”„ **Event-Driven Communication**
Steps communicate through events, enabling loose coupling and independent scaling.

### ðŸŽ¯ **Single Deployment Model**
Deploy all languages together as a cohesive system, not as separate microservices.

### ðŸ **Python Step Naming**
Python steps use the `_step.py` suffix convention for proper module resolution (e.g., `simple-python_step.py`).

---

## Trying It Out

Ready to build your first multi-language Motia application? Let's get it running.

<Steps>

### Create Your Motia App

Start by creating a new Motia project with the interactive setup.

```shell
npx motia@latest create
```

### Navigate and Start Development

Move into your project directory and start the development server.

```shell
cd my-app  # Replace with your project name
npm run dev
```

### Open the Workbench

Navigate to [`http://localhost:3000`](http://localhost:3000) to access the Workbench and run your workflow.

### Test the Multi-Language Pipeline

Send a request to your API endpoint to see the multi-language workflow in action:

```shell
   curl -X POST http://localhost:3000/start-app \
     -H "Content-Type: application/json" \
     -d '{"data": {"test": "value"}, "message": "Hello!"}'
```

Watch in the Workbench as your data flows through:
1. **TypeScript** validation and event emission
2. **TypeScript** bridge processing and forwarding  
3. **Python** data processing with rich logging
4. **TypeScript** notification handling
5. **TypeScript** finalization and aggregation
6. **JavaScript** summary generation and metrics

</Steps>

---

## ðŸ’» Dive into the Code

Want to explore multi-language workflows further? Check out additional examples and the complete source code:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Multi-Language Examples</h3>
        <p className="text-gray-600 mb-4">Access complete multi-language implementations, configuration examples, and learn how to integrate TypeScript, Python, and JavaScript in production applications.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Explore Examples
          </a>
          <a 
            href="/docs/getting-started/quick-start" 
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Quick Start â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of Unification Through Steps

This multi-language data processing pipeline demonstrates how **steps** fundamentally change multi-language development. By providing a single primitive that works across TypeScript, Python, and JavaScript, we've eliminated the traditional complexity of polyglot architectures.

**The step primitive enables true unification:**
- **Universal Pattern** - Every step, regardless of language, follows the same receive-process-emit pattern
- **Seamless Integration** - Add Ruby, Go, Rust, or any language using the same step abstraction
- **Unified Deployment** - All languages deploy together as a single, coherent system
- **Shared Development Model** - Write, debug, and monitor everything through the same interface

**Key benefits of step-based unification:**
- **Single Mental Model** - Learn the step pattern once, apply it to any language
- **Cohesive System** - All components work together as parts of one application, not separate services
- **Consistent Experience** - Development, debugging, and monitoring work the same way across all languages
- **Natural Scaling** - Each step can scale independently while maintaining system coherence

**Extend your pipeline with more steps:**
- Add specialized processing steps for different data types and business logic
- Integrate machine learning workflows with Python steps for AI processing
- Build real-time analytics with streaming steps for live data processing
- Connect to enterprise systems through database and API integration steps
- Implement scheduled processing with cron steps for batch operations

The **step primitive** makes all extensions natural and straightforwardâ€”every new capability follows the same unified pattern.

Ready to unify your multi-language systems? Start building with steps today!


## Examples
[multi-language-data-processing](/docs/examples/multi-language-data-processing): Code example
---
title: 'Multi-Language Processing'
description: 'Multi-Language Data Processing: Building a Unified Pipeline with Motia'
---

Modern backend development often requires combining the strengths of different programming languages. TypeScript for APIs, Python for data processing and AI, JavaScript for rapid prototyping. Traditional approaches involve complex microservices architectures with intricate communication patterns.

This comprehensive guide explores how to build a unified multi-language data processing pipeline using Motia's **step** primitive. We'll cover:

1. **Steps as Core Primitive**: How steps unify different languages under a single abstraction.
2. **Building the Pipeline**: A step-by-step guide to creating a cohesive multi-language data processing workflow.
3. **Unified Execution Model**: How steps enable seamless communication between different runtime environments.
4. **Hands-On Development**: How to build, run, and observe your unified multi-language pipeline.

Let's build a production-ready data processing system where steps unify TypeScript, Python, and JavaScript into a single cohesive workflow.

---

## Explore the Workbench

<div className="my-8">![Multi-Language Data Processing in Motia Workbench](/docs-images/motia-build-your-app-2.gif)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/multi-language-data-processing)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Steps: A Unified Multi-Language Primitive

At its core, our data processing pipeline demonstrates how **steps** solve the fundamental challenge of multi-language systems: unifying different programming languages under a single, coherent abstraction. Traditional polyglot architectures require complex inter-process communication and deployment coordination. Motia's **step** primitive unifies everything.

**Steps enable true language unification:**

- **[TypeScript](https://www.typescriptlang.org/)** steps: Strong typing and excellent tooling for APIs and orchestration
- **[Python](https://www.python.org/)** steps: Rich ecosystem for data processing, ML, and scientific computing  
- **[JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)** steps: Dynamic processing and rapid development
- **[Motia's Step Primitive](https://motia.dev)**: The unifying abstraction that makes all languages work as a single system

Instead of managing multiple services, **steps** provide a single programming model. Whether written in TypeScript, Python, or JavaScript, every step follows the same pattern: receive data, process it, emit events. This unification is what makes multi-language development straightforward.

---

## The Anatomy of Our Multi-Language Pipeline

Our application consists of six specialized steps, each leveraging the optimal language for its specific task. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="01-starter.step.ts" />
  <File name="02-bridge.step.ts" />
  <File name="simple-python_step.py" />
  <File name="notify.step.ts" />
  <File name="04-final.step.ts" />
  <File name="05-summary.step.js" />
</Folder>

<Folder name="types" defaultOpen>
  <File name="index.ts" />
</Folder>

<Tabs items={['api-starter', 'bridge-step', 'python-processor', 'notification-handler', 'finalizer', 'summary-generator']}>
  <Tab value="api-starter">
    The entry point for our multi-language workflow. This TypeScript API endpoint receives data, validates it with Zod schemas, and kicks off the processing pipeline.

```typescript
import { z } from 'zod'

const bodySchema = z.object({
  data: z.record(z.unknown()).optional(),
  message: z.string().optional()
})

// API endpoint to start the multi-language pipeline
export const config = {
  type: 'api',
  name: 'AppStarter',
  description: 'Start the multi-language app pipeline',

  method: 'POST',
  path: '/start-app',

  bodySchema,
  responseSchema: {
    200: z.object({
      message: z.string(),
      appId: z.number(),
      traceId: z.string()
    })
  },

  emits: ['app.started'],
  flows: ['data-processing']
} as const

export const handler = async (req: any, { logger, emit, traceId }: any) => {
  logger.info('ðŸš€ Starting multi-language app', { body: req.body, traceId })
  
  const appData = {
    id: Date.now(),
    input: req.body.data || {},
    started_at: new Date().toISOString(),
    traceId
  }

  // Emit to next step
  await emit({
    topic: 'app.started',
    data: appData
  })

  logger.info('âœ… App started successfully', { 
    appId: appData.id,
    traceId 
  })

  return {
    status: 200,
    body: {
      message: 'Multi-language app started successfully',
      appId: appData.id,
      traceId
    }
  }
}
```

  </Tab>
  <Tab value="bridge-step">
    A TypeScript bridge that receives the app start event, processes the data, and forwards it to the Python processing step with proper type transformation.

```typescript
import { z } from 'zod'

// Bridge step to connect app starter to Python processing
export const config = {
  type: 'event',
  name: 'AppBridge',
  description: 'Bridge between app start and Python processing',
  subscribes: ['app.started'],
  emits: ['data.processed'],
  input: z.object({
    id: z.number(),
    input: z.record(z.unknown()),
    started_at: z.string(),
    traceId: z.string()
  }),
  flows: ['data-processing']
} as const

export const handler = async (input: any, { logger, emit }: any) => {
  logger.info('ðŸŒ‰ Processing app data and sending to Python', { appId: input.id })
  
  // Process data for Python step
  const processedResult = {
    original_id: input.id,
    processed_at: input.started_at,
    result: `Processed: ${JSON.stringify(input.input)}`,
    confidence: 0.95,
    model_version: '1.0'
  }

  // Send to Python processing
  await emit({
    topic: 'data.processed', 
    data: processedResult
  })

  logger.info('âœ… Data sent to Python processing', { 
    originalId: input.id
  })
}
```

  </Tab>
  <Tab value="python-processor">
    The core data processor written in Python, demonstrating how Python steps integrate seamlessly with the TypeScript workflow while maintaining access to Python's rich ecosystem. Note the `_step.py` naming convention.

```python
import time
from datetime import datetime

# Python processing step configuration
config = {
    "type": "event",
    "name": "ProcessDataPython",
    "description": "Process data using Python capabilities",
    "subscribes": ["data.processed"],
    "emits": ["python.done"],
    "flows": ["data-processing"]
}

async def handler(input_data, ctx):
    """
    Python step that processes data and demonstrates Python capabilities
    """
    logger = ctx.logger
    emit = ctx.emit
    
    # Extract data from input
    original_id = input_data.get("original_id")
    result = input_data.get("result", "")
    
    logger.info(f"ðŸ Python processing data for ID: {original_id}")
    
    start_time = time.time()
    
    # Simulate Python data processing
    processed_message = f"Python processed: {result}"
    
    # Add some Python-specific processing
    data_analysis = {
        "word_count": len(result.split()) if isinstance(result, str) else 0,
        "character_count": len(result) if isinstance(result, str) else 0,
        "processed_timestamp": datetime.now().isoformat(),
        "processing_language": "Python 3.x"
    }
    
    processing_time = (time.time() - start_time) * 1000  # Convert to milliseconds
    
    # Create result object
    python_result = {
        "id": original_id,
        "python_message": processed_message,
        "processed_by": ["appStarter", "appBridge", "ProcessDataPython"],
        "processing_time": processing_time,
        "analysis": data_analysis
    }
    
    # Emit to next step
    await emit({
        "topic": "python.done",
        "data": python_result
    })
    
    logger.info(f"âœ… Python processing completed in {processing_time:.2f}ms")
```

  </Tab>
  <Tab value="notification-handler">
    A TypeScript notification handler that processes the Python results and sends notifications, showing seamless data flow between Python and TypeScript.

```typescript
import { z } from 'zod'

export const config = {
  type: 'event',
  name: 'NotificationHandler',
  description: 'Send notifications after Python processing',
  subscribes: ['python.done'],
  emits: ['notification.sent'],
  input: z.object({
    id: z.number(),
    python_message: z.string(),
    processed_by: z.array(z.string()),
    processing_time: z.number(),
    analysis: z.record(z.unknown()).optional()
  }),
  flows: ['data-processing']
} as const

export const handler = async (input: any, { logger, emit }: any) => {
  logger.info('ðŸ“§ Sending notifications after Python processing', { id: input.id })
  
  // Simulate sending notifications (email, slack, etc.)
  const notification = {
    id: input.id,
    message: `Notification: ${input.python_message}`,
    processed_by: input.processed_by,
    sent_at: new Date().toISOString()
  }

  // Send notification data to final step
  await emit({
    topic: 'notification.sent',
    data: {
      ...notification,
      processing_time: input.processing_time
    }
  })

  logger.info('âœ… Notifications sent successfully', { id: input.id })
}
```

  </Tab>
  <Tab value="finalizer">
    A TypeScript finalizer that aggregates all the processing results and prepares the final summary data before handing off to JavaScript for metrics generation.

```typescript
import { z } from 'zod'

// Final step to complete the app - TypeScript
export const config = {
  type: 'event',
  name: 'AppFinalizer',
  description: 'Complete the basic app and log final results',
  subscribes: ['notification.sent'],
  emits: ['app.completed'],
  input: z.object({
    id: z.number(),
    message: z.string(),
    processed_by: z.array(z.string()),
    sent_at: z.string(),
    processing_time: z.number()
  }),
  flows: ['data-processing']
} as const

export const handler = async (input: any, { logger, emit }: any) => {
  logger.info('ðŸ Finalizing app', { 
    notificationId: input.id,
    message: input.message 
  })
  
  // Create final app summary
  const summary = {
    appId: input.id,
    status: 'completed',
    completed_at: new Date().toISOString(),
    steps_executed: [
      'app-starter',
      'app-bridge', 
      'python-processor',
      'notification-handler',
      'app-finalizer'
    ],
    result: input.message
  }

  // Send to JavaScript summary generator
  await emit({
    topic: 'app.completed',
    data: {
      ...summary,
      total_processing_time: input.processing_time
    }
  })

  logger.info('âœ… App finalized successfully', { 
    appId: input.id,
    totalSteps: summary.steps_executed.length
  })
}
```

  </Tab>
  <Tab value="summary-generator">
    The final step uses JavaScript for dynamic summary generation and metrics calculation, showcasing how all three languages work together in a single workflow.

```javascript
// Final summary step - JavaScript
export const config = {
  type: 'event',
  name: 'summaryGenerator',
  description: 'Generate final summary in JavaScript',
  subscribes: ['app.completed'],
  emits: [], // Final step - no further processing needed
  flows: ['data-processing']
}

export const handler = async (input, { logger }) => {
  logger.info('ðŸ“Š Generating final summary in JavaScript', { 
    appId: input.appId,
    status: input.status 
  })
  
  // Calculate processing metrics
  const processingTime = input.total_processing_time || 0
  const stepsCount = input.steps_executed ? input.steps_executed.length : 0
  
  // Create comprehensive summary
  const summary = {
    appId: input.appId,
    finalStatus: input.status,
    totalSteps: stepsCount,
    processingTimeMs: processingTime,
    languages: ['TypeScript', 'Python', 'JavaScript'],
    summary: `Multi-language app completed successfully with ${stepsCount} steps`,
    result: input.result,
    completedAt: new Date().toISOString(),
    generatedBy: 'javascript-summary-step'
  }
  
  // Log final summary (final step - no emit needed)
  logger.info('âœ¨ Final summary generated successfully', summary)
  
  return summary
}
```

  </Tab>
</Tabs>

---

## Type Definitions

Our unified system uses shared TypeScript types to ensure type safety across the multi-language pipeline:

```typescript
// types/index.ts
export interface AppData {
  id: number
  input: Record<string, unknown>
  started_at: string
  traceId: string
}

export interface ProcessedResult {
  original_id: number
  processed_at: string
  result: string
  confidence: number
  model_version: string
}

export interface PythonResult {
  id: number
  python_message: string
  processed_by: string[]
  processing_time: number
}

export interface NotificationData {
  id: number
  message: string
  processed_by: string[]
  sent_at: string
}

export interface AppSummary {
  appId: number
  status: string
  completed_at: string
  steps_executed: string[]
  result: string
}
```

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your multi-language pipeline, making it easy to trace data flow between TypeScript, Python, and JavaScript steps.

<div className="my-8">![Multi-Language Workflow in Motia Workbench](/docs-images/motia-build-your-app-2.gif)</div>

You can monitor real-time execution, view logs from all languages in a unified interface, and trace the complete data flow from the TypeScript API through Python processing to JavaScript summary generation.

---

## Event Flow Architecture

The pipeline follows a clear event-driven flow that connects all languages seamlessly:

1. **`app.started`** - TypeScript API â†’ TypeScript Bridge
2. **`data.processed`** - TypeScript Bridge â†’ Python Processor  
3. **`python.done`** - Python Processor â†’ TypeScript Notification Handler
4. **`notification.sent`** - TypeScript Notification â†’ TypeScript Finalizer
5. **`app.completed`** - TypeScript Finalizer â†’ JavaScript Summary Generator

Each step only needs to know the events it subscribes to and emits, creating loose coupling while maintaining strong data flow guarantees.

---

## Key Features & Benefits

### ðŸ§© **Step as Universal Primitive**
Every piece of logicâ€”whether TypeScript, Python, or JavaScriptâ€”follows the same step pattern, creating true unification.

### ðŸŒ **Seamless Language Integration**
Steps eliminate the complexity of multi-language systems by providing a unified programming model.

### ðŸ“Š **Unified Development Experience**
Write, debug, and monitor all languages through a single interface and shared execution model.

### âš¡ **Hot Reload Across Languages**
Edit any step in any language and see changes instantly across the entire pipeline.

### ðŸ”„ **Event-Driven Communication**
Steps communicate through events, enabling loose coupling and independent scaling.

### ðŸŽ¯ **Single Deployment Model**
Deploy all languages together as a cohesive system, not as separate microservices.

### ðŸ **Python Step Naming**
Python steps use the `_step.py` suffix convention for proper module resolution (e.g., `simple-python_step.py`).

---

## Trying It Out

Ready to build your first multi-language Motia application? Let's get it running.

<Steps>

### Create Your Motia App

Start by creating a new Motia project with the interactive setup.

```shell
npx motia@latest create
```

### Navigate and Start Development

Move into your project directory and start the development server.

```shell
cd my-app  # Replace with your project name
npm run dev
```

### Open the Workbench

Navigate to [`http://localhost:3000`](http://localhost:3000) to access the Workbench and run your workflow.

### Test the Multi-Language Pipeline

Send a request to your API endpoint to see the multi-language workflow in action:

```shell
   curl -X POST http://localhost:3000/start-app \
     -H "Content-Type: application/json" \
     -d '{"data": {"test": "value"}, "message": "Hello!"}'
```

Watch in the Workbench as your data flows through:
1. **TypeScript** validation and event emission
2. **TypeScript** bridge processing and forwarding  
3. **Python** data processing with rich logging
4. **TypeScript** notification handling
5. **TypeScript** finalization and aggregation
6. **JavaScript** summary generation and metrics

</Steps>

---

## ðŸ’» Dive into the Code

Want to explore multi-language workflows further? Check out additional examples and the complete source code:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Multi-Language Examples</h3>
        <p className="text-gray-600 mb-4">Access complete multi-language implementations, configuration examples, and learn how to integrate TypeScript, Python, and JavaScript in production applications.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Explore Examples
          </a>
          <a 
            href="/docs/getting-started/quick-start" 
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Quick Start â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of Unification Through Steps

This multi-language data processing pipeline demonstrates how **steps** fundamentally change multi-language development. By providing a single primitive that works across TypeScript, Python, and JavaScript, we've eliminated the traditional complexity of polyglot architectures.

**The step primitive enables true unification:**
- **Universal Pattern** - Every step, regardless of language, follows the same receive-process-emit pattern
- **Seamless Integration** - Add Ruby, Go, Rust, or any language using the same step abstraction
- **Unified Deployment** - All languages deploy together as a single, coherent system
- **Shared Development Model** - Write, debug, and monitor everything through the same interface

**Key benefits of step-based unification:**
- **Single Mental Model** - Learn the step pattern once, apply it to any language
- **Cohesive System** - All components work together as parts of one application, not separate services
- **Consistent Experience** - Development, debugging, and monitoring work the same way across all languages
- **Natural Scaling** - Each step can scale independently while maintaining system coherence

**Extend your pipeline with more steps:**
- Add specialized processing steps for different data types and business logic
- Integrate machine learning workflows with Python steps for AI processing
- Build real-time analytics with streaming steps for live data processing
- Connect to enterprise systems through database and API integration steps
- Implement scheduled processing with cron steps for batch operations

The **step primitive** makes all extensions natural and straightforwardâ€”every new capability follows the same unified pattern.

Ready to unify your multi-language systems? Start building with steps today!

-   [rag-docling-weaviate](/docs/examples/rag-docling-weaviate): Documentation for rag-docling-weaviate.
---
title: 'RAG PDF Analyzer'
description: 'Intelligent Document Processing: Building a RAG System with Motia'
---

In the era of AI-powered applications, the ability to extract insights from documents is crucial. Whether you're building a knowledge base, a research assistant, or a customer support system, you need to transform static PDFs into queryable, intelligent systems. This is where Retrieval-Augmented Generation (RAG) architecture shines, and where the Motia framework provides an elegant solution.

This comprehensive guide explores how to build a production-ready RAG system that intelligently processes PDFs and answers questions about their content. We'll cover:

1.  **The RAG Architecture**: Understanding how document processing, vector storage, and AI generation work together.
2.  **Motia's Event-Driven Approach**: How `steps` create a scalable, maintainable RAG pipeline.
3.  **Building the Workflow**: A detailed walkthrough of our polyglot processing pipeline.
4.  **Advanced Features**: Real-time progress tracking, error handling, and production considerations.
5.  **Hands-On Testing**: How to ingest documents and query your knowledge base.

Let's transform your documents into an intelligent AI assistant.

---

## Explore the Workbench

<div className="my-8">![RAG Workflow in Motia Workbench](./../img/rag-docling-weaviate-agent.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Intelligent Document Processing


At its core, our RAG agent solves a fundamental challenge: how do you make unstructured documents searchable and queryable by AI? Traditional approaches often involve complex, monolithic systems that are difficult to scale and maintain. Our Motia-powered solution breaks this down into discrete, event-driven steps that each handle a specific aspect of the pipeline.

The magic happens through the integration of three powerful technologies:

-   **[Docling](https://github.com/docling-project/docling)**: Advanced PDF parsing with intelligent chunking that preserves document structure
-   **[Weaviate](https://weaviate.io/)**: Cloud-native vector database with built-in OpenAI integration
-   **[Motia](https://motia.dev)**: Event-driven framework that orchestrates the entire pipeline

Instead of a brittle, tightly-coupled system, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our RAG Pipeline

Our application consists of seven specialized steps, each handling a specific part of the document processing and querying workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <Folder name="api-steps" defaultOpen>
    <File name="api-process-pdfs.step.ts" />
    <File name="api-query-rag.step.ts" />
  </Folder>
  <Folder name="event-steps" defaultOpen>
    <File name="init-weaviate.step.ts" />
    <File name="read-pdfs.step.ts" />
    <File name="process-pdfs.step.py" />
    <File name="load-weaviate.step.ts" />
  </Folder>
</Folder>

<Tabs items={['api-process-pdfs', 'init-weaviate', 'read-pdfs', 'process-pdfs', 'load-weaviate', 'api-query-rag']}>
  <Tab value="api-process-pdfs">
    The entry point for document ingestion. This API endpoint receives a folder path, kicks off the processing pipeline, and returns immediately with a tracking ID for real-time progress monitoring.

    ```ts
    import { Handlers } from 'motia'
    import { z } from 'zod'
    import { v4 as uuidv4 } from 'uuid'

    export const config = {
      type: 'api',
      name: 'api-process-pdfs',
      description: 'API endpoint to start PDF processing pipeline',
      path: '/api/rag/process-pdfs',
      method: 'POST',
      emits: ['rag.read.pdfs'],
      bodySchema: z.object({
        folderPath: z.string().min(1, 'folderPath is required'),
      }),
      flows: ['rag-workflow'],
    } as const

    export const handler: Handlers['api-process-pdfs'] = async (req, { emit, logger }) => {
      const { folderPath } = req.body
      const streamId = uuidv4()

      logger.info('Starting PDF processing pipeline', { folderPath, streamId })

      // Emit event to start the processing chain
      await emit({
        topic: 'rag.read.pdfs',
        data: { folderPath, streamId },
      })

      return {
        status: 200,
        body: { 
          message: 'PDF processing started',
          streamId,
          status: 'processing'
        },
      }
    }
    ```

  </Tab>
  <Tab value="init-weaviate">
    Ensures the Weaviate vector database is properly configured with the correct schema for our documents. This step creates the "Books" collection with OpenAI embeddings and GPT-4o generation capabilities.

    ```ts
    import weaviate, { WeaviateClient, vectorizer, generative } from 'weaviate-client'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: EventConfig = {
      type: 'event',
      name: 'init-weaviate',
      subscribes: ['rag.read.pdfs'],
      emits: [],
      flows: ['rag-workflow'],
      input: z.object({
        folderPath: z.string(),
        streamId: z.string().optional(),
      }),
    }

    const WEAVIATE_SCHEMA = {
      name: 'Books',
      description: 'Document chunks with metadata',
      vectorizers: vectorizer.text2VecOpenAI({
        model: 'text-embedding-3-small',
        sourceProperties: ['text'],
      }),
      generative: generative.openAI({
        model: 'gpt-4o',
        maxTokens: 4096,
      }),
      properties: [
        { name: 'text', dataType: 'text' as const },
        { name: 'title', dataType: 'text' as const },
        { name: 'source', dataType: 'text' as const },
        { name: 'page', dataType: 'number' as const },
      ],
    }

    export const handler: Handlers['init-weaviate'] = async (input, { logger }) => {
      logger.info('Initializing Weaviate client')
      
      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const exists = await client.collections.get('Books').exists()
        if (!exists) {
          logger.info('Creating Books collection with OpenAI integration...')
          await client.collections.create(WEAVIATE_SCHEMA)
          logger.info('Collection created successfully')
        } else {
          logger.info('Books collection already exists')
        }
      } catch (error) {
        logger.error('Error initializing Weaviate', { error })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="read-pdfs">
    Scans the specified folder for PDF files and prepares them for processing. Includes intelligent path resolution to handle various folder structures.

    ```ts
    import { readdir } from 'fs/promises'
    import { join, resolve, basename } from 'path'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: EventConfig = {
      type: 'event',
      name: 'read-pdfs',
      flows: ['rag-workflow'],
      subscribes: ['rag.read.pdfs'],
      emits: [{ topic: 'rag.process.pdfs', label: 'Start processing PDFs' }],
      input: z.object({
        folderPath: z.string(),
        streamId: z.string().optional(),
      }),
    }

    export const handler: Handlers['read-pdfs'] = async (input, { emit, logger }) => {
      const { folderPath: inputFolderPath, streamId } = input
      logger.info(`Reading PDFs from folder: ${inputFolderPath}`)

      // Intelligent path resolution to prevent ENOENT errors
      const currentDirName = basename(process.cwd())
      let resolvedFolderPath = resolve(inputFolderPath)

      // Handle duplicated path segments
      const duplicatedSegment = `${currentDirName}/${currentDirName}`
      if (resolvedFolderPath.includes(duplicatedSegment)) {
        resolvedFolderPath = resolvedFolderPath.replace(duplicatedSegment, currentDirName)
      }

      logger.info(`Resolved folder path: ${resolvedFolderPath}`)

      try {
        const files = await readdir(resolvedFolderPath)
        const pdfFiles = files.filter((file) => file.endsWith('.pdf'))

        logger.info(`Found ${pdfFiles.length} PDF files`)

        const filesInfo = await Promise.all(
          pdfFiles.map(async (pdfFile) => {
            const filePath = join(resolvedFolderPath, pdfFile)
            return {
              filePath,
              fileName: pdfFile,
            }
          })
        )

        await emit({
          topic: 'rag.process.pdfs',
          data: { files: filesInfo, streamId },
        })
      } catch (error) {
        logger.error(`Failed to read PDFs from folder: ${resolvedFolderPath}`, { error })
        throw error
      }
    }
    ```

  </Tab>
  <Tab value="process-pdfs">
    The heart of our document processing pipeline. This Python step uses Docling to intelligently parse and chunk PDFs, preserving document structure and context.

    ```python
    import json
    import os
    from pathlib import Path
    from typing import Any, Dict, List
    from docling.document_converter import DocumentConverter
    from docling.chunking import HybridChunker
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions
    from docling.document_converter import PdfFormatOption

    def handler(input_data: Dict[str, Any], context: Dict[str, Any]) -> None:
        """Process PDFs using Docling with intelligent chunking"""
        logger = context['logger']
        emit = context['emit']
        
        files = input_data.get('files', [])
        stream_id = input_data.get('streamId')
        
        logger.info(f"Processing {len(files)} PDF files with Docling")
        
        # Configure Docling with optimized settings
        pipeline_options = PdfPipelineOptions(
            do_ocr=True,
            do_table_structure=True,
            table_structure_options={
                "do_cell_matching": True,
            }
        )
        
        doc_converter = DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
            }
        )
        
        # Initialize the hybrid chunker for intelligent document segmentation
        chunker = HybridChunker(
            tokenizer="cl100k_base",
            max_tokens=512,
            overlap_tokens=50,
            heading_hierarchies=True,
            split_by_page=False
        )
        
        all_chunks = []
        
        for file_info in files:
            file_path = file_info['filePath']
            file_name = file_info['fileName']
            
            logger.info(f"Processing file: {file_name}")
            
            try:
                # Convert PDF to structured document
                result = doc_converter.convert(file_path)
                doc = result.document
                
                logger.info(f"Converted {file_name}: {len(doc.pages)} pages")
                
                # Apply intelligent chunking
                chunks = list(chunker.chunk(doc))
                logger.info(f"Generated {len(chunks)} chunks for {file_name}")
                
                # Prepare chunks for Weaviate
                for i, chunk in enumerate(chunks):
                    chunk_data = {
                        'text': chunk.text,
                        'title': file_name,
                        'source': file_path,
                        'page': getattr(chunk, 'page_no', i + 1),
                        'chunk_id': f"{file_name}_chunk_{i}"
                    }
                    all_chunks.append(chunk_data)
                    
            except Exception as e:
                logger.error(f"Error processing {file_name}: {str(e)}")
                continue
        
        logger.info(f"Total chunks generated: {len(all_chunks)}")
        
        if all_chunks:
            # Emit chunks for Weaviate ingestion
            emit({
                'topic': 'rag.load.weaviate',
                'data': {
                    'chunks': all_chunks,
                    'streamId': stream_id,
                    'totalFiles': len(files),
                    'totalChunks': len(all_chunks)
                }
            })
        else:
            logger.warning("No chunks generated from PDF processing")
    ```

  </Tab>
  <Tab value="load-weaviate">
    Efficiently batches and loads the processed document chunks into Weaviate with progress tracking and error handling.

    ```ts
    import weaviate from 'weaviate-client'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    const ChunkSchema = z.object({
      text: z.string(),
      title: z.string(),
      source: z.string(),
      page: z.number(),
      chunk_id: z.string(),
    })

    export const config: EventConfig = {
      type: 'event',
      name: 'load-weaviate',
      subscribes: ['rag.load.weaviate'],
      emits: [],
      flows: ['rag-workflow'],
      input: z.object({
        chunks: z.array(ChunkSchema),
        streamId: z.string().optional(),
        totalFiles: z.number().optional(),
        totalChunks: z.number().optional(),
      }),
    }

    export const handler: Handlers['load-weaviate'] = async (input, { logger }) => {
      const { chunks, streamId, totalFiles, totalChunks } = input
      
      logger.info('Loading chunks into Weaviate', { 
        chunkCount: chunks.length,
        totalFiles,
        totalChunks,
        streamId 
      })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        const BATCH_SIZE = 100

        // Process chunks in batches for optimal performance
        for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
          const batch = chunks.slice(i, i + BATCH_SIZE)
          const batchNumber = Math.floor(i / BATCH_SIZE) + 1
          const totalBatches = Math.ceil(chunks.length / BATCH_SIZE)

          logger.info(`Inserting batch ${batchNumber}/${totalBatches}`, {
            batchSize: batch.length,
            streamId
          })

          const objects = batch.map(chunk => ({
            properties: {
              text: chunk.text,
              title: chunk.title,
              source: chunk.source,
              page: chunk.page,
            }
          }))

          const result = await collection.data.insertMany(objects)
          
          if (result.hasErrors) {
            logger.error('Batch insertion had errors', { 
              errors: result.errors,
              batchNumber,
              streamId 
            })
          } else {
            logger.info(`Successfully inserted batch ${batchNumber}/${totalBatches}`)
          }
        }

        logger.info('Successfully loaded all chunks into Weaviate', {
          totalChunks: chunks.length,
          streamId
        })

      } catch (error) {
        logger.error('Error loading chunks into Weaviate', { error, streamId })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="api-query-rag">
    The query interface that performs semantic search and generates contextual answers using Weaviate's integrated OpenAI capabilities.

    ```ts
    import weaviate from 'weaviate-client'
    import { Handlers } from 'motia'
    import { z } from 'zod'

    const RAGResponse = z.object({
      answer: z.string(),
      chunks: z.array(z.object({
        text: z.string(),
        title: z.string(),
        source: z.string(),
        page: z.number(),
      })),
      query: z.string(),
      timestamp: z.string(),
    })

    export const config = {
      type: 'api',
      name: 'api-query-rag',
      description: 'Query the RAG system for answers',
      path: '/api/rag/query',
      method: 'POST',
      emits: [],
      bodySchema: z.object({
        query: z.string().min(1, 'Query is required'),
        limit: z.number().min(1).max(10).default(3),
      }),
      flows: ['rag-workflow'],
    } as const

    export const handler: Handlers['api-query-rag'] = async (req, { logger }) => {
      const { query, limit = 3 } = req.body

      logger.info('Processing RAG query', { query, limit })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        
        // Perform semantic search with AI generation
        const results = await collection.generate.nearText(
          query,
          { limit, distance: 0.6 },
          { 
            singlePrompt: `Answer this question based on the provided context: ${query}. 
                          Be specific and cite the sources when possible.` 
          }
        )

        // Extract the generated answer and source chunks
        const generatedAnswer = results.generated || 'No answer could be generated.'
        
        const chunks = results.objects.map(obj => ({
          text: obj.properties.text as string,
          title: obj.properties.title as string,
          source: obj.properties.source as string,
          page: obj.properties.page as number,
        }))

        const response = RAGResponse.parse({
          answer: generatedAnswer,
          chunks,
          query,
          timestamp: new Date().toISOString(),
        })

        logger.info('RAG query completed successfully', { 
          query, 
          chunksFound: chunks.length,
          answerLength: generatedAnswer.length 
        })

        return {
          status: 200,
          body: response,
        }

      } catch (error) {
        logger.error('Error processing RAG query', { error, query })
        return {
          status: 500,
          body: { error: 'Failed to process query' },
        }
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your RAG pipeline, making it easy to understand the flow and debug any issues.

<div className="my-8">![RAG Workflow in Motia Workbench](./../img/rag-example.gif)</div>

You can monitor real-time processing, view logs, and trace the execution of each step directly in the Workbench interface. This makes development and debugging significantly easier compared to traditional monolithic approaches.

---

## Key Features & Benefits

### ðŸš€ **Event-Driven Architecture**
Each step is independent and communicates through events, making the system highly scalable and maintainable.

### ðŸ§  **Intelligent Document Processing**  
Docling's hybrid chunking preserves document structure while creating optimal chunks for embedding.

### âš¡ **High-Performance Vector Search**
Weaviate's cloud-native architecture provides fast, scalable similarity search with built-in OpenAI integration.

### ðŸ”„ **Real-Time Progress Tracking**
Monitor document processing progress with detailed logging and status updates.

### ðŸŒ **Polyglot Support**
Seamlessly combine Python (Docling) and TypeScript (orchestration) in a single workflow.

### ðŸ›¡ï¸ **Production-Ready**
Built-in error handling, batch processing, and resource cleanup ensure reliability.

---

## Trying It Out

Ready to build your own intelligent document assistant? Let's get the system running.

<Steps>

### Install Dependencies

Install both Node.js and Python dependencies. The prepare script automatically sets up the Python virtual environment.

```shell
npm install
```

### Set Your Environment Variables

You'll need API keys for OpenAI and Weaviate Cloud. Create a `.env` file:

```shell
OPENAI_API_KEY="sk-..."
WEAVIATE_URL="https://your-cluster.weaviate.network"
WEAVIATE_API_KEY="your-weaviate-api-key"
```

### Run the Project

Start the Motia development server to begin processing documents.

```shell
npm run dev
```

### Process Your First Documents

Add some PDF files to the `docs/pdfs/` folder, then start the ingestion pipeline:

```shell
curl -X POST http://localhost:3000/api/rag/process-pdfs \
  -H "Content-Type: application/json" \
  -d '{"folderPath":"docs/pdfs"}'
```

Watch the logs as your documents are processed through the pipeline:
1. **PDF Reading**: Files are discovered and queued
2. **Docling Processing**: Intelligent chunking with structure preservation  
3. **Weaviate Loading**: Chunks are embedded and stored

### Query Your Knowledge Base

Once processing is complete, you can ask questions about your documents:

#### General Query
```shell
curl -X POST http://localhost:3000/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What are the main topics covered in these documents?","limit":3}'
```

#### Specific Question
```shell
curl -X POST http://localhost:3000/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What methodology was used in the research?","limit":5}'
```

The response includes both a generated answer and the source chunks with page numbers for verification.

</Steps>

---

## Advanced Usage

### Custom Chunking Strategies

Modify the Python processing step to implement custom chunking logic:

```python
# In process-pdfs.step.py
chunker = HybridChunker(
    tokenizer="cl100k_base",
    max_tokens=1024,  # Larger chunks for more context
    overlap_tokens=100,  # More overlap for better continuity
    heading_hierarchies=True,
    split_by_page=True  # Preserve page boundaries
)
```

### Batch Processing Optimization

Adjust batch sizes in the Weaviate loading step for optimal performance:

```ts
// In load-weaviate.step.ts
const BATCH_SIZE = 50  // Smaller batches for large documents
```

### Multi-Collection Support

Extend the system to handle different document types by creating separate Weaviate collections:

```ts
const COLLECTIONS = {
  research: 'ResearchPapers',
  manuals: 'TechnicalManuals', 
  reports: 'BusinessReports'
}
```

---

## Troubleshooting

### Common Issues

**ENOENT Path Errors**: The system automatically handles path normalization, but ensure your `folderPath` is relative to the project root.

**Empty Answers**: Check that documents were successfully processed by examining the logs. Verify your OpenAI API key is valid.

**Weaviate Connection Issues**: Ensure your `WEAVIATE_URL` and `WEAVIATE_API_KEY` are correct and your cluster is running.

### Performance Tips

- **Document Size**: For large PDFs, consider preprocessing to split them into smaller files
- **Batch Size**: Adjust the Weaviate batch size based on your cluster's capacity
- **Chunking Strategy**: Experiment with different chunk sizes and overlap for your specific use case

---

## ðŸ’» Dive into the Code

Want to explore the complete RAG implementation? Check out the full source code, including all steps, configuration files, and setup instructions:

<div className="not-prose">
  <div className="bg-gradient-to-r from-purple-50 to-pink-50 border border-purple-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-purple-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete RAG Implementation</h3>
        <p className="text-gray-600 mb-4">Access the full source code for this RAG agent, including Python processing scripts, TypeScript orchestration, and production configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View RAG Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Future of Document Intelligence

This RAG system demonstrates the power of combining best-in-class technologies with Motia's event-driven architecture. By breaking down complex document processing into discrete, manageable steps, we've created a system that's not only powerful but also maintainable and scalable.

The polyglot nature of the solution: Python for document processing, TypeScript for orchestration, shows how Motia enables you to use the right tool for each job without sacrificing integration or maintainability.

From here, you can extend the system by:
- Adding support for other document formats (Word, PowerPoint, etc.)
- Implementing document classification and routing
- Adding real-time document updates and synchronization
- Building a web interface for document management
- Integrating with existing business systems

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing pipeline.

Ready to transform your documents into intelligent, queryable knowledge bases? Start building with Motia today!



## Examples
[rag-docling-weaviate](/docs/examples/rag-docling-weaviate): Code example
---
title: 'RAG PDF Analyzer'
description: 'Intelligent Document Processing: Building a RAG System with Motia'
---

In the era of AI-powered applications, the ability to extract insights from documents is crucial. Whether you're building a knowledge base, a research assistant, or a customer support system, you need to transform static PDFs into queryable, intelligent systems. This is where Retrieval-Augmented Generation (RAG) architecture shines, and where the Motia framework provides an elegant solution.

This comprehensive guide explores how to build a production-ready RAG system that intelligently processes PDFs and answers questions about their content. We'll cover:

1.  **The RAG Architecture**: Understanding how document processing, vector storage, and AI generation work together.
2.  **Motia's Event-Driven Approach**: How `steps` create a scalable, maintainable RAG pipeline.
3.  **Building the Workflow**: A detailed walkthrough of our polyglot processing pipeline.
4.  **Advanced Features**: Real-time progress tracking, error handling, and production considerations.
5.  **Hands-On Testing**: How to ingest documents and query your knowledge base.

Let's transform your documents into an intelligent AI assistant.

---

## Explore the Workbench

<div className="my-8">![RAG Workflow in Motia Workbench](./../img/rag-docling-weaviate-agent.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate-agent)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Intelligent Document Processing


At its core, our RAG agent solves a fundamental challenge: how do you make unstructured documents searchable and queryable by AI? Traditional approaches often involve complex, monolithic systems that are difficult to scale and maintain. Our Motia-powered solution breaks this down into discrete, event-driven steps that each handle a specific aspect of the pipeline.

The magic happens through the integration of three powerful technologies:

-   **[Docling](https://github.com/docling-project/docling)**: Advanced PDF parsing with intelligent chunking that preserves document structure
-   **[Weaviate](https://weaviate.io/)**: Cloud-native vector database with built-in OpenAI integration
-   **[Motia](https://motia.dev)**: Event-driven framework that orchestrates the entire pipeline

Instead of a brittle, tightly-coupled system, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our RAG Pipeline

Our application consists of seven specialized steps, each handling a specific part of the document processing and querying workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <Folder name="api-steps" defaultOpen>
    <File name="api-process-pdfs.step.ts" />
    <File name="api-query-rag.step.ts" />
  </Folder>
  <Folder name="event-steps" defaultOpen>
    <File name="init-weaviate.step.ts" />
    <File name="read-pdfs.step.ts" />
    <File name="process-pdfs.step.py" />
    <File name="load-weaviate.step.ts" />
  </Folder>
</Folder>

<Tabs items={['api-process-pdfs', 'init-weaviate', 'read-pdfs', 'process-pdfs', 'load-weaviate', 'api-query-rag']}>
  <Tab value="api-process-pdfs">
    The entry point for document ingestion. This API endpoint receives a folder path, kicks off the processing pipeline, and returns immediately with a tracking ID for real-time progress monitoring.

    ```ts
    import { Handlers } from 'motia'
    import { z } from 'zod'
    import { v4 as uuidv4 } from 'uuid'

    export const config = {
      type: 'api',
      name: 'api-process-pdfs',
      description: 'API endpoint to start PDF processing pipeline',
      path: '/api/rag/process-pdfs',
      method: 'POST',
      emits: ['rag.read.pdfs'],
      bodySchema: z.object({
        folderPath: z.string().min(1, 'folderPath is required'),
      }),
      flows: ['rag-workflow'],
    } as const

    export const handler: Handlers['api-process-pdfs'] = async (req, { emit, logger }) => {
      const { folderPath } = req.body
      const streamId = uuidv4()

      logger.info('Starting PDF processing pipeline', { folderPath, streamId })

      // Emit event to start the processing chain
      await emit({
        topic: 'rag.read.pdfs',
        data: { folderPath, streamId },
      })

      return {
        status: 200,
        body: { 
          message: 'PDF processing started',
          streamId,
          status: 'processing'
        },
      }
    }
    ```

  </Tab>
  <Tab value="init-weaviate">
    Ensures the Weaviate vector database is properly configured with the correct schema for our documents. This step creates the "Books" collection with OpenAI embeddings and GPT-4o generation capabilities.

    ```ts
    import weaviate, { WeaviateClient, vectorizer, generative } from 'weaviate-client'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: EventConfig = {
      type: 'event',
      name: 'init-weaviate',
      subscribes: ['rag.read.pdfs'],
      emits: [],
      flows: ['rag-workflow'],
      input: z.object({
        folderPath: z.string(),
        streamId: z.string().optional(),
      }),
    }

    const WEAVIATE_SCHEMA = {
      name: 'Books',
      description: 'Document chunks with metadata',
      vectorizers: vectorizer.text2VecOpenAI({
        model: 'text-embedding-3-small',
        sourceProperties: ['text'],
      }),
      generative: generative.openAI({
        model: 'gpt-4o',
        maxTokens: 4096,
      }),
      properties: [
        { name: 'text', dataType: 'text' as const },
        { name: 'title', dataType: 'text' as const },
        { name: 'source', dataType: 'text' as const },
        { name: 'page', dataType: 'number' as const },
      ],
    }

    export const handler: Handlers['init-weaviate'] = async (input, { logger }) => {
      logger.info('Initializing Weaviate client')
      
      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const exists = await client.collections.get('Books').exists()
        if (!exists) {
          logger.info('Creating Books collection with OpenAI integration...')
          await client.collections.create(WEAVIATE_SCHEMA)
          logger.info('Collection created successfully')
        } else {
          logger.info('Books collection already exists')
        }
      } catch (error) {
        logger.error('Error initializing Weaviate', { error })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="read-pdfs">
    Scans the specified folder for PDF files and prepares them for processing. Includes intelligent path resolution to handle various folder structures.

    ```ts
    import { readdir } from 'fs/promises'
    import { join, resolve, basename } from 'path'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: EventConfig = {
      type: 'event',
      name: 'read-pdfs',
      flows: ['rag-workflow'],
      subscribes: ['rag.read.pdfs'],
      emits: [{ topic: 'rag.process.pdfs', label: 'Start processing PDFs' }],
      input: z.object({
        folderPath: z.string(),
        streamId: z.string().optional(),
      }),
    }

    export const handler: Handlers['read-pdfs'] = async (input, { emit, logger }) => {
      const { folderPath: inputFolderPath, streamId } = input
      logger.info(`Reading PDFs from folder: ${inputFolderPath}`)

      // Intelligent path resolution to prevent ENOENT errors
      const currentDirName = basename(process.cwd())
      let resolvedFolderPath = resolve(inputFolderPath)

      // Handle duplicated path segments
      const duplicatedSegment = `${currentDirName}/${currentDirName}`
      if (resolvedFolderPath.includes(duplicatedSegment)) {
        resolvedFolderPath = resolvedFolderPath.replace(duplicatedSegment, currentDirName)
      }

      logger.info(`Resolved folder path: ${resolvedFolderPath}`)

      try {
        const files = await readdir(resolvedFolderPath)
        const pdfFiles = files.filter((file) => file.endsWith('.pdf'))

        logger.info(`Found ${pdfFiles.length} PDF files`)

        const filesInfo = await Promise.all(
          pdfFiles.map(async (pdfFile) => {
            const filePath = join(resolvedFolderPath, pdfFile)
            return {
              filePath,
              fileName: pdfFile,
            }
          })
        )

        await emit({
          topic: 'rag.process.pdfs',
          data: { files: filesInfo, streamId },
        })
      } catch (error) {
        logger.error(`Failed to read PDFs from folder: ${resolvedFolderPath}`, { error })
        throw error
      }
    }
    ```

  </Tab>
  <Tab value="process-pdfs">
    The heart of our document processing pipeline. This Python step uses Docling to intelligently parse and chunk PDFs, preserving document structure and context.

    ```python
    import json
    import os
    from pathlib import Path
    from typing import Any, Dict, List
    from docling.document_converter import DocumentConverter
    from docling.chunking import HybridChunker
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions
    from docling.document_converter import PdfFormatOption

    def handler(input_data: Dict[str, Any], context: Dict[str, Any]) -> None:
        """Process PDFs using Docling with intelligent chunking"""
        logger = context['logger']
        emit = context['emit']
        
        files = input_data.get('files', [])
        stream_id = input_data.get('streamId')
        
        logger.info(f"Processing {len(files)} PDF files with Docling")
        
        # Configure Docling with optimized settings
        pipeline_options = PdfPipelineOptions(
            do_ocr=True,
            do_table_structure=True,
            table_structure_options={
                "do_cell_matching": True,
            }
        )
        
        doc_converter = DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
            }
        )
        
        # Initialize the hybrid chunker for intelligent document segmentation
        chunker = HybridChunker(
            tokenizer="cl100k_base",
            max_tokens=512,
            overlap_tokens=50,
            heading_hierarchies=True,
            split_by_page=False
        )
        
        all_chunks = []
        
        for file_info in files:
            file_path = file_info['filePath']
            file_name = file_info['fileName']
            
            logger.info(f"Processing file: {file_name}")
            
            try:
                # Convert PDF to structured document
                result = doc_converter.convert(file_path)
                doc = result.document
                
                logger.info(f"Converted {file_name}: {len(doc.pages)} pages")
                
                # Apply intelligent chunking
                chunks = list(chunker.chunk(doc))
                logger.info(f"Generated {len(chunks)} chunks for {file_name}")
                
                # Prepare chunks for Weaviate
                for i, chunk in enumerate(chunks):
                    chunk_data = {
                        'text': chunk.text,
                        'title': file_name,
                        'source': file_path,
                        'page': getattr(chunk, 'page_no', i + 1),
                        'chunk_id': f"{file_name}_chunk_{i}"
                    }
                    all_chunks.append(chunk_data)
                    
            except Exception as e:
                logger.error(f"Error processing {file_name}: {str(e)}")
                continue
        
        logger.info(f"Total chunks generated: {len(all_chunks)}")
        
        if all_chunks:
            # Emit chunks for Weaviate ingestion
            emit({
                'topic': 'rag.load.weaviate',
                'data': {
                    'chunks': all_chunks,
                    'streamId': stream_id,
                    'totalFiles': len(files),
                    'totalChunks': len(all_chunks)
                }
            })
        else:
            logger.warning("No chunks generated from PDF processing")
    ```

  </Tab>
  <Tab value="load-weaviate">
    Efficiently batches and loads the processed document chunks into Weaviate with progress tracking and error handling.

    ```ts
    import weaviate from 'weaviate-client'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    const ChunkSchema = z.object({
      text: z.string(),
      title: z.string(),
      source: z.string(),
      page: z.number(),
      chunk_id: z.string(),
    })

    export const config: EventConfig = {
      type: 'event',
      name: 'load-weaviate',
      subscribes: ['rag.load.weaviate'],
      emits: [],
      flows: ['rag-workflow'],
      input: z.object({
        chunks: z.array(ChunkSchema),
        streamId: z.string().optional(),
        totalFiles: z.number().optional(),
        totalChunks: z.number().optional(),
      }),
    }

    export const handler: Handlers['load-weaviate'] = async (input, { logger }) => {
      const { chunks, streamId, totalFiles, totalChunks } = input
      
      logger.info('Loading chunks into Weaviate', { 
        chunkCount: chunks.length,
        totalFiles,
        totalChunks,
        streamId 
      })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        const BATCH_SIZE = 100

        // Process chunks in batches for optimal performance
        for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
          const batch = chunks.slice(i, i + BATCH_SIZE)
          const batchNumber = Math.floor(i / BATCH_SIZE) + 1
          const totalBatches = Math.ceil(chunks.length / BATCH_SIZE)

          logger.info(`Inserting batch ${batchNumber}/${totalBatches}`, {
            batchSize: batch.length,
            streamId
          })

          const objects = batch.map(chunk => ({
            properties: {
              text: chunk.text,
              title: chunk.title,
              source: chunk.source,
              page: chunk.page,
            }
          }))

          const result = await collection.data.insertMany(objects)
          
          if (result.hasErrors) {
            logger.error('Batch insertion had errors', { 
              errors: result.errors,
              batchNumber,
              streamId 
            })
          } else {
            logger.info(`Successfully inserted batch ${batchNumber}/${totalBatches}`)
          }
        }

        logger.info('Successfully loaded all chunks into Weaviate', {
          totalChunks: chunks.length,
          streamId
        })

      } catch (error) {
        logger.error('Error loading chunks into Weaviate', { error, streamId })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="api-query-rag">
    The query interface that performs semantic search and generates contextual answers using Weaviate's integrated OpenAI capabilities.

    ```ts
    import weaviate from 'weaviate-client'
    import { Handlers } from 'motia'
    import { z } from 'zod'

    const RAGResponse = z.object({
      answer: z.string(),
      chunks: z.array(z.object({
        text: z.string(),
        title: z.string(),
        source: z.string(),
        page: z.number(),
      })),
      query: z.string(),
      timestamp: z.string(),
    })

    export const config = {
      type: 'api',
      name: 'api-query-rag',
      description: 'Query the RAG system for answers',
      path: '/api/rag/query',
      method: 'POST',
      emits: [],
      bodySchema: z.object({
        query: z.string().min(1, 'Query is required'),
        limit: z.number().min(1).max(10).default(3),
      }),
      flows: ['rag-workflow'],
    } as const

    export const handler: Handlers['api-query-rag'] = async (req, { logger }) => {
      const { query, limit = 3 } = req.body

      logger.info('Processing RAG query', { query, limit })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        
        // Perform semantic search with AI generation
        const results = await collection.generate.nearText(
          query,
          { limit, distance: 0.6 },
          { 
            singlePrompt: `Answer this question based on the provided context: ${query}. 
                          Be specific and cite the sources when possible.` 
          }
        )

        // Extract the generated answer and source chunks
        const generatedAnswer = results.generated || 'No answer could be generated.'
        
        const chunks = results.objects.map(obj => ({
          text: obj.properties.text as string,
          title: obj.properties.title as string,
          source: obj.properties.source as string,
          page: obj.properties.page as number,
        }))

        const response = RAGResponse.parse({
          answer: generatedAnswer,
          chunks,
          query,
          timestamp: new Date().toISOString(),
        })

        logger.info('RAG query completed successfully', { 
          query, 
          chunksFound: chunks.length,
          answerLength: generatedAnswer.length 
        })

        return {
          status: 200,
          body: response,
        }

      } catch (error) {
        logger.error('Error processing RAG query', { error, query })
        return {
          status: 500,
          body: { error: 'Failed to process query' },
        }
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your RAG pipeline, making it easy to understand the flow and debug any issues.

<div className="my-8">![RAG Workflow in Motia Workbench](./../img/rag-example.gif)</div>

You can monitor real-time processing, view logs, and trace the execution of each step directly in the Workbench interface. This makes development and debugging significantly easier compared to traditional monolithic approaches.

---

## Key Features & Benefits

### ðŸš€ **Event-Driven Architecture**
Each step is independent and communicates through events, making the system highly scalable and maintainable.

### ðŸ§  **Intelligent Document Processing**  
Docling's hybrid chunking preserves document structure while creating optimal chunks for embedding.

### âš¡ **High-Performance Vector Search**
Weaviate's cloud-native architecture provides fast, scalable similarity search with built-in OpenAI integration.

### ðŸ”„ **Real-Time Progress Tracking**
Monitor document processing progress with detailed logging and status updates.

### ðŸŒ **Polyglot Support**
Seamlessly combine Python (Docling) and TypeScript (orchestration) in a single workflow.

### ðŸ›¡ï¸ **Production-Ready**
Built-in error handling, batch processing, and resource cleanup ensure reliability.

---

## Trying It Out

Ready to build your own intelligent document assistant? Let's get the system running.

<Steps>

### Install Dependencies

Install both Node.js and Python dependencies. The prepare script automatically sets up the Python virtual environment.

```shell
npm install
```

### Set Your Environment Variables

You'll need API keys for OpenAI and Weaviate Cloud. Create a `.env` file:

```shell
OPENAI_API_KEY="sk-..."
WEAVIATE_URL="https://your-cluster.weaviate.network"
WEAVIATE_API_KEY="your-weaviate-api-key"
```

### Run the Project

Start the Motia development server to begin processing documents.

```shell
npm run dev
```

### Process Your First Documents

Add some PDF files to the `docs/pdfs/` folder, then start the ingestion pipeline:

```shell
curl -X POST http://localhost:3000/api/rag/process-pdfs \
  -H "Content-Type: application/json" \
  -d '{"folderPath":"docs/pdfs"}'
```

Watch the logs as your documents are processed through the pipeline:
1. **PDF Reading**: Files are discovered and queued
2. **Docling Processing**: Intelligent chunking with structure preservation  
3. **Weaviate Loading**: Chunks are embedded and stored

### Query Your Knowledge Base

Once processing is complete, you can ask questions about your documents:

#### General Query
```shell
curl -X POST http://localhost:3000/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What are the main topics covered in these documents?","limit":3}'
```

#### Specific Question
```shell
curl -X POST http://localhost:3000/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What methodology was used in the research?","limit":5}'
```

The response includes both a generated answer and the source chunks with page numbers for verification.

</Steps>

---

## Advanced Usage

### Custom Chunking Strategies

Modify the Python processing step to implement custom chunking logic:

```python
# In process-pdfs.step.py
chunker = HybridChunker(
    tokenizer="cl100k_base",
    max_tokens=1024,  # Larger chunks for more context
    overlap_tokens=100,  # More overlap for better continuity
    heading_hierarchies=True,
    split_by_page=True  # Preserve page boundaries
)
```

### Batch Processing Optimization

Adjust batch sizes in the Weaviate loading step for optimal performance:

```ts
// In load-weaviate.step.ts
const BATCH_SIZE = 50  // Smaller batches for large documents
```

### Multi-Collection Support

Extend the system to handle different document types by creating separate Weaviate collections:

```ts
const COLLECTIONS = {
  research: 'ResearchPapers',
  manuals: 'TechnicalManuals', 
  reports: 'BusinessReports'
}
```

---

## Troubleshooting

### Common Issues

**ENOENT Path Errors**: The system automatically handles path normalization, but ensure your `folderPath` is relative to the project root.

**Empty Answers**: Check that documents were successfully processed by examining the logs. Verify your OpenAI API key is valid.

**Weaviate Connection Issues**: Ensure your `WEAVIATE_URL` and `WEAVIATE_API_KEY` are correct and your cluster is running.

### Performance Tips

- **Document Size**: For large PDFs, consider preprocessing to split them into smaller files
- **Batch Size**: Adjust the Weaviate batch size based on your cluster's capacity
- **Chunking Strategy**: Experiment with different chunk sizes and overlap for your specific use case

---

## ðŸ’» Dive into the Code

Want to explore the complete RAG implementation? Check out the full source code, including all steps, configuration files, and setup instructions:

<div className="not-prose">
  <div className="bg-gradient-to-r from-purple-50 to-pink-50 border border-purple-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-purple-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete RAG Implementation</h3>
        <p className="text-gray-600 mb-4">Access the full source code for this RAG agent, including Python processing scripts, TypeScript orchestration, and production configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View RAG Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Future of Document Intelligence

This RAG system demonstrates the power of combining best-in-class technologies with Motia's event-driven architecture. By breaking down complex document processing into discrete, manageable steps, we've created a system that's not only powerful but also maintainable and scalable.

The polyglot nature of the solution: Python for document processing, TypeScript for orchestration, shows how Motia enables you to use the right tool for each job without sacrificing integration or maintainability.

From here, you can extend the system by:
- Adding support for other document formats (Word, PowerPoint, etc.)
- Implementing document classification and routing
- Adding real-time document updates and synchronization
- Building a web interface for document management
- Integrating with existing business systems

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing pipeline.

Ready to transform your documents into intelligent, queryable knowledge bases? Start building with Motia today!


-   [sentiment-analysis](/docs/examples/sentiment-analysis): Documentation for sentiment-analysis.
---
title: 'Sentiment Analysis'
description: 'Dynamic Workflows: Building a Sentiment Analyzer with Motia'
---

In modern application development, workflows are rarely linear. Whether you're building a simple "prompt => response" system or a complex, multi-stage data processing pipeline, you often need your application to make decisions and route data dynamically. This is where the power of event-driven architecture shines, and where the Motia framework provides a clear path forward.

---

## Explore the Workbench

<div className="my-8">![motia workbench for sentiment analysis](./../img/sentimental-analyzer-workbench.gif)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/sentimental-analysis)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

This guide explores how to build a dynamic sentiment analysis application that uses an LLM to determine how to proceed. We'll cover:

1.  **The Motia Philosophy**: How `steps` as a core primitive simplify complex architectures.
2.  **Building the Workflow**: A step-by-step guide to creating the four key components of our application.
3.  **Visualizing the Flow**: How events chain together to create a cohesive, dynamic system.
4.  **Hands-On with the API**: How to run and test your new sentiment analyzer.

Let's dive in.

---

## A Step at a Time

<div className="my-8">![motia workbench for sentiment analysis](./../img/sentimental-analyzer-workbench.png)</div>

At the heart of the Motia framework is a simple but powerful idea: the **`step`**. A step is a self-contained, independent unit of logic that listens for an event, performs a task, and, optionally, emits a new event. This concept is the core primitive that allows you to break down even the most complex architectures into a series of simple, manageable components.

Instead of a monolithic application where business logic is tightly coupled, Motia encourages a decoupled, event-driven approach. This has several key advantages:

-   **Clarity**: Each step has a single responsibility, making the application easier to understand and reason about.
-   **Scalability**: Steps can be scaled independently, so you can allocate resources where they're needed most.
-   **Extensibility**: Adding new functionality is as simple as creating a new step and subscribing it to an existing event.
-   **Resilience**: The decoupled nature of steps means that a failure in one part of the system doesn't necessarily bring down the entire application.

In this project, we'll see this philosophy in action as we build a sentiment analyzer with four distinct steps, each with its own clear purpose.

---

## The Anatomy of Our Sentiment Analyzer

Our application will be composed of four steps. Let's explore each one.

<Folder name="steps" defaultOpen>
  <File name="analyzeSentimentApi.step.ts" />
  <File name="openAiAnalyzeSentiment.step.ts" />
  <File name="handlePositive.step.ts" />
  <File name="handleNegative.step.ts" />
</Folder>

<Tabs items={['analyzeSentimentApi', 'openAiAnalyzeSentiment', 'handlePositive', 'handleNegative']}>
  <Tab value="analyzeSentimentApi">
    This is the entry point to our workflow. It's an API step that listens for `POST` requests, validates the incoming data, and emits an `openai.analyzeSentimentRequest` event.

    ```ts
    // Receives user text, emits "openai.analyzeSentimentRequest".
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'api',
      name: 'analyzeSentimentApi',
      description: 'Receives user text and emits an event to trigger sentiment analysis.',
      path: '/api/analyze-sentiment',
      method: 'POST',
      emits: ['openai.analyzeSentimentRequest'],
      bodySchema: z.object({
        text: z.string().min(1, 'text is required'),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['analyzeSentimentApi'] = async (req, { emit, logger }) => {
      const { text } = req.body

      logger.info('[AnalyzeSentimentAPI] Received text', { text })

      // Emit an event to call OpenAI
      await emit({
        topic: 'openai.analyzeSentimentRequest',
        data: { text },
      })

      // Return right away
      return {
        status: 200,
        body: { status: 'Accepted', message: 'Your text is being analyzed' },
      }
    }
    ```

  </Tab>
  <Tab value="openAiAnalyzeSentiment">
    This step is the brains of our operation. It subscribes to the `openai.analyzeSentimentRequest` event, calls the OpenAI API, and then based on the response, emits either a `openai.positiveSentiment` or `openai.negativeSentiment` event. This is where the dynamic routing happens.

    ```ts
    // Calls OpenAI, instructing it to ONLY return JSON like {"sentiment":"positive","analysis":"..."}
    import { Handlers } from 'motia'
    import { z } from 'zod'
    import { OpenAI } from 'openai'

    // 1) Create an OpenAI client (newer syntax)
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

    export const config = {
      type: 'event',
      name: 'openAiSentimentAnalyzer',
      description: 'Calls OpenAI to analyze sentiment and emits corresponding events.',
      subscribes: ['openai.analyzeSentimentRequest'],
      // We'll emit different events: "openai.positiveSentiment" or "openai.negativeSentiment"
      emits: ['openai.positiveSentiment', 'openai.negativeSentiment'],
      input: z.object({ text: z.string() }),
      flows: ['sentiment-demo'],
    } as const

    // 3) Provide the code that runs on each event
    export const handler: Handlers['openAiSentimentAnalyzer'] = async (input, { emit, logger }) => {
      logger.info('[OpenAI Sentiment Analyzer] Prompting OpenAI...', { text: input.text })

      try {
        // We'll ask the model to ONLY return JSON with a "sentiment" field
        const systemPrompt =
          'You are an assistant that returns only JSON: {"sentiment":"positive|negative","analysis":"..."}'
        const userPrompt = `Analyze the sentiment of this text: "${input.text}". Return JSON with keys "sentiment" and "analysis".`

        // 4) Use the new openai syntax:
        const response = await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt },
          ],
        })

        // 5) Log and parse the response
        const content = response.choices[0]?.message?.content || ''
        logger.info('[OpenAI Sentiment Analyzer] Raw response', { content })

        let parsed: { sentiment?: string; analysis?: string } = {}
        try {
          parsed = JSON.parse(content.trim())
        } catch (err) {
          logger.error('[OpenAI Sentiment Analyzer] Unable to parse JSON', { error: err })
          // If it's not JSON, we bail or handle differently
          return
        }

        // 6) Decide how to route the event
        if (parsed.sentiment) {
          if (parsed.sentiment.toLowerCase() === 'positive') {
            await emit({
              topic: 'openai.positiveSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          } else {
            // default to negative
            await emit({
              topic: 'openai.negativeSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          }
        } else {
          logger.error('[OpenAI Sentiment Analyzer] Sentiment is missing from the parsed response', { parsed })
        }
      } catch (err) {
        if (err instanceof Error) {
          logger.error('[OpenAI Sentiment Analyzer] Error calling OpenAI', { error: err.message })
        } else {
          logger.error('[OpenAI Sentiment Analyzer] An unknown error occurred while calling OpenAI', { error: err })
        }
      }
    }
    ```
  </Tab>
  <Tab value="handlePositive">
    A specialized responder that listens for the `openai.positiveSentiment` event and logs a confirmation message. In a real-world application, this could trigger a Slack notification, send an email, or kick off another workflow.

    ```ts
    // Handles "openai.positiveSentiment"
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'handlePositive',
      description: 'Handles positive sentiment responses.',
      subscribes: ['openai.positiveSentiment'],
      emits: [],
      input: z.object({
        sentiment: z.string(),
        analysis: z.string().optional(),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['handlePositive'] = async (input, { logger }) => {
      logger.info('[Positive Responder] The sentiment is positive!', { analysis: input.analysis })
      // Maybe notify a Slack channel: "All good vibes here!"
    }
    ```

  </Tab>
  <Tab value="handleNegative">
    Similar to the positive handler, this step listens for the `openai.negativeSentiment` event. This is where you could implement logic to escalate a customer complaint, create a support ticket, or alert the on-call team.

    ```ts
    // Handles "openai.negativeSentiment"
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'handleNegative',
      description: 'Handles negative or unknown sentiment responses.',
      subscribes: ['openai.negativeSentiment'],
      emits: [],
      input: z.object({
        sentiment: z.string(),
        analysis: z.string().optional(),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['handleNegative'] = async (input, { logger }) => {
      logger.info('[Negative Responder] The sentiment is negative or unknown.', { analysis: input.analysis })
      // Could escalate to a service, or respond gently, etc.
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

You can explore the workflow in the Workbench.

<div className="my-8">![Flow](./../img/sentimental-analyzer.png)</div>

You can also read your files and watch logs, traces, debug your architecture directly in the Workbench.

<div className="my-8">![Workbench](./../img/sentimental-analyzer-workbench.gif)</div>

---

## Trying It Out

Ready to see it in action? Let's get the project running.

<Steps>

### Install Dependencies

First, install the necessary npm packages.

```shell
npm install
```

### Set Your Environment Variables

You'll need an OpenAI API key for this project. Export it as an environment variable.

```shell
export OPENAI_API_KEY="sk-..."
```

### Run the Project

Start the Motia development server.

```shell
npm run dev
```

### Test the API

Now you can send requests to your API and see the workflow in action.

#### Positive Sentiment

```shell
curl -X POST http://localhost:3000/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"I absolutely love this new device! It is amazing and works perfectly."}'
```

Check your logs, and you should see the `[Positive Responder]` has been triggered.

#### Negative Sentiment

```shell
curl -X POST http://localhost:3000/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"This is the worst product I have ever used. It broke after one day."}'
```

This time, the `[Negative Responder]` will fire.

</Steps>

---

## ðŸ’» Dive into the Code

Want to explore the complete implementation? Check out the full source code and additional examples in our GitHub repository:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Explore More Examples</h3>
        <p className="text-gray-600 mb-4">Get hands-on with the complete source code, configuration files, and additional examples to accelerate your learning.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/sentimental-analysis" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Sentiment Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of a Simple Primitive

This sentiment analysis application is a powerful demonstration of the Motia philosophy. By embracing the `step` as a core primitive, we've turned a potentially complex, branching workflow into a series of simple, understandable, and scalable components.

This is just the beginning. From here, you can extend the application by adding new steps to handle neutral sentiment, send notifications, or store results in a database. The event-driven architecture of Motia makes it easy to add new functionality without disrupting the existing flow.

We encourage you to explore, experiment, and see for yourself how Motia can simplify your most complex backend challenges. Happy coding!


## Examples
[sentiment-analysis](/docs/examples/sentiment-analysis): Code example
---
title: 'Sentiment Analysis'
description: 'Dynamic Workflows: Building a Sentiment Analyzer with Motia'
---

In modern application development, workflows are rarely linear. Whether you're building a simple "prompt => response" system or a complex, multi-stage data processing pipeline, you often need your application to make decisions and route data dynamically. This is where the power of event-driven architecture shines, and where the Motia framework provides a clear path forward.

---

## Explore the Workbench

<div className="my-8">![motia workbench for sentiment analysis](./../img/sentimental-analyzer-workbench.gif)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/sentimental-analysis)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

This guide explores how to build a dynamic sentiment analysis application that uses an LLM to determine how to proceed. We'll cover:

1.  **The Motia Philosophy**: How `steps` as a core primitive simplify complex architectures.
2.  **Building the Workflow**: A step-by-step guide to creating the four key components of our application.
3.  **Visualizing the Flow**: How events chain together to create a cohesive, dynamic system.
4.  **Hands-On with the API**: How to run and test your new sentiment analyzer.

Let's dive in.

---

## A Step at a Time

<div className="my-8">![motia workbench for sentiment analysis](./../img/sentimental-analyzer-workbench.png)</div>

At the heart of the Motia framework is a simple but powerful idea: the **`step`**. A step is a self-contained, independent unit of logic that listens for an event, performs a task, and, optionally, emits a new event. This concept is the core primitive that allows you to break down even the most complex architectures into a series of simple, manageable components.

Instead of a monolithic application where business logic is tightly coupled, Motia encourages a decoupled, event-driven approach. This has several key advantages:

-   **Clarity**: Each step has a single responsibility, making the application easier to understand and reason about.
-   **Scalability**: Steps can be scaled independently, so you can allocate resources where they're needed most.
-   **Extensibility**: Adding new functionality is as simple as creating a new step and subscribing it to an existing event.
-   **Resilience**: The decoupled nature of steps means that a failure in one part of the system doesn't necessarily bring down the entire application.

In this project, we'll see this philosophy in action as we build a sentiment analyzer with four distinct steps, each with its own clear purpose.

---

## The Anatomy of Our Sentiment Analyzer

Our application will be composed of four steps. Let's explore each one.

<Folder name="steps" defaultOpen>
  <File name="analyzeSentimentApi.step.ts" />
  <File name="openAiAnalyzeSentiment.step.ts" />
  <File name="handlePositive.step.ts" />
  <File name="handleNegative.step.ts" />
</Folder>

<Tabs items={['analyzeSentimentApi', 'openAiAnalyzeSentiment', 'handlePositive', 'handleNegative']}>
  <Tab value="analyzeSentimentApi">
    This is the entry point to our workflow. It's an API step that listens for `POST` requests, validates the incoming data, and emits an `openai.analyzeSentimentRequest` event.

    ```ts
    // Receives user text, emits "openai.analyzeSentimentRequest".
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'api',
      name: 'analyzeSentimentApi',
      description: 'Receives user text and emits an event to trigger sentiment analysis.',
      path: '/api/analyze-sentiment',
      method: 'POST',
      emits: ['openai.analyzeSentimentRequest'],
      bodySchema: z.object({
        text: z.string().min(1, 'text is required'),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['analyzeSentimentApi'] = async (req, { emit, logger }) => {
      const { text } = req.body

      logger.info('[AnalyzeSentimentAPI] Received text', { text })

      // Emit an event to call OpenAI
      await emit({
        topic: 'openai.analyzeSentimentRequest',
        data: { text },
      })

      // Return right away
      return {
        status: 200,
        body: { status: 'Accepted', message: 'Your text is being analyzed' },
      }
    }
    ```

  </Tab>
  <Tab value="openAiAnalyzeSentiment">
    This step is the brains of our operation. It subscribes to the `openai.analyzeSentimentRequest` event, calls the OpenAI API, and then based on the response, emits either a `openai.positiveSentiment` or `openai.negativeSentiment` event. This is where the dynamic routing happens.

    ```ts
    // Calls OpenAI, instructing it to ONLY return JSON like {"sentiment":"positive","analysis":"..."}
    import { Handlers } from 'motia'
    import { z } from 'zod'
    import { OpenAI } from 'openai'

    // 1) Create an OpenAI client (newer syntax)
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

    export const config = {
      type: 'event',
      name: 'openAiSentimentAnalyzer',
      description: 'Calls OpenAI to analyze sentiment and emits corresponding events.',
      subscribes: ['openai.analyzeSentimentRequest'],
      // We'll emit different events: "openai.positiveSentiment" or "openai.negativeSentiment"
      emits: ['openai.positiveSentiment', 'openai.negativeSentiment'],
      input: z.object({ text: z.string() }),
      flows: ['sentiment-demo'],
    } as const

    // 3) Provide the code that runs on each event
    export const handler: Handlers['openAiSentimentAnalyzer'] = async (input, { emit, logger }) => {
      logger.info('[OpenAI Sentiment Analyzer] Prompting OpenAI...', { text: input.text })

      try {
        // We'll ask the model to ONLY return JSON with a "sentiment" field
        const systemPrompt =
          'You are an assistant that returns only JSON: {"sentiment":"positive|negative","analysis":"..."}'
        const userPrompt = `Analyze the sentiment of this text: "${input.text}". Return JSON with keys "sentiment" and "analysis".`

        // 4) Use the new openai syntax:
        const response = await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt },
          ],
        })

        // 5) Log and parse the response
        const content = response.choices[0]?.message?.content || ''
        logger.info('[OpenAI Sentiment Analyzer] Raw response', { content })

        let parsed: { sentiment?: string; analysis?: string } = {}
        try {
          parsed = JSON.parse(content.trim())
        } catch (err) {
          logger.error('[OpenAI Sentiment Analyzer] Unable to parse JSON', { error: err })
          // If it's not JSON, we bail or handle differently
          return
        }

        // 6) Decide how to route the event
        if (parsed.sentiment) {
          if (parsed.sentiment.toLowerCase() === 'positive') {
            await emit({
              topic: 'openai.positiveSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          } else {
            // default to negative
            await emit({
              topic: 'openai.negativeSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          }
        } else {
          logger.error('[OpenAI Sentiment Analyzer] Sentiment is missing from the parsed response', { parsed })
        }
      } catch (err) {
        if (err instanceof Error) {
          logger.error('[OpenAI Sentiment Analyzer] Error calling OpenAI', { error: err.message })
        } else {
          logger.error('[OpenAI Sentiment Analyzer] An unknown error occurred while calling OpenAI', { error: err })
        }
      }
    }
    ```
  </Tab>
  <Tab value="handlePositive">
    A specialized responder that listens for the `openai.positiveSentiment` event and logs a confirmation message. In a real-world application, this could trigger a Slack notification, send an email, or kick off another workflow.

    ```ts
    // Handles "openai.positiveSentiment"
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'handlePositive',
      description: 'Handles positive sentiment responses.',
      subscribes: ['openai.positiveSentiment'],
      emits: [],
      input: z.object({
        sentiment: z.string(),
        analysis: z.string().optional(),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['handlePositive'] = async (input, { logger }) => {
      logger.info('[Positive Responder] The sentiment is positive!', { analysis: input.analysis })
      // Maybe notify a Slack channel: "All good vibes here!"
    }
    ```

  </Tab>
  <Tab value="handleNegative">
    Similar to the positive handler, this step listens for the `openai.negativeSentiment` event. This is where you could implement logic to escalate a customer complaint, create a support ticket, or alert the on-call team.

    ```ts
    // Handles "openai.negativeSentiment"
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'handleNegative',
      description: 'Handles negative or unknown sentiment responses.',
      subscribes: ['openai.negativeSentiment'],
      emits: [],
      input: z.object({
        sentiment: z.string(),
        analysis: z.string().optional(),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['handleNegative'] = async (input, { logger }) => {
      logger.info('[Negative Responder] The sentiment is negative or unknown.', { analysis: input.analysis })
      // Could escalate to a service, or respond gently, etc.
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

You can explore the workflow in the Workbench.

<div className="my-8">![Flow](./../img/sentimental-analyzer.png)</div>

You can also read your files and watch logs, traces, debug your architecture directly in the Workbench.

<div className="my-8">![Workbench](./../img/sentimental-analyzer-workbench.gif)</div>

---

## Trying It Out

Ready to see it in action? Let's get the project running.

<Steps>

### Install Dependencies

First, install the necessary npm packages.

```shell
npm install
```

### Set Your Environment Variables

You'll need an OpenAI API key for this project. Export it as an environment variable.

```shell
export OPENAI_API_KEY="sk-..."
```

### Run the Project

Start the Motia development server.

```shell
npm run dev
```

### Test the API

Now you can send requests to your API and see the workflow in action.

#### Positive Sentiment

```shell
curl -X POST http://localhost:3000/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"I absolutely love this new device! It is amazing and works perfectly."}'
```

Check your logs, and you should see the `[Positive Responder]` has been triggered.

#### Negative Sentiment

```shell
curl -X POST http://localhost:3000/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"This is the worst product I have ever used. It broke after one day."}'
```

This time, the `[Negative Responder]` will fire.

</Steps>

---

## ðŸ’» Dive into the Code

Want to explore the complete implementation? Check out the full source code and additional examples in our GitHub repository:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Explore More Examples</h3>
        <p className="text-gray-600 mb-4">Get hands-on with the complete source code, configuration files, and additional examples to accelerate your learning.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/sentimental-analysis" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Sentiment Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of a Simple Primitive

This sentiment analysis application is a powerful demonstration of the Motia philosophy. By embracing the `step` as a core primitive, we've turned a potentially complex, branching workflow into a series of simple, understandable, and scalable components.

This is just the beginning. From here, you can extend the application by adding new steps to handle neutral sentiment, send notifications, or store results in a database. The event-driven architecture of Motia makes it easy to add new functionality without disrupting the existing flow.

We encourage you to explore, experiment, and see for yourself how Motia can simplify your most complex backend challenges. Happy coding!

-   [trello-automation](/docs/examples/trello-automation): Documentation for trello-automation.
---
title: 'Trello Automation'
description: Build an automated card progression system for Trello boards with AI-powered summaries
---

import { TrelloTab, TrelloCodeContent } from '../../../components/TrelloCodeFetcher'

---

## Explore the Workbench

<div className="my-8">![Trello Automation](./../img/trello.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/trello-flow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a Trello automation system that:

1. Automatically progresses cards across board lists
2. Validates card completeness
3. Generates AI-powered summaries for code review
4. Integrates with Slack for notifications
5. Monitors due dates and sends overdue alerts

## Board Structure

The Trello board is organized into four main lists:

- **New Cards**: Entry point for all new cards
- **In Progress**: Active development stage
- **Needs Review**: Code review stage with AI summaries
- **Completed**: Successfully reviewed and approved cards

## The Steps

<Folder name="steps" defaultOpen>
  <File name="trello-webhook.step.ts" />
  <File name="trello-webhook-validation.step.ts" />
  <File name="validate-card-requirements.step.ts" />
  <File name="start-assigned-card.step.ts" />
  <File name="mark-card-for-review.step.ts" />
  <File name="complete-approved-card.step.ts" />
  <File name="check-overdue-cards.step.ts" />
  <File name="slack-notifier.step.ts" />
</Folder>

<Tabs items={['webhook', 'validation', 'requirements', 'assigned', 'review', 'completion', 'overdue', 'slack']}>
  <TrelloTab tab="webhook" value="trello-webhook" />
  <TrelloTab tab="validation" value="trello-webhook-validation" />
  <TrelloTab tab="requirements" value="validate-card-requirements" />
  <TrelloTab tab="assigned" value="start-assigned-card" />
  <TrelloTab tab="review" value="mark-card-for-review" />
  <TrelloTab tab="completion" value="complete-approved-card" />
  <TrelloTab tab="overdue" value="check-overdue-cards" />
  <TrelloTab tab="slack" value="slack-notifier" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Trello Automation Steps](./../img/trello.png)</div>

1. **Card Validation** â†’ Checks for required information
2. **Progress Tracking** â†’ Moves cards between lists
3. **Review Process** â†’ Generates AI summaries and notifies reviewers
4. **Completion Handling** â†’ Processes approved cards

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- Trello account with API access
- Node.js installed
- Slack workspace (for notifications)
- OpenAI API key (for AI summaries)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/trello-flow
```

### Install Dependencies

```bash
pnpm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
TRELLO_API_KEY=your_trello_api_key
TRELLO_TOKEN=your_trello_token

OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=your_openai_model

SLACK_WEBHOOK_URL=your_slack_webhook_url

TRELLO_NEW_TASKS_LIST_ID=your_new_tasks_list_id
TRELLO_IN_PROGRESS_LIST_ID=your_in_progress_list_id
TRELLO_NEEDS_REVIEW_LIST_ID=your_needs_review_list_id
TRELLO_COMPLETED_LIST_ID=your_completed_list_id
```

### Set Up Trello Board

1. Create a new Trello board with these lists:

   - New Tasks
   - In Progress
   - Needs Review
   - Completed

2. Add a custom field:
   - Status (dropdown: Todo, In Progress, Done)

### Run the Application

```bash
pnpm dev
```

### Test the Flow

1. Create a new card in the "New Tasks" list
2. Assign a member to see it move to "In Progress"
3. Add an "approved" comment to see it move to "Completed"
4. Check Slack for notifications

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/trello-flow).
</Callout>{' '}



## Examples
[trello-automation](/docs/examples/trello-automation): Code example
---
title: 'Trello Automation'
description: Build an automated card progression system for Trello boards with AI-powered summaries
---

import { TrelloTab, TrelloCodeContent } from '../../../components/TrelloCodeFetcher'

---

## Explore the Workbench

<div className="my-8">![Trello Automation](./../img/trello.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/trello-flow)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## Let's build a Trello automation system that:

1. Automatically progresses cards across board lists
2. Validates card completeness
3. Generates AI-powered summaries for code review
4. Integrates with Slack for notifications
5. Monitors due dates and sends overdue alerts

## Board Structure

The Trello board is organized into four main lists:

- **New Cards**: Entry point for all new cards
- **In Progress**: Active development stage
- **Needs Review**: Code review stage with AI summaries
- **Completed**: Successfully reviewed and approved cards

## The Steps

<Folder name="steps" defaultOpen>
  <File name="trello-webhook.step.ts" />
  <File name="trello-webhook-validation.step.ts" />
  <File name="validate-card-requirements.step.ts" />
  <File name="start-assigned-card.step.ts" />
  <File name="mark-card-for-review.step.ts" />
  <File name="complete-approved-card.step.ts" />
  <File name="check-overdue-cards.step.ts" />
  <File name="slack-notifier.step.ts" />
</Folder>

<Tabs items={['webhook', 'validation', 'requirements', 'assigned', 'review', 'completion', 'overdue', 'slack']}>
  <TrelloTab tab="webhook" value="trello-webhook" />
  <TrelloTab tab="validation" value="trello-webhook-validation" />
  <TrelloTab tab="requirements" value="validate-card-requirements" />
  <TrelloTab tab="assigned" value="start-assigned-card" />
  <TrelloTab tab="review" value="mark-card-for-review" />
  <TrelloTab tab="completion" value="complete-approved-card" />
  <TrelloTab tab="overdue" value="check-overdue-cards" />
  <TrelloTab tab="slack" value="slack-notifier" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Trello Automation Steps](./../img/trello.png)</div>

1. **Card Validation** â†’ Checks for required information
2. **Progress Tracking** â†’ Moves cards between lists
3. **Review Process** â†’ Generates AI summaries and notifies reviewers
4. **Completion Handling** â†’ Processes approved cards

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- Trello account with API access
- Node.js installed
- Slack workspace (for notifications)
- OpenAI API key (for AI summaries)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/trello-flow
```

### Install Dependencies

```bash
pnpm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
TRELLO_API_KEY=your_trello_api_key
TRELLO_TOKEN=your_trello_token

OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=your_openai_model

SLACK_WEBHOOK_URL=your_slack_webhook_url

TRELLO_NEW_TASKS_LIST_ID=your_new_tasks_list_id
TRELLO_IN_PROGRESS_LIST_ID=your_in_progress_list_id
TRELLO_NEEDS_REVIEW_LIST_ID=your_needs_review_list_id
TRELLO_COMPLETED_LIST_ID=your_completed_list_id
```

### Set Up Trello Board

1. Create a new Trello board with these lists:

   - New Tasks
   - In Progress
   - Needs Review
   - Completed

2. Add a custom field:
   - Status (dropdown: Todo, In Progress, Done)

### Run the Application

```bash
pnpm dev
```

### Test the Flow

1. Create a new card in the "New Tasks" list
2. Assign a member to see it move to "In Progress"
3. Add an "approved" comment to see it move to "Completed"
4. Check Slack for notifications

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/trello-flow).
</Callout>{' '}


-   [uptime-discord-monitor](/docs/examples/uptime-discord-monitor): Documentation for uptime-discord-monitor.
---
title: 'Uptime Monitor'
description: 'Real-Time Uptime Monitoring: Building a Resilient Website Monitor with Motia'
---

In today's modern era, website uptime is critical for business success. Whether you're monitoring a personal blog or enterprise applications, you need a reliable system that can detect outages, send alerts, and provide visibility into your site's health. Traditional monitoring solutions often involve complex infrastructure and vendor lock-in, but there's a better way.

This comprehensive guide explores how to build a production-ready uptime monitoring system using Motia's event-driven architecture. We'll cover:

1.  **Event-Driven Monitoring**: How Motia's `steps` create a scalable, maintainable monitoring pipeline.
2.  **Building the Architecture**: A detailed walkthrough of our five-component monitoring system.
3.  **Smart Alerting**: Implementing rate limiting and status change detection to prevent spam.

Let's build a monitoring system that actually works for you.

---

## Explore the Workbench

<div className="my-8">![Uptime Monitor](./../img/uptime-monitor-architecture.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-uptime-monitor)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Event-Driven Monitoring

<div className="my-8">![Uptime Monitor Architecture](./../img/uptime-monitor.gif)</div>

At its core, our uptime monitoring system solves a fundamental challenge: how do you continuously monitor multiple websites without creating a brittle, monolithic application? Traditional monitoring tools often suffer from tight coupling, making them difficult to scale and customize. Our Motia-powered solution breaks this down into discrete, event-driven components that each handle a specific aspect of monitoring.

The magic happens through the integration of proven technologies and patterns:

-   **[Cron-Based Scheduling](https://en.wikipedia.org/wiki/Cron)**: Configurable check intervals using familiar cron expressions
-   **[Discord Webhooks](https://discord.com/developers/docs/resources/webhook)**: Instant notifications with rich formatting
-   **[Token Bucket Rate Limiting](https://en.wikipedia.org/wiki/Token_bucket)**: Intelligent alert throttling to prevent spam
-   **[Motia Framework](https://motia.dev)**: Event-driven orchestration with built-in observability

Instead of a monolithic monitoring daemon, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our Monitoring System

Our application consists of five specialized steps, each handling a specific part of the monitoring workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="cron.step.js" />
  <File name="checker.step.js" />
  <File name="alerter.step.js" />
  <File name="health.step.js" />
</Folder>

<Folder name="lib" defaultOpen>
  <File name="env.js" />
  <File name="rate-limiter.js" />
  <File name="streams.js" />
</Folder>

<Tabs items={['cron', 'checker', 'alerter', 'health', 'utilities']}>
  <Tab value="cron">
    The heartbeat of our monitoring system. This cron-triggered step periodically emits check requests for all configured websites, acting as the central scheduler.

    ```js
    import { config as envConfig } from '../lib/env.js';

    export const config = {
      type: 'cron',
      name: 'UptimeCronTrigger',
      cron: envConfig.cron,
      emits: ['check.requested'],
      flows: ['uptime-monitoring']
    };

    export async function handler(context) {
      context.logger.info(`Starting uptime checks for ${envConfig.sites.length} sites`);
      context.logger.info(`Sites configured: ${JSON.stringify(envConfig.sites)}`);

      try {
        // Emit one check.requested event per configured site URL
        for (const url of envConfig.sites) {
          context.logger.info(`Scheduling check for: ${url}`);
          
          await context.emit({ 
            topic: 'check.requested', 
            data: { url: url } 
          });
          
          context.logger.info(`Successfully emitted for: ${url}`);
        }

        context.logger.info(`Successfully scheduled checks for all ${envConfig.sites.length} sites`);
      } catch (error) {
        context.logger.error('Error during cron execution:', error);
        throw error;
      }
    }
    ```

  </Tab>
  <Tab value="checker">
    The core monitoring component that performs HTTP checks on websites. It handles timeouts, errors, and response code analysis, then emits results for further processing.

    ```js
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'WebsiteChecker',
      description: 'Performs HTTP checks on websites and emits results',
      subscribes: ['check.requested'],
      emits: ['check.result', 'status.stream'],
      input: z.object({
        url: z.string().url('Must be a valid URL')
      }),
      flows: ['uptime-monitoring'],
    }

    export const handler = async (input, { logger, emit }) => {
      const { url } = input
      
      logger.info('Starting website check', { url })

      const startTime = performance.now()
      let result

      try {
        // Validate URL format before making request
        const urlObj = new URL(url)
        if (!['http:', 'https:'].includes(urlObj.protocol)) {
          throw new Error('Only HTTP and HTTPS protocols are supported')
        }

        // Perform HTTP request with timeout handling
        const controller = new AbortController()
        const timeoutId = setTimeout(() => controller.abort(), 10000) // 10 second timeout

        const response = await fetch(url, {
          method: 'GET',
          signal: controller.signal,
          headers: {
            'User-Agent': 'Motia-Uptime-Monitor/1.0',
            'Accept': '*/*',
            'Cache-Control': 'no-cache'
          },
          redirect: 'manual'
        })

        clearTimeout(timeoutId)
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        // Determine status: 2xx and 3xx as UP, everything else as DOWN
        const status = (response.status >= 200 && response.status < 400) ? 'UP' : 'DOWN'

        result = {
          url,
          status,
          code: response.status,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: null
        }

        logger.info('Website check completed', {
          url,
          status,
          code: response.status,
          responseTime
        })

      } catch (error) {
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        let errorMessage = error.message

        // Handle specific error types with detailed messages
        if (error.name === 'AbortError') {
          errorMessage = 'Request timeout (10s)'
        } else if (error.name === 'TypeError' && error.message.includes('fetch')) {
          errorMessage = 'Network error - unable to connect'
        } else if (error.code === 'ENOTFOUND') {
          errorMessage = 'DNS resolution failed'
        } else if (error.code === 'ECONNREFUSED') {
          errorMessage = 'Connection refused'
        }

        result = {
          url,
          status: 'DOWN',
          code: null,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: errorMessage
        }

        logger.error('Website check failed', {
          url,
          error: errorMessage,
          responseTime,
          originalError: error.code || error.name
        })
      }

      // Emit results to both alerter and dashboard
      await emit({ topic: 'check.result', data: result })
      await emit({ topic: 'status.stream', data: result })

      logger.info('Check results emitted successfully', { url, status: result.status })
    }
    ```

  </Tab>
  <Tab value="alerter">
    The intelligent alerting system that detects status changes, applies rate limiting, and sends Discord notifications. Only triggers alerts when status actually changes, preventing noise.

    ```js
    import { z } from 'zod'
    import { getPreviousStatus } from '../lib/streams.js'
    import { createRateLimiter } from '../lib/rate-limiter.js'
    import { config as envConfig } from '../lib/env.js'

    // Create a rate limiter instance for Discord alerts
    const rateLimiter = createRateLimiter({
      burst: envConfig.alertBurst,
      windowSec: envConfig.alertWindowSec
    })

    export const config = {
      type: 'event',
      name: 'DiscordAlerter',
      description: 'Sends Discord notifications when website status changes',
      subscribes: ['check.result'],
      emits: [],
      input: z.object({
        url: z.string().url(),
        status: z.enum(['UP', 'DOWN']),
        code: z.number().nullable(),
        responseTime: z.number(),
        checkedAt: z.string(),
        error: z.string().nullable()
      }),
      flows: ['uptime-monitoring'],
    }

    function createDiscordMessage(result, previousStatus) {
      const { url, status, code, responseTime, checkedAt, error } = result

      const isUp = status === 'UP'
      const emoji = isUp ? 'ðŸŸ¢' : 'ðŸ”´'
      const color = isUp ? 0x00ff00 : 0xff0000

      const content = `${emoji} ${url} is ${status}${code ? ` (${code})` : ''}`

      const fields = [
        {
          name: 'Response Time',
          value: `${responseTime}ms`,
          inline: true
        }
      ]

      if (code !== null) {
        fields.push({
          name: 'Status Code',
          value: code.toString(),
          inline: true
        })
      }

      if (error) {
        fields.push({
          name: 'Error',
          value: error,
          inline: false
        })
      }

      fields.push({
        name: 'Previous Status',
        value: previousStatus,
        inline: true
      })

      return {
        content,
        embeds: [{
          title: `Website Status Change: ${status}`,
          description: `${url} changed from ${previousStatus} to ${status}`,
          color,
          timestamp: checkedAt,
          fields
        }]
      }
    }

    export const handler = async (input, { logger }) => {
      const { url, status } = input

      // Get the previous status for comparison
      const previousResult = getPreviousStatus(url)

      // Handle first-time checks
      if (!previousResult) {
        logger.info('First-time check for site, no alert needed', { url, status })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      const previousStatus = previousResult.status

      // Only trigger alerts when status actually changes
      if (status === previousStatus) {
        logger.debug('Status unchanged, no alert needed', { url, status, previousStatus })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      // Status has changed - check rate limiting
      logger.info('Status change detected', {
        url,
        previousStatus,
        newStatus: status,
        transition: `${previousStatus} â†’ ${status}`
      })

      if (!rateLimiter.consume(url)) {
        const timeUntilNext = rateLimiter.getTimeUntilNextToken(url)
        logger.warn('Alert rate limited', {
          url,
          status,
          previousStatus,
          timeUntilNextMs: timeUntilNext,
          tokensRemaining: rateLimiter.getTokenCount(url)
        })
        return
      }

      // Send Discord notification
      const message = createDiscordMessage(input, previousStatus)
      
      try {
        const response = await fetch(envConfig.discordWebhook, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'User-Agent': 'Motia-Uptime-Monitor/1.0'
          },
          body: JSON.stringify(message)
        })

        if (response.ok) {
          logger.info('Discord alert sent successfully', { url, status, previousStatus })
        } else {
          const errorText = await response.text().catch(() => 'Unknown error')
          logger.error('Discord webhook failed', {
            status: response.status,
            error: errorText
          })
        }
      } catch (error) {
        logger.error('Failed to send Discord webhook', {
          error: error.message
        })
      }

      // Update status store after sending alert
      const { updateLastStatus } = await import('../lib/streams.js')
      updateLastStatus(input)
    }
    ```

  </Tab>
  <Tab value="health">
    A health check endpoint that provides system status and monitoring metrics. Essential for monitoring the monitor itself and integrating with external health check services.

    ```js
    import { z } from 'zod'
    import { getSnapshot } from '../lib/streams.js'
    import { config as envConfig } from '../lib/env.js'

    export const config = {
      type: 'api',
      name: 'HealthCheck',
      description: 'Provides system health status endpoint',
      method: 'GET',
      path: '/healthz',
      emits: [],
      responseSchema: {
        200: z.object({
          status: z.literal('ok'),
          sitesConfigured: z.number(),
          lastKnown: z.record(z.any()),
          now: z.string()
        })
      },
      flows: ['uptime-monitoring'],
    }

    export const handler = async (_, { logger }) => {
      logger.info('Health check endpoint accessed')
      
      try {
        const now = new Date().toISOString()
        const sitesConfigured = envConfig.sites.length
        const lastKnown = getSnapshot()
        
        const response = {
          status: 'ok',
          sitesConfigured,
          lastKnown,
          now
        }
        
        logger.info('Health check completed successfully', { 
          sitesConfigured,
          sitesWithStatus: Object.keys(lastKnown).length
        })
        
        return {
          status: 200,
          body: response
        }
        
      } catch (error) {
        logger.error('Health check failed', { 
          error: error.message,
          stack: error.stack
        })
        
        return {
          status: 200,
          body: {
            status: 'ok',
            sitesConfigured: 0,
            lastKnown: {},
            now: new Date().toISOString(),
            error: error.message
          }
        }
      }
    }
    ```

  </Tab>
  <Tab value="utilities">
    Three essential utility libraries that power the monitoring system: environment validation, rate limiting, and persistent status storage.

    **Environment Configuration (`lib/env.js`)**
    ```js
    // Validates Discord webhook URLs
    function isValidDiscordWebhook(url) {
      if (!url || typeof url !== 'string') return false;
      
      try {
        const parsed = new URL(url);
        return parsed.hostname === 'discord.com' || parsed.hostname === 'discordapp.com';
      } catch {
        return false;
      }
    }

    // Parses and validates the SITES environment variable
    function parseSites(sitesJson) {
      if (!sitesJson) {
        throw new Error('SITES environment variable is required');
      }

      let sites;
      try {
        sites = JSON.parse(sitesJson);
      } catch (error) {
        throw new Error(`Invalid SITES JSON format: ${error.message}`);
      }

      if (!Array.isArray(sites) || sites.length === 0) {
        throw new Error('SITES must be a non-empty JSON array of URLs');
      }

      // Validate each URL
      sites.forEach(site => {
        if (typeof site !== 'string') {
          throw new Error(`Invalid site URL: ${site} (must be string)`);
        }
        try {
          new URL(site);
        } catch {
          throw new Error(`Invalid site URL format: ${site}`);
        }
      });

      return sites;
    }

    export const config = {
      discordWebhook: process.env.DISCORD_WEBHOOK,
      sites: parseSites(process.env.SITES),
      cron: process.env.CHECK_INTERVAL_CRON || '*/1 * * * *',
      alertBurst: parseInt(process.env.ALERT_BURST) || 3,
      alertWindowSec: parseInt(process.env.ALERT_WINDOW_SEC) || 300
    };
    ```

    **Rate Limiter (`lib/rate-limiter.js`)**
    ```js
    // Token bucket rate limiter with per-site isolation
    export function createRateLimiter({ burst, windowSec }) {
      const buckets = new Map()
      const refillRate = burst / (windowSec * 1000)

      function consume(siteUrl) {
        const bucket = getBucket(siteUrl)
        refillBucket(bucket)
        
        if (bucket.tokens >= 1) {
          bucket.tokens -= 1
          return true
        }
        
        return false
      }

      function getBucket(siteUrl) {
        if (!buckets.has(siteUrl)) {
          buckets.set(siteUrl, {
            tokens: burst,
            lastRefill: Date.now()
          })
        }
        return buckets.get(siteUrl)
      }

      function refillBucket(bucket) {
        const now = Date.now()
        const timePassed = now - bucket.lastRefill
        
        if (timePassed > 0) {
          const tokensToAdd = timePassed * refillRate
          bucket.tokens = Math.min(burst, bucket.tokens + tokensToAdd)
          bucket.lastRefill = now
        }
      }

      return { consume, /* other methods */ }
    }
    ```

    **Status Storage (`lib/streams.js`)**
    ```js
    // File-based persistent storage for site status
    import { readFileSync, writeFileSync, existsSync } from 'fs'

    const STORE_FILE = join(process.cwd(), '.motia', 'status-store.json')

    export function updateLastStatus(result) {
      // Validate input
      if (!result?.url || !['UP', 'DOWN'].includes(result.status)) {
        throw new Error('Invalid result object')
      }

      const store = loadStatusStore()
      store[result.url] = { ...result }
      saveStatusStore(store)
    }

    export function getPreviousStatus(url) {
      const store = loadStatusStore()
      const result = store[url]
      return result ? { ...result } : null
    }

    export function getSnapshot() {
      const store = loadStatusStore()
      const snapshot = {}
      
      for (const [url, result] of Object.entries(store)) {
        snapshot[url] = { ...result }
      }
      
      return snapshot
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your monitoring pipeline, making it easy to understand the event flow and debug issues in real-time.

<div className="my-8">![Uptime Monitor in Motia Workbench](./../img/uptime-monitor.gif)</div>

You can monitor real-time status checks, view Discord alert logs, and trace the execution of each step directly in the Workbench interface. This makes development and debugging significantly easier compared to traditional monitoring solutions.

---

## Key Features & Benefits

### âš¡ **Event-Driven Architecture**
Each component is independent and communicates through events, making the system highly scalable and maintainable.

### ðŸŽ¯ **Smart Status Detection**  
Only triggers alerts when status actually changes (UP â†” DOWN), eliminating noise from temporary fluctuations.

### ðŸš¨ **Intelligent Rate Limiting**
Token bucket algorithm prevents alert spam during site flapping while ensuring critical alerts get through.

### ðŸ“Š **Built-in Observability**
Comprehensive logging, health checks, and real-time status tracking with persistent storage.

### ðŸ”§ **Production-Ready**
Robust error handling, timeout management, and configurable check intervals ensure reliability.

### ðŸŽ¨ **Rich Discord Alerts**
Beautiful embedded messages with response times, error details, and status transitions.

---

## Data Flow & Event Architecture

![Uptime Monitor Event Flow](./../img/uptime-monitor-flow.png)

### Event Flow
1. **Cron Trigger** â†’ Emits `check.requested` events for each configured site
2. **Website Checker** â†’ Receives `check.requested`, performs HTTP check
3. **Status Update** â†’ Checker emits `check.result` with result
4. **Alert Processing** â†’ Alerter receives `check.result`, detects status changes
5. **Discord Notification** â†’ Alerter sends webhook if status changed and rate limit allows
6. **Status Storage** â†’ Status is persisted for health endpoint and future comparisons

---

## Trying It Out

Ready to build your own production-ready monitoring system? Let's get it running.

<Steps>

### Install Dependencies

Install the necessary npm packages and set up the development environment.

```shell
npm install
```

### Configure Environment Variables

Create a `.env` file with your monitoring configuration. You'll need a Discord webhook URL and the sites you want to monitor.

```shell
# Required: Discord webhook for alerts
DISCORD_WEBHOOK="https://discord.com/api/webhooks/123456789/your-webhook-token"

# Required: JSON array of URLs to monitor
SITES='["https://example.com", "https://api.yourdomain.com", "https://blog.yoursite.org"]'

# Optional: Check frequency (default: every minute)
CHECK_INTERVAL_CRON="*/1 * * * *"

# Optional: Rate limiting (default: 3 alerts per 5 minutes)
ALERT_BURST="3"
ALERT_WINDOW_SEC="300"
```

### Set Up Discord Webhook

Create a Discord webhook to receive alerts:

1. Go to your Discord server settings
2. Navigate to **Integrations** â†’ **Webhooks**
3. Click **New Webhook**
4. Copy the webhook URL and add it to your `.env` file

### Run the Monitoring System

Start the Motia development server to begin monitoring your websites.

```shell
npm run dev
```

### Check System Health

Verify your monitoring system is working correctly:

```shell
curl http://localhost:3000/healthz
```

You should see a response with your configured sites and their current status:

```json
{
  "status": "ok",
  "sitesConfigured": 3,
  "lastKnown": {
    "https://example.com": {
      "url": "https://example.com",
      "status": "UP",
      "code": 200,
      "responseTime": 245,
      "checkedAt": "2024-01-15T10:30:00.000Z",
      "error": null
    }
  },
  "now": "2024-01-15T10:35:00.000Z"
}
```

### Monitor the Logs

Watch the logs to see your monitoring system in action:

- **Cron triggers**: Check scheduling for all configured sites
- **Website checks**: HTTP requests and response analysis  
- **Status changes**: UP/DOWN transitions and Discord alerts
- **Rate limiting**: Alert suppression during site flapping

</Steps>

---

## Advanced Configuration

### Custom Check Intervals

Modify the cron expression to change monitoring frequency:

```shell
# Every 5 minutes
CHECK_INTERVAL_CRON="*/5 * * * *"

# Every hour
CHECK_INTERVAL_CRON="0 * * * *"

# Every 6 hours
CHECK_INTERVAL_CRON="0 */6 * * *"

# Business hours only (9 AM - 5 PM, Mon-Fri)
CHECK_INTERVAL_CRON="* 9-17 * * 1-5"
```

### Alert Rate Limiting

Fine-tune the rate limiting to match your needs:

```shell
# Very strict: 1 alert per 10 minutes
ALERT_BURST="1"
ALERT_WINDOW_SEC="600"

# More permissive: 5 alerts per 2 minutes
ALERT_BURST="5"  
ALERT_WINDOW_SEC="120"
```

### Multi-Environment Monitoring

Set up different monitoring configurations for different environments:

```shell
# Production sites
SITES='["https://app.production.com", "https://api.production.com"]'

# Staging sites  
SITES='["https://app.staging.com", "https://api.staging.com"]'

# Development sites
SITES='["https://app.dev.com", "http://localhost:8080"]'
```

### Custom Discord Alert Formatting

Modify the `createDiscordMessage` function in `alerter.step.js` to customize alert appearance:

```js
function createDiscordMessage(result, previousStatus) {
  const { url, status, code, responseTime } = result
  
  // Custom colors for your brand
  const color = status === 'UP' ? 0x2ecc71 : 0xe74c3c
  
  // Custom emoji and formatting
  const emoji = status === 'UP' ? 'âœ…' : 'âŒ'
  const urgency = responseTime > 5000 ? 'ðŸŒ SLOW' : 'âš¡ FAST'
  
  return {
    content: `${emoji} **${url}** is ${status}`,
    embeds: [{
      title: `${urgency} Website ${status}`,
      description: `**${url}** changed from ${previousStatus} to ${status}`,
      color,
      timestamp: result.checkedAt,
      fields: [
        {
          name: 'â±ï¸ Response Time',
          value: `${responseTime}ms`,
          inline: true
        },
        {
          name: 'ðŸ“Š Status Code', 
          value: code?.toString() || 'N/A',
          inline: true
        }
      ]
    }]
  }
}
```

---

## Troubleshooting

### Common Issues

**Sites not being checked:**
- Verify `SITES` environment variable is valid JSON
- Check cron expression syntax using [crontab.guru](https://crontab.guru)
- Review logs for parsing errors

**Discord alerts not working:**
- Verify `DISCORD_WEBHOOK` URL is correct
- Test webhook manually: `curl -X POST $DISCORD_WEBHOOK -H "Content-Type: application/json" -d '{"content":"Test message"}'`
- Check Discord webhook permissions

**High memory usage:**
- Monitor status store size with health endpoint
- Consider implementing status history cleanup
- Reduce check frequency for many sites

**False positive alerts:**
- Increase timeout values in checker step
- Implement retry logic before marking as DOWN
- Adjust rate limiting to reduce noise

### Performance Tips

- **Large Site Lists**: Consider sharding across multiple instances
- **Slow Sites**: Implement custom timeout values per site
- **High Frequency**: Use Redis for status storage instead of file system
- **Alert Fatigue**: Implement escalation policies and alert grouping

### Monitoring the Monitor

Set up monitoring for your monitoring system:

```shell
# Monitor the health endpoint itself
curl -f http://localhost:3000/healthz || echo "Monitor is down!"

# Check for recent status updates
curl http://localhost:3000/healthz | jq '.lastKnown | to_entries | map(select(.value.checkedAt > (now - 300)))'

# Verify all sites are being checked
curl http://localhost:3000/healthz | jq '.sitesConfigured == (.lastKnown | length)'
```

---

## ðŸ’» Dive into the Code

Want to explore the complete monitoring implementation? Check out the full source code, including all steps, utilities, and configuration examples:

<div className="not-prose">
  <div className="bg-gradient-to-r from-green-50 to-emerald-50 border border-green-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-green-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete Uptime Monitor</h3>
        <p className="text-gray-600 mb-4">Access the full implementation with event steps, utility libraries, Discord integration, and production-ready configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Monitor Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Monitoring That Actually Works

This uptime monitoring system demonstrates the power of event-driven architecture for infrastructure monitoring. By breaking down monitoring into discrete, specialized components, we've created a system that's not only reliable but also extensible and maintainable.

The event-driven approach means you can easily:
- **Add new notification channels** (Slack, PagerDuty, email) by creating new steps
- **Implement custom health checks** (database connectivity, API endpoints, SSL certificates)
- **Scale monitoring** across multiple regions or environments
- **Integrate with existing systems** without disrupting the core monitoring loop

Key architectural benefits:
- **Resilience**: Component failures don't bring down the entire system
- **Observability**: Built-in logging and tracing at every step
- **Flexibility**: Easy to modify check intervals, alert logic, or add new features
- **Testing**: Each component can be tested in isolation

From here, you can extend the system by:
- Adding support for different check types (TCP, database, custom health endpoints)
- Implementing escalation policies and on-call rotations
- Building a web dashboard for historical data and trends
- Adding integration with incident management systems
- Implementing multi-region monitoring with failover

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing monitoring pipeline.

Ready to build monitoring infrastructure that scales with your business? Start building with Motia today!



## Examples
[uptime-discord-monitor](/docs/examples/uptime-discord-monitor): Code example
---
title: 'Uptime Monitor'
description: 'Real-Time Uptime Monitoring: Building a Resilient Website Monitor with Motia'
---

In today's modern era, website uptime is critical for business success. Whether you're monitoring a personal blog or enterprise applications, you need a reliable system that can detect outages, send alerts, and provide visibility into your site's health. Traditional monitoring solutions often involve complex infrastructure and vendor lock-in, but there's a better way.

This comprehensive guide explores how to build a production-ready uptime monitoring system using Motia's event-driven architecture. We'll cover:

1.  **Event-Driven Monitoring**: How Motia's `steps` create a scalable, maintainable monitoring pipeline.
2.  **Building the Architecture**: A detailed walkthrough of our five-component monitoring system.
3.  **Smart Alerting**: Implementing rate limiting and status change detection to prevent spam.

Let's build a monitoring system that actually works for you.

---

## Explore the Workbench

<div className="my-8">![Uptime Monitor](./../img/uptime-monitor-architecture.png)</div>

**Try it yourself:**
- [View Source Code](https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-uptime-monitor)
- [Browse All Examples](https://github.com/MotiaDev/motia-examples)

---

## The Power of Event-Driven Monitoring

<div className="my-8">![Uptime Monitor Architecture](./../img/uptime-monitor.gif)</div>

At its core, our uptime monitoring system solves a fundamental challenge: how do you continuously monitor multiple websites without creating a brittle, monolithic application? Traditional monitoring tools often suffer from tight coupling, making them difficult to scale and customize. Our Motia-powered solution breaks this down into discrete, event-driven components that each handle a specific aspect of monitoring.

The magic happens through the integration of proven technologies and patterns:

-   **[Cron-Based Scheduling](https://en.wikipedia.org/wiki/Cron)**: Configurable check intervals using familiar cron expressions
-   **[Discord Webhooks](https://discord.com/developers/docs/resources/webhook)**: Instant notifications with rich formatting
-   **[Token Bucket Rate Limiting](https://en.wikipedia.org/wiki/Token_bucket)**: Intelligent alert throttling to prevent spam
-   **[Motia Framework](https://motia.dev)**: Event-driven orchestration with built-in observability

Instead of a monolithic monitoring daemon, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our Monitoring System

Our application consists of five specialized steps, each handling a specific part of the monitoring workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="cron.step.js" />
  <File name="checker.step.js" />
  <File name="alerter.step.js" />
  <File name="health.step.js" />
</Folder>

<Folder name="lib" defaultOpen>
  <File name="env.js" />
  <File name="rate-limiter.js" />
  <File name="streams.js" />
</Folder>

<Tabs items={['cron', 'checker', 'alerter', 'health', 'utilities']}>
  <Tab value="cron">
    The heartbeat of our monitoring system. This cron-triggered step periodically emits check requests for all configured websites, acting as the central scheduler.

    ```js
    import { config as envConfig } from '../lib/env.js';

    export const config = {
      type: 'cron',
      name: 'UptimeCronTrigger',
      cron: envConfig.cron,
      emits: ['check.requested'],
      flows: ['uptime-monitoring']
    };

    export async function handler(context) {
      context.logger.info(`Starting uptime checks for ${envConfig.sites.length} sites`);
      context.logger.info(`Sites configured: ${JSON.stringify(envConfig.sites)}`);

      try {
        // Emit one check.requested event per configured site URL
        for (const url of envConfig.sites) {
          context.logger.info(`Scheduling check for: ${url}`);
          
          await context.emit({ 
            topic: 'check.requested', 
            data: { url: url } 
          });
          
          context.logger.info(`Successfully emitted for: ${url}`);
        }

        context.logger.info(`Successfully scheduled checks for all ${envConfig.sites.length} sites`);
      } catch (error) {
        context.logger.error('Error during cron execution:', error);
        throw error;
      }
    }
    ```

  </Tab>
  <Tab value="checker">
    The core monitoring component that performs HTTP checks on websites. It handles timeouts, errors, and response code analysis, then emits results for further processing.

    ```js
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'WebsiteChecker',
      description: 'Performs HTTP checks on websites and emits results',
      subscribes: ['check.requested'],
      emits: ['check.result', 'status.stream'],
      input: z.object({
        url: z.string().url('Must be a valid URL')
      }),
      flows: ['uptime-monitoring'],
    }

    export const handler = async (input, { logger, emit }) => {
      const { url } = input
      
      logger.info('Starting website check', { url })

      const startTime = performance.now()
      let result

      try {
        // Validate URL format before making request
        const urlObj = new URL(url)
        if (!['http:', 'https:'].includes(urlObj.protocol)) {
          throw new Error('Only HTTP and HTTPS protocols are supported')
        }

        // Perform HTTP request with timeout handling
        const controller = new AbortController()
        const timeoutId = setTimeout(() => controller.abort(), 10000) // 10 second timeout

        const response = await fetch(url, {
          method: 'GET',
          signal: controller.signal,
          headers: {
            'User-Agent': 'Motia-Uptime-Monitor/1.0',
            'Accept': '*/*',
            'Cache-Control': 'no-cache'
          },
          redirect: 'manual'
        })

        clearTimeout(timeoutId)
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        // Determine status: 2xx and 3xx as UP, everything else as DOWN
        const status = (response.status >= 200 && response.status < 400) ? 'UP' : 'DOWN'

        result = {
          url,
          status,
          code: response.status,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: null
        }

        logger.info('Website check completed', {
          url,
          status,
          code: response.status,
          responseTime
        })

      } catch (error) {
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        let errorMessage = error.message

        // Handle specific error types with detailed messages
        if (error.name === 'AbortError') {
          errorMessage = 'Request timeout (10s)'
        } else if (error.name === 'TypeError' && error.message.includes('fetch')) {
          errorMessage = 'Network error - unable to connect'
        } else if (error.code === 'ENOTFOUND') {
          errorMessage = 'DNS resolution failed'
        } else if (error.code === 'ECONNREFUSED') {
          errorMessage = 'Connection refused'
        }

        result = {
          url,
          status: 'DOWN',
          code: null,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: errorMessage
        }

        logger.error('Website check failed', {
          url,
          error: errorMessage,
          responseTime,
          originalError: error.code || error.name
        })
      }

      // Emit results to both alerter and dashboard
      await emit({ topic: 'check.result', data: result })
      await emit({ topic: 'status.stream', data: result })

      logger.info('Check results emitted successfully', { url, status: result.status })
    }
    ```

  </Tab>
  <Tab value="alerter">
    The intelligent alerting system that detects status changes, applies rate limiting, and sends Discord notifications. Only triggers alerts when status actually changes, preventing noise.

    ```js
    import { z } from 'zod'
    import { getPreviousStatus } from '../lib/streams.js'
    import { createRateLimiter } from '../lib/rate-limiter.js'
    import { config as envConfig } from '../lib/env.js'

    // Create a rate limiter instance for Discord alerts
    const rateLimiter = createRateLimiter({
      burst: envConfig.alertBurst,
      windowSec: envConfig.alertWindowSec
    })

    export const config = {
      type: 'event',
      name: 'DiscordAlerter',
      description: 'Sends Discord notifications when website status changes',
      subscribes: ['check.result'],
      emits: [],
      input: z.object({
        url: z.string().url(),
        status: z.enum(['UP', 'DOWN']),
        code: z.number().nullable(),
        responseTime: z.number(),
        checkedAt: z.string(),
        error: z.string().nullable()
      }),
      flows: ['uptime-monitoring'],
    }

    function createDiscordMessage(result, previousStatus) {
      const { url, status, code, responseTime, checkedAt, error } = result

      const isUp = status === 'UP'
      const emoji = isUp ? 'ðŸŸ¢' : 'ðŸ”´'
      const color = isUp ? 0x00ff00 : 0xff0000

      const content = `${emoji} ${url} is ${status}${code ? ` (${code})` : ''}`

      const fields = [
        {
          name: 'Response Time',
          value: `${responseTime}ms`,
          inline: true
        }
      ]

      if (code !== null) {
        fields.push({
          name: 'Status Code',
          value: code.toString(),
          inline: true
        })
      }

      if (error) {
        fields.push({
          name: 'Error',
          value: error,
          inline: false
        })
      }

      fields.push({
        name: 'Previous Status',
        value: previousStatus,
        inline: true
      })

      return {
        content,
        embeds: [{
          title: `Website Status Change: ${status}`,
          description: `${url} changed from ${previousStatus} to ${status}`,
          color,
          timestamp: checkedAt,
          fields
        }]
      }
    }

    export const handler = async (input, { logger }) => {
      const { url, status } = input

      // Get the previous status for comparison
      const previousResult = getPreviousStatus(url)

      // Handle first-time checks
      if (!previousResult) {
        logger.info('First-time check for site, no alert needed', { url, status })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      const previousStatus = previousResult.status

      // Only trigger alerts when status actually changes
      if (status === previousStatus) {
        logger.debug('Status unchanged, no alert needed', { url, status, previousStatus })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      // Status has changed - check rate limiting
      logger.info('Status change detected', {
        url,
        previousStatus,
        newStatus: status,
        transition: `${previousStatus} â†’ ${status}`
      })

      if (!rateLimiter.consume(url)) {
        const timeUntilNext = rateLimiter.getTimeUntilNextToken(url)
        logger.warn('Alert rate limited', {
          url,
          status,
          previousStatus,
          timeUntilNextMs: timeUntilNext,
          tokensRemaining: rateLimiter.getTokenCount(url)
        })
        return
      }

      // Send Discord notification
      const message = createDiscordMessage(input, previousStatus)
      
      try {
        const response = await fetch(envConfig.discordWebhook, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'User-Agent': 'Motia-Uptime-Monitor/1.0'
          },
          body: JSON.stringify(message)
        })

        if (response.ok) {
          logger.info('Discord alert sent successfully', { url, status, previousStatus })
        } else {
          const errorText = await response.text().catch(() => 'Unknown error')
          logger.error('Discord webhook failed', {
            status: response.status,
            error: errorText
          })
        }
      } catch (error) {
        logger.error('Failed to send Discord webhook', {
          error: error.message
        })
      }

      // Update status store after sending alert
      const { updateLastStatus } = await import('../lib/streams.js')
      updateLastStatus(input)
    }
    ```

  </Tab>
  <Tab value="health">
    A health check endpoint that provides system status and monitoring metrics. Essential for monitoring the monitor itself and integrating with external health check services.

    ```js
    import { z } from 'zod'
    import { getSnapshot } from '../lib/streams.js'
    import { config as envConfig } from '../lib/env.js'

    export const config = {
      type: 'api',
      name: 'HealthCheck',
      description: 'Provides system health status endpoint',
      method: 'GET',
      path: '/healthz',
      emits: [],
      responseSchema: {
        200: z.object({
          status: z.literal('ok'),
          sitesConfigured: z.number(),
          lastKnown: z.record(z.any()),
          now: z.string()
        })
      },
      flows: ['uptime-monitoring'],
    }

    export const handler = async (_, { logger }) => {
      logger.info('Health check endpoint accessed')
      
      try {
        const now = new Date().toISOString()
        const sitesConfigured = envConfig.sites.length
        const lastKnown = getSnapshot()
        
        const response = {
          status: 'ok',
          sitesConfigured,
          lastKnown,
          now
        }
        
        logger.info('Health check completed successfully', { 
          sitesConfigured,
          sitesWithStatus: Object.keys(lastKnown).length
        })
        
        return {
          status: 200,
          body: response
        }
        
      } catch (error) {
        logger.error('Health check failed', { 
          error: error.message,
          stack: error.stack
        })
        
        return {
          status: 200,
          body: {
            status: 'ok',
            sitesConfigured: 0,
            lastKnown: {},
            now: new Date().toISOString(),
            error: error.message
          }
        }
      }
    }
    ```

  </Tab>
  <Tab value="utilities">
    Three essential utility libraries that power the monitoring system: environment validation, rate limiting, and persistent status storage.

    **Environment Configuration (`lib/env.js`)**
    ```js
    // Validates Discord webhook URLs
    function isValidDiscordWebhook(url) {
      if (!url || typeof url !== 'string') return false;
      
      try {
        const parsed = new URL(url);
        return parsed.hostname === 'discord.com' || parsed.hostname === 'discordapp.com';
      } catch {
        return false;
      }
    }

    // Parses and validates the SITES environment variable
    function parseSites(sitesJson) {
      if (!sitesJson) {
        throw new Error('SITES environment variable is required');
      }

      let sites;
      try {
        sites = JSON.parse(sitesJson);
      } catch (error) {
        throw new Error(`Invalid SITES JSON format: ${error.message}`);
      }

      if (!Array.isArray(sites) || sites.length === 0) {
        throw new Error('SITES must be a non-empty JSON array of URLs');
      }

      // Validate each URL
      sites.forEach(site => {
        if (typeof site !== 'string') {
          throw new Error(`Invalid site URL: ${site} (must be string)`);
        }
        try {
          new URL(site);
        } catch {
          throw new Error(`Invalid site URL format: ${site}`);
        }
      });

      return sites;
    }

    export const config = {
      discordWebhook: process.env.DISCORD_WEBHOOK,
      sites: parseSites(process.env.SITES),
      cron: process.env.CHECK_INTERVAL_CRON || '*/1 * * * *',
      alertBurst: parseInt(process.env.ALERT_BURST) || 3,
      alertWindowSec: parseInt(process.env.ALERT_WINDOW_SEC) || 300
    };
    ```

    **Rate Limiter (`lib/rate-limiter.js`)**
    ```js
    // Token bucket rate limiter with per-site isolation
    export function createRateLimiter({ burst, windowSec }) {
      const buckets = new Map()
      const refillRate = burst / (windowSec * 1000)

      function consume(siteUrl) {
        const bucket = getBucket(siteUrl)
        refillBucket(bucket)
        
        if (bucket.tokens >= 1) {
          bucket.tokens -= 1
          return true
        }
        
        return false
      }

      function getBucket(siteUrl) {
        if (!buckets.has(siteUrl)) {
          buckets.set(siteUrl, {
            tokens: burst,
            lastRefill: Date.now()
          })
        }
        return buckets.get(siteUrl)
      }

      function refillBucket(bucket) {
        const now = Date.now()
        const timePassed = now - bucket.lastRefill
        
        if (timePassed > 0) {
          const tokensToAdd = timePassed * refillRate
          bucket.tokens = Math.min(burst, bucket.tokens + tokensToAdd)
          bucket.lastRefill = now
        }
      }

      return { consume, /* other methods */ }
    }
    ```

    **Status Storage (`lib/streams.js`)**
    ```js
    // File-based persistent storage for site status
    import { readFileSync, writeFileSync, existsSync } from 'fs'

    const STORE_FILE = join(process.cwd(), '.motia', 'status-store.json')

    export function updateLastStatus(result) {
      // Validate input
      if (!result?.url || !['UP', 'DOWN'].includes(result.status)) {
        throw new Error('Invalid result object')
      }

      const store = loadStatusStore()
      store[result.url] = { ...result }
      saveStatusStore(store)
    }

    export function getPreviousStatus(url) {
      const store = loadStatusStore()
      const result = store[url]
      return result ? { ...result } : null
    }

    export function getSnapshot() {
      const store = loadStatusStore()
      const snapshot = {}
      
      for (const [url, result] of Object.entries(store)) {
        snapshot[url] = { ...result }
      }
      
      return snapshot
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your monitoring pipeline, making it easy to understand the event flow and debug issues in real-time.

<div className="my-8">![Uptime Monitor in Motia Workbench](./../img/uptime-monitor.gif)</div>

You can monitor real-time status checks, view Discord alert logs, and trace the execution of each step directly in the Workbench interface. This makes development and debugging significantly easier compared to traditional monitoring solutions.

---

## Key Features & Benefits

### âš¡ **Event-Driven Architecture**
Each component is independent and communicates through events, making the system highly scalable and maintainable.

### ðŸŽ¯ **Smart Status Detection**  
Only triggers alerts when status actually changes (UP â†” DOWN), eliminating noise from temporary fluctuations.

### ðŸš¨ **Intelligent Rate Limiting**
Token bucket algorithm prevents alert spam during site flapping while ensuring critical alerts get through.

### ðŸ“Š **Built-in Observability**
Comprehensive logging, health checks, and real-time status tracking with persistent storage.

### ðŸ”§ **Production-Ready**
Robust error handling, timeout management, and configurable check intervals ensure reliability.

### ðŸŽ¨ **Rich Discord Alerts**
Beautiful embedded messages with response times, error details, and status transitions.

---

## Data Flow & Event Architecture

![Uptime Monitor Event Flow](./../img/uptime-monitor-flow.png)

### Event Flow
1. **Cron Trigger** â†’ Emits `check.requested` events for each configured site
2. **Website Checker** â†’ Receives `check.requested`, performs HTTP check
3. **Status Update** â†’ Checker emits `check.result` with result
4. **Alert Processing** â†’ Alerter receives `check.result`, detects status changes
5. **Discord Notification** â†’ Alerter sends webhook if status changed and rate limit allows
6. **Status Storage** â†’ Status is persisted for health endpoint and future comparisons

---

## Trying It Out

Ready to build your own production-ready monitoring system? Let's get it running.

<Steps>

### Install Dependencies

Install the necessary npm packages and set up the development environment.

```shell
npm install
```

### Configure Environment Variables

Create a `.env` file with your monitoring configuration. You'll need a Discord webhook URL and the sites you want to monitor.

```shell
# Required: Discord webhook for alerts
DISCORD_WEBHOOK="https://discord.com/api/webhooks/123456789/your-webhook-token"

# Required: JSON array of URLs to monitor
SITES='["https://example.com", "https://api.yourdomain.com", "https://blog.yoursite.org"]'

# Optional: Check frequency (default: every minute)
CHECK_INTERVAL_CRON="*/1 * * * *"

# Optional: Rate limiting (default: 3 alerts per 5 minutes)
ALERT_BURST="3"
ALERT_WINDOW_SEC="300"
```

### Set Up Discord Webhook

Create a Discord webhook to receive alerts:

1. Go to your Discord server settings
2. Navigate to **Integrations** â†’ **Webhooks**
3. Click **New Webhook**
4. Copy the webhook URL and add it to your `.env` file

### Run the Monitoring System

Start the Motia development server to begin monitoring your websites.

```shell
npm run dev
```

### Check System Health

Verify your monitoring system is working correctly:

```shell
curl http://localhost:3000/healthz
```

You should see a response with your configured sites and their current status:

```json
{
  "status": "ok",
  "sitesConfigured": 3,
  "lastKnown": {
    "https://example.com": {
      "url": "https://example.com",
      "status": "UP",
      "code": 200,
      "responseTime": 245,
      "checkedAt": "2024-01-15T10:30:00.000Z",
      "error": null
    }
  },
  "now": "2024-01-15T10:35:00.000Z"
}
```

### Monitor the Logs

Watch the logs to see your monitoring system in action:

- **Cron triggers**: Check scheduling for all configured sites
- **Website checks**: HTTP requests and response analysis  
- **Status changes**: UP/DOWN transitions and Discord alerts
- **Rate limiting**: Alert suppression during site flapping

</Steps>

---

## Advanced Configuration

### Custom Check Intervals

Modify the cron expression to change monitoring frequency:

```shell
# Every 5 minutes
CHECK_INTERVAL_CRON="*/5 * * * *"

# Every hour
CHECK_INTERVAL_CRON="0 * * * *"

# Every 6 hours
CHECK_INTERVAL_CRON="0 */6 * * *"

# Business hours only (9 AM - 5 PM, Mon-Fri)
CHECK_INTERVAL_CRON="* 9-17 * * 1-5"
```

### Alert Rate Limiting

Fine-tune the rate limiting to match your needs:

```shell
# Very strict: 1 alert per 10 minutes
ALERT_BURST="1"
ALERT_WINDOW_SEC="600"

# More permissive: 5 alerts per 2 minutes
ALERT_BURST="5"  
ALERT_WINDOW_SEC="120"
```

### Multi-Environment Monitoring

Set up different monitoring configurations for different environments:

```shell
# Production sites
SITES='["https://app.production.com", "https://api.production.com"]'

# Staging sites  
SITES='["https://app.staging.com", "https://api.staging.com"]'

# Development sites
SITES='["https://app.dev.com", "http://localhost:8080"]'
```

### Custom Discord Alert Formatting

Modify the `createDiscordMessage` function in `alerter.step.js` to customize alert appearance:

```js
function createDiscordMessage(result, previousStatus) {
  const { url, status, code, responseTime } = result
  
  // Custom colors for your brand
  const color = status === 'UP' ? 0x2ecc71 : 0xe74c3c
  
  // Custom emoji and formatting
  const emoji = status === 'UP' ? 'âœ…' : 'âŒ'
  const urgency = responseTime > 5000 ? 'ðŸŒ SLOW' : 'âš¡ FAST'
  
  return {
    content: `${emoji} **${url}** is ${status}`,
    embeds: [{
      title: `${urgency} Website ${status}`,
      description: `**${url}** changed from ${previousStatus} to ${status}`,
      color,
      timestamp: result.checkedAt,
      fields: [
        {
          name: 'â±ï¸ Response Time',
          value: `${responseTime}ms`,
          inline: true
        },
        {
          name: 'ðŸ“Š Status Code', 
          value: code?.toString() || 'N/A',
          inline: true
        }
      ]
    }]
  }
}
```

---

## Troubleshooting

### Common Issues

**Sites not being checked:**
- Verify `SITES` environment variable is valid JSON
- Check cron expression syntax using [crontab.guru](https://crontab.guru)
- Review logs for parsing errors

**Discord alerts not working:**
- Verify `DISCORD_WEBHOOK` URL is correct
- Test webhook manually: `curl -X POST $DISCORD_WEBHOOK -H "Content-Type: application/json" -d '{"content":"Test message"}'`
- Check Discord webhook permissions

**High memory usage:**
- Monitor status store size with health endpoint
- Consider implementing status history cleanup
- Reduce check frequency for many sites

**False positive alerts:**
- Increase timeout values in checker step
- Implement retry logic before marking as DOWN
- Adjust rate limiting to reduce noise

### Performance Tips

- **Large Site Lists**: Consider sharding across multiple instances
- **Slow Sites**: Implement custom timeout values per site
- **High Frequency**: Use Redis for status storage instead of file system
- **Alert Fatigue**: Implement escalation policies and alert grouping

### Monitoring the Monitor

Set up monitoring for your monitoring system:

```shell
# Monitor the health endpoint itself
curl -f http://localhost:3000/healthz || echo "Monitor is down!"

# Check for recent status updates
curl http://localhost:3000/healthz | jq '.lastKnown | to_entries | map(select(.value.checkedAt > (now - 300)))'

# Verify all sites are being checked
curl http://localhost:3000/healthz | jq '.sitesConfigured == (.lastKnown | length)'
```

---

## ðŸ’» Dive into the Code

Want to explore the complete monitoring implementation? Check out the full source code, including all steps, utilities, and configuration examples:

<div className="not-prose">
  <div className="bg-gradient-to-r from-green-50 to-emerald-50 border border-green-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-green-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete Uptime Monitor</h3>
        <p className="text-gray-600 mb-4">Access the full implementation with event steps, utility libraries, Discord integration, and production-ready configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Monitor Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Monitoring That Actually Works

This uptime monitoring system demonstrates the power of event-driven architecture for infrastructure monitoring. By breaking down monitoring into discrete, specialized components, we've created a system that's not only reliable but also extensible and maintainable.

The event-driven approach means you can easily:
- **Add new notification channels** (Slack, PagerDuty, email) by creating new steps
- **Implement custom health checks** (database connectivity, API endpoints, SSL certificates)
- **Scale monitoring** across multiple regions or environments
- **Integrate with existing systems** without disrupting the core monitoring loop

Key architectural benefits:
- **Resilience**: Component failures don't bring down the entire system
- **Observability**: Built-in logging and tracing at every step
- **Flexibility**: Easy to modify check intervals, alert logic, or add new features
- **Testing**: Each component can be tested in isolation

From here, you can extend the system by:
- Adding support for different check types (TCP, database, custom health endpoints)
- Implementing escalation policies and on-call rotations
- Building a web dashboard for historical data and trends
- Adding integration with incident management systems
- Implementing multi-region monitoring with failover

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing monitoring pipeline.

Ready to build monitoring infrastructure that scales with your business? Start building with Motia today!


-   [ai-agents](/docs/getting-started/build-your-first-motia-app/ai-agents): Documentation for ai-agents.
---
title: Agentic Workflows
description: Learn how to build intelligent agentic workflows that make decisions and automate workflows with Motia
---

## What You'll Build

An intelligent pet management system with agentic workflows that automate decisions and enrich data:

- **AI Profile Enrichment** - Automatically generates detailed pet profiles using AI
- **Health Review Agentic Step** - Makes intelligent health decisions based on symptoms
- **Adoption Review Agentic Step** - Assesses adoption readiness and data completeness
- **Orchestrator Integration** - AI decisions that drive real workflow changes

![workbench](../../img/build-your-first-app/ai-agents-workbench.png)
---

## Getting Started

Clone the example repository:

```bash
git clone https://github.com/MotiaDev/build-your-first-app.git
cd build-your-first-app
git checkout ai-agents
```

Install dependencies:

```bash
npm install
```

Set up your OpenAI API key in `.env`:

```bash
OPENAI_API_KEY=your_api_key_here
```

<Callout type="warning">
**Important!** This tutorial requires an OpenAI API key. Get yours at [platform.openai.com/api-keys](https://platform.openai.com/api-keys). Without it, the agentic workflows won't work.
</Callout>

Start the Workbench:

```bash
npm run dev
```

Your Workbench will be available at `http://localhost:3000`.

---

## Project Structure

<Folder name="my-pet-api" defaultOpen>
  <Folder name="steps" defaultOpen>
    <Folder name="typescript">
      <File name="create-pet.step.ts" />
      <File name="ai-profile-enrichment.step.ts" />
      <File name="health-review-agent.step.ts" />
      <File name="adoption-review-agent.step.ts" />
      <File name="pet-lifecycle-orchestrator.step.ts" />
      <File name="agent-decision-framework.ts" />
      <File name="ts-store.ts" />
    </Folder>
    <Folder name="javascript">
      <File name="create-pet.step.js" />
      <File name="ai-profile-enrichment.step.js" />
      <File name="health-review-agent.step.js" />
      <File name="adoption-review-agent.step.js" />
      <File name="pet-lifecycle-orchestrator.step.js" />
      <File name="agent-decision-framework.js" />
      <File name="js-store.js" />
    </Folder>
    <Folder name="python">
      <File name="create_pet_step.py" />
      <File name="ai_profile_enrichment_step.py" />
      <File name="health_review_agent_step.py" />
      <File name="adoption_review_agent_step.py" />
      <File name="pet_lifecycle_orchestrator_step.py" />
    </Folder>
  </Folder>
  <Folder name="services">
    <File name="pet_store.py" />
    <File name="types.py" />
  </Folder>
  <File name=".env" />
  <File name="package.json" />
  <File name="requirements.txt" />
  <File name="types.d.ts" />
</Folder>

<Callout type="info">
Files like `features.json` and `tutorial/tutorial.tsx` are only for the interactive tutorial and are not part of Motia's project structure.
</Callout>

All code examples in this guide are available in the [build-your-first-app](https://github.com/MotiaDev/build-your-first-app/tree/ai-agents) repository.

You can follow this guide to learn how to build agentic workflows with Motia step by step, or you can clone the repository and dive into our Interactive Tutorial to learn by doing directly in the Workbench.

![interactive-tutorial](../../img/build-your-first-app/interactive-tutorial-ai.png)

---

## Understanding Agentic Workflows

You've built APIs, background jobs, and workflows that orchestrate your pet shelter. But what about decisions that aren't black and white? Should this pet's symptoms require treatment? Is this profile ready for the adoption page?

That's where agentic workflows come in. They're smart assistants that make judgment calls based on context - the kind of decisions that would normally need a human to review every single case.

In our pet shelter, we use two flavors:
- **Content generators** write engaging pet profiles automatically
- **Decision makers** evaluate health symptoms and choose whether treatment is needed
- **Data reviewers** assess if adoption information is complete

The difference from traditional code? Instead of writing hundreds of if-else rules for every possible symptom combination, you describe what matters to the AI. It reads the context and makes an informed call.

When a pet arrives with "coughing, lethargy, loss of appetite" - the AI evaluates these symptoms together and decides if treatment is needed. No hardcoded rules. Just intelligent analysis of the situation.

---

## Creating Your First Agentic Step

Let's start with a content generation agentic step that automatically enriches pet profiles when they're created.

### Step 1: Set Up Pet Creation to Emit Events

First, update your pet creation endpoint to emit events that will trigger the agentic step.

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/ai-agents/steps/typescript/create-pet.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/ai-agents/steps/python/create_pet_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/ai-agents/steps/javascript/create-pet.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/create-pet.step.ts"
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'
    import { TSStore } from './ts-store'

    const createPetSchema = z.object({
      name: z.string().min(1, 'Name is required').trim(),
      species: z.enum(['dog', 'cat', 'bird', 'other']),
      ageMonths: z.number().int().min(0, 'Age must be a positive number')
    })

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'TsCreatePet',
      path: '/ts/pets',
      method: 'POST',
      emits: ['ts.pet.created', 'ts.feeding.reminder.enqueued'],
      flows: ['TsPetManagement']
    }

    export const handler: Handlers['TsCreatePet'] = async (req, { emit, logger }) => {
      try {
        const validatedData = createPetSchema.parse(req.body)
        
        const pet = TSStore.create({ 
          name: validatedData.name, 
          species: validatedData.species, 
          ageMonths: validatedData.ageMonths 
        })
        
        if (logger) {
          logger.info('ðŸ¾ Pet created', { petId: pet.id, name: pet.name, species: pet.species, status: pet.status })
        }
        
        if (emit) {
          await (emit as any)({
            topic: 'ts.pet.created',
            data: { petId: pet.id, event: 'pet.created', name: pet.name, species: validatedData.species }
          })
          
          await (emit as any)({
            topic: 'ts.feeding.reminder.enqueued',
            data: { petId: pet.id, enqueuedAt: Date.now() }
          })
        }

      return { status: 201, body: pet }
        
      } catch (error) {
        if (error instanceof z.ZodError) {
          return {
            status: 400,
            body: {
              message: 'Validation error',
              errors: error.errors
            }
          }
        }
        
        return {
          status: 500,
          body: { message: 'Internal server error' }
        }
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/create_pet_step.py"
    config = {
        "type": "api",
        "name": "PyCreatePet",
        "path": "/py/pets",
        "method": "POST",
        "emits": ["py.pet.created", "py.feeding.reminder.enqueued"],
        "flows": ["PyPetManagement"]
    }

    async def handler(req, ctx=None):
        logger = getattr(ctx, 'logger', None) if ctx else None
        emit = getattr(ctx, 'emit', None) if ctx else None
        
        try:
            import sys
            import os
            import time
            sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
            from services import pet_store
        except ImportError:
            return {"status": 500, "body": {"message": "Import error"}}
        
        b = (req.get("body") or {})
        name = b.get("name")
        species = b.get("species")
        age = b.get("ageMonths")

        if not isinstance(name, str) or not name.strip():
            return {"status": 400, "body": {"message": "Invalid name"}}
        if species not in ["dog","cat","bird","other"]:
            return {"status": 400, "body": {"message": "Invalid species"}}
        try:
            age_val = int(age)
        except Exception:
            return {"status": 400, "body": {"message": "Invalid ageMonths"}}

        pet = pet_store.create(name, species, age_val)
        
        if logger:
            logger.info('ðŸ¾ Pet created', {
                'petId': pet['id'], 
                'name': pet['name'], 
                'species': pet['species'], 
                'status': pet['status']
            })
        
        if emit:
            await emit({
                'topic': 'py.pet.created',
                'data': {'petId': pet['id'], 'event': 'pet.created', 'name': pet['name'], 'species': pet['species']}
            })
            
            await emit({
                'topic': 'py.feeding.reminder.enqueued',
                'data': {'petId': pet['id'], 'enqueuedAt': int(time.time() * 1000)}
            })

        return {"status": 201, "body": pet}
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/create-pet.step.js"
    const { create } = require('./js-store')

    exports.config = {
      type: 'api',
      name: 'JsCreatePet',
      path: '/js/pets',
      method: 'POST',
      emits: ['js.pet.created', 'js.feeding.reminder.enqueued'],
      flows: ['JsPetManagement']
    }

    exports.handler = async (req, context) => {
      const { emit, logger } = context || {}
      const b = req.body || {}
      const name = typeof b.name === 'string' && b.name.trim()
      const speciesOk = ['dog','cat','bird','other'].includes(b.species)
      const ageOk = Number.isFinite(b.ageMonths)

      if (!name || !speciesOk || !ageOk) {
        return { status: 400, body: { message: 'Invalid payload: {name, species, ageMonths}' } }
      }

      const pet = create({ name, species: b.species, ageMonths: Number(b.ageMonths) })

      if (logger) {
        logger.info('ðŸ¾ Pet created', { petId: pet.id, name: pet.name, species: pet.species, status: pet.status })
      }
      
      if (emit) {
        await emit({
          topic: 'js.pet.created',
          data: { petId: pet.id, event: 'pet.created', name: pet.name, species: pet.species }
        })
        
        await emit({
          topic: 'js.feeding.reminder.enqueued',
          data: { petId: pet.id, enqueuedAt: Date.now() }
        })
      }

      return { status: 201, body: pet }
    }
    ```
  </Tab>
</Tabs>

The API endpoint now emits an event after creating a pet. The response returns immediately while the agentic step processes asynchronously in the background.

---

### Step 2: Create the AI Profile Enrichment Agentic Step

Now let's create the agentic step that listens for new pets and enriches their profiles with AI-generated content.

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/ai-agents/steps/typescript/ai-profile-enrichment.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/ai-agents/steps/python/ai_profile_enrichment_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/ai-agents/steps/javascript/ai-profile-enrichment.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/ai-profile-enrichment.step.ts"
    // steps/typescript/ai-profile-enrichment.step.ts
    import { EventConfig, Handlers } from 'motia';
    import { TSStore, PetProfile } from './ts-store';

    export const config = {
      type: 'event',
      name: 'TsAiProfileEnrichment',
      description: 'Agentic step that enriches pet profiles using OpenAI',
      subscribes: ['ts.pet.created'],
      emits: [],
      flows: ['TsPetManagement']
    };

    export const handler: Handlers['TsAiProfileEnrichment'] = async (input, { logger }) => {
      const { petId, name, species } = input;

      if (logger) {
        logger.info('ðŸ¤– AI Profile Enrichment started', { petId, name, species });
      }

      try {
        const apiKey = process.env.OPENAI_API_KEY;
        if (!apiKey) {
          throw new Error('OPENAI_API_KEY environment variable is not set');
        }

        const prompt = `Generate a pet profile for adoption purposes. Pet details:
- Name: ${name}
- Species: ${species}

Please provide a JSON response with these fields:
- bio: A warm, engaging 2-3 sentence description that would appeal to potential adopters
- breedGuess: Your best guess at the breed or breed mix (be specific but realistic)
- temperamentTags: An array of 3-5 personality traits (e.g., "friendly", "energetic", "calm")
- adopterHints: Practical advice for potential adopters (family type, living situation, care needs)

Keep it positive, realistic, and adoption-focused.`;

        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'gpt-3.5-turbo',
            messages: [
              {
                role: 'system',
                content: 'You are a pet adoption specialist who creates compelling, accurate pet profiles. Always respond with valid JSON only.'
              },
              {
                role: 'user',
                content: prompt
              }
            ],
            max_tokens: 500,
            temperature: 0.7,
          }),
        });

        if (!response.ok) {
          throw new Error(`OpenAI API error: ${response.status} ${response.statusText}`);
        }

        const data = await response.json();
        const aiResponse = data.choices[0]?.message?.content;

        if (!aiResponse) {
          throw new Error('No response from OpenAI API');
        }

        let profile: PetProfile;
        try {
          profile = JSON.parse(aiResponse);
        } catch (parseError) {
          profile = {
            bio: `${name} is a wonderful ${species} looking for a loving home. This pet has a unique personality and would make a great companion.`,
            breedGuess: species === 'dog' ? 'Mixed Breed' : species === 'cat' ? 'Domestic Shorthair' : 'Mixed Breed',
            temperamentTags: ['friendly', 'loving', 'loyal'],
            adopterHints: `${name} would do well in a caring home with patience and love.`
          };
          
          if (logger) {
            logger.warn('âš ï¸ AI response parsing failed, using fallback profile', { petId, parseError: parseError instanceof Error ? parseError.message : String(parseError) });
          }
        }

        const updatedPet = TSStore.updateProfile(petId, profile);
        
        if (!updatedPet) {
          throw new Error(`Pet not found: ${petId}`);
        }

        if (logger) {
          logger.info('âœ… AI Profile Enrichment completed', { 
            petId, 
            profile: {
              bio: profile.bio.substring(0, 50) + '...',
              breedGuess: profile.breedGuess,
              temperamentTags: profile.temperamentTags,
              adopterHints: profile.adopterHints.substring(0, 50) + '...'
            }
          });
        }

      } catch (error: any) {
        if (logger) {
          logger.error('âŒ AI Profile Enrichment failed', { 
            petId, 
            error: error.message 
          });
        }

        const fallbackProfile: PetProfile = {
          bio: `${name} is a lovely ${species} with a unique personality, ready to find their forever home.`,
          breedGuess: species === 'dog' ? 'Mixed Breed' : species === 'cat' ? 'Domestic Shorthair' : 'Mixed Breed',
          temperamentTags: ['friendly', 'adaptable'],
          adopterHints: `${name} is looking for a patient and loving family.`
        };

        TSStore.updateProfile(petId, fallbackProfile);
      }
    };
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/ai_profile_enrichment_step.py"
    import json
    import os
    import asyncio
    import urllib.request
    import urllib.parse
    import urllib.error
    import time

    config = {
        "type": "event",
        "name": "PyAiProfileEnrichment",
        "description": "Agentic step that enriches pet profiles using OpenAI",
        "subscribes": ["py.pet.created"],
        "emits": [],
        "flows": ["PyPetManagement"]
    }

    async def handler(input_data, ctx=None):
        logger = getattr(ctx, 'logger', None) if ctx else None
        emit = getattr(ctx, 'emit', None) if ctx else None
        
        pet_id = input_data.get('petId')
        name = input_data.get('name')
        species = input_data.get('species')

        if logger:
            logger.info('ðŸ¤– AI Profile Enrichment started', {'petId': pet_id, 'name': name, 'species': species})

        try:
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
            from services import pet_store

            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                raise Exception('OPENAI_API_KEY environment variable is not set')

            prompt = f"""Generate a pet profile for adoption purposes. Pet details:
- Name: {name}
- Species: {species}

Please provide a JSON response with these fields:
- bio: A warm, engaging 2-3 sentence description that would appeal to potential adopters
- breedGuess: Your best guess at the breed or breed mix (be specific but realistic)
- temperamentTags: An array of 3-5 personality traits (e.g., "friendly", "energetic", "calm")
- adopterHints: Practical advice for potential adopters (family type, living situation, care needs)

Keep it positive, realistic, and adoption-focused."""

            request_data = {
                'model': 'gpt-3.5-turbo',
                'messages': [
                    {
                        'role': 'system',
                        'content': 'You are a pet adoption specialist who creates compelling, accurate pet profiles. Always respond with valid JSON only.'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': 500,
                'temperature': 0.7,
            }
            
            request_json = json.dumps(request_data).encode('utf-8')
            
            request = urllib.request.Request(
                    'https://api.openai.com/v1/chat/completions',
                data=request_json,
                    headers={
                    'Authorization': f'Bearer {api_key}',
                        'Content-Type': 'application/json',
                }
            )
            
            try:
                with urllib.request.urlopen(request) as response:
                    if response.status != 200:
                        raise Exception(f'OpenAI API error: {response.status} {response.reason}')
                    
                    response_data = response.read().decode('utf-8')
                    data = json.loads(response_data)
                    ai_response = data.get('choices', [{}])[0].get('message', {}).get('content')

                    if not ai_response:
                        raise Exception('No response from OpenAI API')
            except urllib.error.HTTPError as e:
                raise Exception(f'OpenAI API HTTP error: {e.code} {e.reason}')
            except urllib.error.URLError as e:
                raise Exception(f'OpenAI API URL error: {e.reason}')

            try:
                profile = json.loads(ai_response)
            except json.JSONDecodeError as parse_error:
                profile = {
                    'bio': f'{name} is a wonderful {species} looking for a loving home. This pet has a unique personality and would make a great companion.',
                    'breedGuess': 'Mixed Breed' if species == 'dog' else 'Domestic Shorthair' if species == 'cat' else 'Mixed Breed',
                    'temperamentTags': ['friendly', 'loving', 'loyal'],
                    'adopterHints': f'{name} would do well in a caring home with patience and love.'
                }
                
                if logger:
                    logger.warn('âš ï¸ AI response parsing failed, using fallback profile', {'petId': pet_id, 'parseError': str(parse_error)})

            updated_pet = pet_store.update_profile(pet_id, profile)
            
            if not updated_pet:
                raise Exception(f'Pet not found: {pet_id}')

            if logger:
                logger.info('âœ… AI Profile Enrichment completed', {
                    'petId': pet_id,
                    'profile': {
                        'bio': profile['bio'][:50] + '...',
                        'breedGuess': profile['breedGuess'],
                        'temperamentTags': profile['temperamentTags'],
                        'adopterHints': profile['adopterHints'][:50] + '...'
                    }
                })

        except Exception as error:
            if logger:
                logger.error('âŒ AI Profile Enrichment failed', {
                    'petId': pet_id,
                    'error': str(error)
                })

            fallback_profile = {
                'bio': f'{name} is a lovely {species} with a unique personality, ready to find their forever home.',
                'breedGuess': 'Mixed Breed' if species == 'dog' else 'Domestic Shorthair' if species == 'cat' else 'Mixed Breed',
                'temperamentTags': ['friendly', 'adaptable'],
                'adopterHints': f'{name} is looking for a patient and loving family.'
            }

            try:
                import sys
                import os
                sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
                from services import pet_store
                pet_store.update_profile(pet_id, fallback_profile)
            except:
                pass
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/ai-profile-enrichment.step.js"
    const { updateProfile } = require('./js-store')

    exports.config = {
      type: 'event',
      name: 'JsAiProfileEnrichment',
      description: 'Agentic step that enriches pet profiles using OpenAI',
      subscribes: ['js.pet.created'],
      emits: [],
      flows: ['JsPetManagement']
    }

    exports.handler = async (input, context) => {
      const { emit, logger } = context || {}
      const { petId, name, species } = input

      if (logger) {
        logger.info('ðŸ¤– AI Profile Enrichment started', { petId, name, species })
      }

      try {
      const apiKey = process.env.OPENAI_API_KEY
      if (!apiKey) {
          throw new Error('OPENAI_API_KEY environment variable is not set')
        }

        const prompt = `Generate a pet profile for adoption purposes. Pet details:
- Name: ${name}
- Species: ${species}

Please provide a JSON response with these fields:
- bio: A warm, engaging 2-3 sentence description that would appeal to potential adopters
- breedGuess: Your best guess at the breed or breed mix (be specific but realistic)
- temperamentTags: An array of 3-5 personality traits (e.g., "friendly", "energetic", "calm")
- adopterHints: Practical advice for potential adopters (family type, living situation, care needs)

Keep it positive, realistic, and adoption-focused.`

        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'gpt-3.5-turbo',
            messages: [
              {
                role: 'system',
                content: 'You are a pet adoption specialist who creates compelling, accurate pet profiles. Always respond with valid JSON only.'
              },
              {
                role: 'user',
                content: prompt
              }
            ],
            max_tokens: 500,
            temperature: 0.7,
          }),
        })

        if (!response.ok) {
          throw new Error(`OpenAI API error: ${response.status} ${response.statusText}`)
        }

        const data = await response.json()
        const aiResponse = data.choices[0]?.message?.content

        if (!aiResponse) {
          throw new Error('No response from OpenAI API')
        }

        let profile
        try {
          profile = JSON.parse(aiResponse)
        } catch (parseError) {
          profile = {
            bio: `${name} is a wonderful ${species} looking for a loving home. This pet has a unique personality and would make a great companion.`,
            breedGuess: species === 'dog' ? 'Mixed Breed' : species === 'cat' ? 'Domestic Shorthair' : 'Mixed Breed',
            temperamentTags: ['friendly', 'loving', 'loyal'],
            adopterHints: `${name} would do well in a caring home with patience and love.`
          }
          
          if (logger) {
            logger.warn('âš ï¸ AI response parsing failed, using fallback profile', { petId, parseError: parseError.message })
          }
        }

        const updatedPet = updateProfile(petId, profile)
        
        if (!updatedPet) {
          throw new Error(`Pet not found: ${petId}`)
        }

        if (logger) {
          logger.info('âœ… AI Profile Enrichment completed', {
            petId,
            profile: {
              bio: profile.bio.substring(0, 50) + '...',
              breedGuess: profile.breedGuess,
              temperamentTags: profile.temperamentTags,
              adopterHints: profile.adopterHints.substring(0, 50) + '...'
            }
          })
        }

      } catch (error) {
        if (logger) {
          logger.error('âŒ AI Profile Enrichment failed', {
            petId,
            error: error.message
          })
        }

        const fallbackProfile = {
          bio: `${name} is a lovely ${species} with a unique personality, ready to find their forever home.`,
          breedGuess: species === 'dog' ? 'Mixed Breed' : species === 'cat' ? 'Domestic Shorthair' : 'Mixed Breed',
          temperamentTags: ['friendly', 'adaptable'],
          adopterHints: `${name} is looking for a patient and loving family.`
        }

        updateProfile(petId, fallbackProfile)
      }
    }
    ```
  </Tab>
</Tabs>

### How This Agentic Step Works

This is a **content generation agentic step** - it enriches data without making workflow decisions:

- **Subscribes** to `pet.created` events
- **Calls OpenAI** with a carefully crafted prompt
- **Parses the response** into structured data
- **Updates the pet** with AI-generated content
- **Has a fallback** if the AI call fails

The key is the prompt engineering - we tell the AI exactly what fields we need and what tone to use. The AI returns JSON that we can parse and store directly.

---

## Testing Your Agentic Step

The best way to test your agentic step is through **Workbench**. It lets you create pets, watch the AI enrichment happen in real-time, and see all the logs in one place.

### Create a Pet

Open Workbench and test the CreatePet endpoint. The AI will automatically start enriching the profile in the background.

<Callout type="tip">
**Prefer using curl?**

```bash
curl -X POST http://localhost:3000/ts/pets \
  -H "Content-Type: application/json" \
  -d '{"name": "Max", "species": "dog", "ageMonths": 24}'
```
</Callout>

Check the logs in Workbench to see the agentic step in action:

![ai-enrichment-logs](../../img/build-your-first-app/ai-enrichment-logs.png)

You'll see:
1. "Pet created" log from the API endpoint
2. "AI Profile Enrichment started" log
3. "AI Profile Enrichment completed" with generated content

### View the Enriched Profile

Fetch the pet in Workbench to see the AI-generated profile, or use curl:

<Callout type="tip">
**Using curl?**

```bash
curl http://localhost:3000/ts/pets/1
```
</Callout>

You'll get back something like:

![ai-enrichment-logs](../../img/build-your-first-app/ai-enrichment-logs-pet-get.png)

---

## Building a Decision-Making Agentic Step

Now let's create an agentic step that doesn't just generate content - it makes decisions that control the workflow. This is called **agentic routing**.

### The Health Review Agentic Step

This agentic step analyzes pet symptoms and decides if treatment is needed. Instead of you writing complex if-else logic, the AI evaluates the context and chooses the appropriate action.

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/ai-agents/steps/typescript/health-review-agent.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/ai-agents/steps/python/health_review_agent_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/ai-agents/steps/javascript/health-review-agent.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/health-review-agent.step.ts"
    // steps/typescript/health-review-agent.step.ts
    import { ApiRouteConfig, Handlers } from 'motia';
    import { TSStore } from './ts-store';
    import { 
      HEALTH_REVIEW_EMITS, 
      buildAgentContext, 
      callAgentDecision,
      getAgentArtifacts
    } from './agent-decision-framework';

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'TsHealthReviewAgent',
      path: '/ts/pets/:id/health-review',
      method: 'POST',
      emits: ['ts.health.treatment_required', 'ts.health.no_treatment_needed'],
      flows: ['TsPetManagement']
    };

    export const handler: Handlers['TsHealthReviewAgent'] = async (req, { emit, logger }) => {
      const petId = req.pathParams?.id;

      if (!petId) {
        return { status: 400, body: { message: 'Pet ID is required' } };
      }

      const pet = TSStore.get(petId);
      if (!pet) {
        return { status: 404, body: { message: 'Pet not found' } };
      }

      if (logger) {
        logger.info('ðŸ¥ Health Review Agent triggered', { 
          petId, 
          currentStatus: pet.status,
          symptoms: pet.symptoms || []
        });
      }

      if (!['healthy', 'in_quarantine', 'available'].includes(pet.status)) {
        return {
          status: 400,
          body: {
            message: 'Health review can only be performed on healthy, quarantined, or available pets',
            currentStatus: pet.status
          }
        };
      }

      const agentContext = buildAgentContext(pet);

      const recentArtifacts = getAgentArtifacts(petId)
        .filter(a => 
          a.agentType === 'health-review' && 
          a.success && 
          a.inputs.currentStatus === pet.status &&
          (Date.now() - a.timestamp) < 60000
        );

      if (recentArtifacts.length > 0) {
        const recent = recentArtifacts[recentArtifacts.length - 1];
        if (logger) {
          logger.info('ðŸ”„ Idempotent health review - returning cached decision', {
            petId,
            chosenEmit: recent.parsedDecision.chosenEmit,
            timestamp: recent.timestamp
          });
        }

        return {
          status: 200,
          body: {
            message: 'Health review completed (cached)',
            petId,
            agentDecision: recent.parsedDecision,
            artifact: {
              timestamp: recent.timestamp,
              success: recent.success
            }
          }
        };
      }

      try {
        if (logger) {
          logger.info('ðŸ” Starting agent decision call', { petId, agentContext });
        }
        
        const artifact = await callAgentDecision(
          'health-review',
          agentContext,
          HEALTH_REVIEW_EMITS,
          logger
        );
        
        if (logger) {
          logger.info('âœ… Agent decision call completed', { petId, success: artifact.success });
        }

        if (!artifact.success) {
          if (logger) {
            logger.warn('âš ï¸ Agent decision failed, but returning error response', {
              petId,
              error: artifact.error
            });
          }
          
          return {
            status: 500,
            body: {
              message: 'Agent decision failed',
              error: artifact.error,
              petId,
              suggestion: 'Check OpenAI API key and try again'
            }
          };
        }

        const chosenEmitDef = HEALTH_REVIEW_EMITS.find(e => e.id === artifact.parsedDecision.chosenEmit);
        if (!chosenEmitDef) {
          return {
            status: 500,
            body: {
              message: 'Invalid emit chosen by agent',
              chosenEmit: artifact.parsedDecision.chosenEmit
            }
          };
        }

        if (emit) {
          (emit as any)({
            topic: chosenEmitDef.topic as 'ts.health.treatment_required' | 'ts.health.no_treatment_needed',
            data: {
              petId,
              event: chosenEmitDef.id.replace('emit.', ''),
              agentDecision: artifact.parsedDecision,
              timestamp: artifact.timestamp,
              context: agentContext
            }
          });

          if (logger) {
            logger.info('âœ… Health review emit fired', {
              petId,
              chosenEmit: artifact.parsedDecision.chosenEmit,
              topic: chosenEmitDef.topic,
              rationale: artifact.parsedDecision.rationale
            });
          }
        }

        return {
          status: 200,
          body: {
            message: 'Health review completed',
            petId,
            agentDecision: artifact.parsedDecision,
            emitFired: chosenEmitDef.topic,
            artifact: {
              timestamp: artifact.timestamp,
              success: artifact.success,
              availableEmits: artifact.availableEmits.map(e => e.id)
            }
          }
        };

      } catch (error: any) {
        if (logger) {
          logger.error('âŒ Health review agent error', {
            petId,
            error: error.message
          });
        }

        return {
          status: 500,
          body: {
            message: 'Health review failed',
            error: error.message,
            petId
          }
        };
      }
    };
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/health_review_agent_step.py"
    import sys
    import os
    import time

    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
    from services import pet_store

    config = {
        "type": "api",
        "name": "PyHealthReviewAgent",
        "path": "/py/pets/:id/health-review",
        "method": "POST",
        "emits": ["py.health.treatment_required", "py.health.no_treatment_needed"],
        "flows": ["PyPetManagement"]
    }

    # Emit Registry - Tools available to health review agent
    HEALTH_REVIEW_EMITS = [
        {
            "id": "emit.health.treatment_required",
            "topic": "py.health.treatment_required",
            "description": "Pet requires medical treatment due to health concerns",
            "orchestratorEffect": "healthy â†’ ill â†’ under_treatment",
            "guards": ["must_be_healthy"]
        },
        {
            "id": "emit.health.no_treatment_needed",
            "topic": "py.health.no_treatment_needed", 
            "description": "Pet is healthy and requires no medical intervention",
            "orchestratorEffect": "stay healthy",
            "guards": ["must_be_healthy"]
        }
    ]

    def build_agent_context(pet):
        return {
            "petId": pet["id"],
            "species": pet["species"],
            "ageMonths": pet["ageMonths"],
            "weightKg": pet.get("weightKg"),
            "symptoms": pet.get("symptoms", []),
            "flags": pet.get("flags", []),
            "profile": pet.get("profile"),
            "currentStatus": pet["status"]
        }

    async def call_agent_decision(agent_type, context, available_emits, logger):
        # ... OpenAI API calling logic ...
        # (See full implementation in the actual file)
        pass

    async def handler(req, ctx=None):
        logger = getattr(ctx, 'logger', None) if ctx else None
        emit = getattr(ctx, 'emit', None) if ctx else None
        pet_id = req.get("pathParams", {}).get("id")

        if not pet_id:
            return {"status": 400, "body": {"message": "Pet ID is required"}}

            pet = pet_store.get(pet_id)
            if not pet:
                return {"status": 404, "body": {"message": "Pet not found"}}

        if logger:
            logger.info('ðŸ¥ Health Review Agent triggered', {
                "petId": pet_id,
                "currentStatus": pet["status"],
                "symptoms": pet.get("symptoms", [])
            })

        if pet["status"] not in ["healthy", "in_quarantine"]:
                return {
                "status": 400,
                    "body": {
                    "message": "Health review can only be performed on healthy or quarantined pets",
                    "currentStatus": pet["status"]
                }
            }

        agent_context = build_agent_context(pet)

        try:
            artifact = await call_agent_decision(
                'health-review',
                agent_context,
                HEALTH_REVIEW_EMITS,
                logger
            )

            if not artifact["success"]:
                return {
                    "status": 500,
                    "body": {
                        "message": "Agent decision failed",
                        "error": artifact["error"],
                        "petId": pet_id,
                        "suggestion": "Check OpenAI API key and try again"
                    }
                }

            chosen_emit_def = None
            for emit_def in HEALTH_REVIEW_EMITS:
                if emit_def["id"] == artifact["parsedDecision"]["chosenEmit"]:
                    chosen_emit_def = emit_def
                    break
                    
            if not chosen_emit_def:
                return {
                    "status": 500,
                    "body": {
                        "message": "Invalid emit chosen by agent",
                        "chosenEmit": artifact["parsedDecision"]["chosenEmit"]
                    }
                }

            if emit:
                await emit({
                    "topic": chosen_emit_def["topic"],
                    "data": {
                        "petId": pet_id,
                        "event": chosen_emit_def["id"].replace('emit.', ''),
                        "agentDecision": artifact["parsedDecision"],
                        "timestamp": artifact["timestamp"],
                        "context": agent_context
                    }
                })

            if logger:
                    logger.info('âœ… Health review emit fired', {
                    "petId": pet_id,
                        "chosenEmit": artifact["parsedDecision"]["chosenEmit"],
                        "topic": chosen_emit_def["topic"],
                        "rationale": artifact["parsedDecision"]["rationale"]
                })

            return {
                "status": 200,
                "body": {
                    "message": "Health review completed",
                    "petId": pet_id,
                    "agentDecision": artifact["parsedDecision"],
                    "emitFired": chosen_emit_def["topic"],
                    "artifact": {
                        "timestamp": artifact["timestamp"],
                        "success": artifact["success"],
                        "availableEmits": [e["id"] for e in artifact["availableEmits"]]
                    }
                }
            }

        except Exception as error:
            if logger:
                logger.error('âŒ Health review agent error', {
                    "petId": pet_id,
                    "error": str(error)
                })

            return {
                "status": 500,
                "body": {
                    "message": "Health review failed",
                    "error": str(error),
                    "petId": pet_id
                }
            }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/health-review-agent.step.js"
    const { get } = require('./js-store')
    const { 
      HEALTH_REVIEW_EMITS, 
      buildAgentContext, 
      callAgentDecision,
      getAgentArtifacts
    } = require('./agent-decision-framework')

    exports.config = {
      type: 'api',
      name: 'JsHealthReviewAgent',
      path: '/js/pets/:id/health-review',
      method: 'POST',
      emits: ['js.health.treatment_required', 'js.health.no_treatment_needed'],
      flows: ['JsPetManagement']
    }

    exports.handler = async (req, context) => {
      const { emit, logger } = context || {}
      const petId = req.pathParams?.id

      if (!petId) {
        return { status: 400, body: { message: 'Pet ID is required' } }
      }

        const pet = get(petId)
        if (!pet) {
        return { status: 404, body: { message: 'Pet not found' } }
      }

      if (logger) {
        logger.info('ðŸ¥ Health Review Agent triggered', { 
          petId, 
          currentStatus: pet.status,
          symptoms: pet.symptoms || []
        })
      }

      if (pet.status !== 'healthy' && pet.status !== 'in_quarantine') {
          return {
            status: 400,
            body: {
            message: 'Health review can only be performed on healthy or quarantined pets',
              currentStatus: pet.status
            }
          }
        }

      const agentContext = buildAgentContext(pet)

      const recentArtifacts = getAgentArtifacts(petId)
        .filter(a => 
          a.agentType === 'health-review' && 
          a.success && 
          a.inputs.currentStatus === pet.status &&
          (Date.now() - a.timestamp) < 60000
        )

      if (recentArtifacts.length > 0) {
        const recent = recentArtifacts[recentArtifacts.length - 1]
          if (logger) {
          logger.info('ðŸ”„ Idempotent health review - returning cached decision', {
            petId,
            chosenEmit: recent.parsedDecision.chosenEmit,
            timestamp: recent.timestamp
          })
        }

          return {
            status: 200,
            body: {
              message: 'Health review completed (cached)',
            petId,
            agentDecision: recent.parsedDecision,
            artifact: {
              timestamp: recent.timestamp,
              success: recent.success
            }
          }
        }
      }

      try {
        const artifact = await callAgentDecision(
          'health-review',
          agentContext,
          HEALTH_REVIEW_EMITS,
          logger
        )

        if (!artifact.success) {
          return {
            status: 500,
            body: {
              message: 'Agent decision failed',
              error: artifact.error,
              petId
            }
          }
        }

        const chosenEmitDef = HEALTH_REVIEW_EMITS.find(e => e.id === artifact.parsedDecision.chosenEmit)
        if (!chosenEmitDef) {
          return {
            status: 500,
            body: {
              message: 'Invalid emit chosen by agent',
              chosenEmit: artifact.parsedDecision.chosenEmit
            }
          }
        }

        if (emit) {
          await emit({
            topic: chosenEmitDef.topic,
            data: {
              petId,
              agentDecision: artifact.parsedDecision,
              timestamp: artifact.timestamp,
              context: agentContext
            }
          })

        if (logger) {
            logger.info('âœ… Health review emit fired', {
            petId,
              chosenEmit: artifact.parsedDecision.chosenEmit,
              topic: chosenEmitDef.topic,
              rationale: artifact.parsedDecision.rationale
          })
          }
        }

        return {
          status: 200,
          body: {
            message: 'Health review completed',
            petId,
            agentDecision: artifact.parsedDecision,
            emitFired: chosenEmitDef.topic,
            artifact: {
              timestamp: artifact.timestamp,
              success: artifact.success,
              availableEmits: artifact.availableEmits.map(e => e.id)
            }
          }
        }

      } catch (error) {
        if (logger) {
          logger.error('âŒ Health review agent error', {
            petId,
            error: error.message
          })
        }

        return {
          status: 500,
          body: {
            message: 'Health review failed',
            error: error.message,
            petId
          }
        }
      }
    }
    ```
  </Tab>
</Tabs>

### How Decision-Making Agentic Steps Work

This agentic step is fundamentally different from the enrichment agentic step:

1. **It's an API Step** - Staff trigger it explicitly when they need a decision
2. **It defines an emits registry** - Lists all possible actions the AI can choose from (in `agent-decision-framework.ts/js`)
3. **It calls the AI with context + options** - The AI evaluates and picks one
4. **It fires the chosen emit** - This emit goes to the orchestrator, changing workflow state
5. **It uses idempotency checking** - Caches recent decisions to prevent duplicate AI calls

The framework functions (`buildAgentContext`, `callAgentDecision`, `getAgentArtifacts`) handle the OpenAI call and ensure the AI picks from valid options.

---

## Testing the Health Review Agentic Step

The best way to test decision-making agentic steps is through **Workbench**. You can create pets, trigger the health review, and watch the AI make decisions in real-time.

### Create a Pet

Use Workbench to create a pet. The AI enrichment will automatically trigger.

<Callout type="tip">
**Prefer using curl?**

```bash
curl -X POST http://localhost:3000/ts/pets \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Buddy",
    "species": "dog",
    "ageMonths": 36
  }'
```
</Callout>

### Trigger the Health Review

In Workbench, test the health review endpoint to see the AI make a decision.

<Callout type="tip">
**Using curl?**

```bash
curl -X POST http://localhost:3000/ts/pets/1/health-review \
  -H "Content-Type: application/json"
```
</Callout>

![ai-health-review-create-pet](../../img/build-your-first-app/health-treatment-reqd-create-pet.png)

You'll get a response like:

```json
{
  "message": "Health review completed",
  "petId": "1",
  "agentDecision": {
    "chosenEmit": "emit.health.treatment_required",
    "rationale": "The pet shows concerning symptoms including coughing, lethargy, and loss of appetite. These symptoms suggest a potential respiratory infection or illness requiring veterinary attention."
  },
  "emitFired": "ts.health.treatment_required",
  "artifact": {
    "timestamp": 1234567890,
    "success": true,
    "availableEmits": ["emit.health.treatment_required", "emit.health.no_treatment_needed"]
  }
}
```
![ai-health-review-reqd](../../img/build-your-first-app/health-treatment-reqd.png)

The AI evaluates the pet's data and makes a decision. The emit it fires will trigger the orchestrator to handle the appropriate state transition.

### Verify the Status Change

Check the pet status in Workbench to see the AI's decision reflected in the workflow state.

<Callout type="tip">
**Using curl?**

```bash
curl http://localhost:3000/ts/pets/1
```
</Callout>

![ai-health-review-status](../../img/build-your-first-app/ai-health-review-status.png)

The pet's status has automatically changed based on the AI's decision!

---

## Connecting Agentic Steps to the Orchestrator

The real power comes when your agentic steps integrate with a workflow orchestrator. The orchestrator subscribes to the events emitted by agentic steps and handles the actual state transitions.

The orchestrator configuration shows it subscribes to agentic step events:

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/pet-lifecycle-orchestrator.step.ts"
    export const config = {
      type: 'event',
      name: 'TsPetLifecycleOrchestrator',
      description: 'Pet lifecycle state management with staff interaction points',
      subscribes: [
        'ts.feeding.reminder.completed',
        'ts.pet.status.update.requested',
        'ts.health.treatment_required',       // From Health Review Agentic Step
        'ts.health.no_treatment_needed',      // From Health Review Agentic Step
        'ts.adoption.needs_data',             // From Adoption Review Agentic Step
        'ts.adoption.ready'                   // From Adoption Review Agentic Step
      ],
      emits: [
        'ts.treatment.required',
        'ts.adoption.ready',
        'ts.treatment.completed'
      ],
      flows: ['TsPetManagement']
    }

    // The orchestrator has transition rules that handle agentic step events
    const TRANSITION_RULES: TransitionRule[] = [
      // ... other rules ...
      
      // Agentic step-driven health transitions
      {
        from: ["healthy", "in_quarantine"],
        to: "ill",
        event: "health.treatment_required",
        description: "Agent assessment - pet requires medical treatment"
      },
      {
        from: ["healthy", "in_quarantine"],
        to: "healthy",
        event: "health.no_treatment_needed",
        description: "Agent assessment - pet remains healthy"
      },
      // Agentic step-driven adoption transitions
      {
        from: ["healthy"],
        to: "healthy",
        event: "adoption.needs_data",
        description: "Agent assessment - pet needs additional data before adoption",
        flagAction: { action: 'add', flag: 'needs_data' }
      },
      {
        from: ["healthy"],
        to: "available",
        event: "adoption.ready",
        description: "Agent assessment - pet ready for adoption",
        guards: ['no_needs_data_flag']
      }
    ]
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/pet_lifecycle_orchestrator_step.py"
    config = {
        "type": "event",
        "name": "PyPetLifecycleOrchestrator",
        "description": "Pet lifecycle state management with staff interaction points",
        "subscribes": [
            "py.feeding.reminder.completed",
            "py.pet.status.update.requested",
            "py.health.treatment_required",       # From Health Review Agentic Step
            "py.health.no_treatment_needed",      # From Health Review Agentic Step
            "py.adoption.needs_data",             # From Adoption Review Agentic Step
            "py.adoption.ready"                   # From Adoption Review Agentic Step
        ],
        "emits": [
            "py.treatment.required",
            "py.adoption.ready",
            "py.treatment.completed"
        ],
        "flows": ["PyPetManagement"]
    }

    # Transition rules that handle agentic step events
    TRANSITION_RULES = [
        # ... other rules ...
        
        # Agentic step-driven health transitions
        {
            'from': ['healthy', 'in_quarantine'],
            'to': 'ill',
            'event': 'health.treatment_required',
            'description': 'Agent assessment - pet requires medical treatment'
        },
        {
            'from': ['healthy', 'in_quarantine'],
            'to': 'healthy',
            'event': 'health.no_treatment_needed',
            'description': 'Agent assessment - pet remains healthy'
        },
        # Agentic step-driven adoption transitions
        {
            'from': ['healthy'],
            'to': 'healthy',
            'event': 'adoption.needs_data',
            'description': 'Agent assessment - pet needs additional data before adoption',
            'flagAction': {'action': 'add', 'flag': 'needs_data'}
        },
        {
            'from': ['healthy'],
            'to': 'available',
            'event': 'adoption.ready',
            'description': 'Agent assessment - pet ready for adoption',
            'guards': ['no_needs_data_flag']
        }
    ]
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/pet-lifecycle-orchestrator.step.js"
    exports.config = {
      type: 'event',
      name: 'JsPetLifecycleOrchestrator',
      description: 'Pet lifecycle state management with staff interaction points',
      subscribes: [
        'js.feeding.reminder.completed',
        'js.pet.status.update.requested',
        'js.health.treatment_required',       // From Health Review Agentic Step
        'js.health.no_treatment_needed',      // From Health Review Agentic Step
        'js.adoption.needs_data',             // From Adoption Review Agentic Step
        'js.adoption.ready'                   // From Adoption Review Agentic Step
      ],
      emits: [
        'js.treatment.required',
        'js.adoption.ready',
        'js.treatment.completed'
      ],
      flows: ['JsPetManagement']
    }

    // Transition rules that handle agentic step events
    const TRANSITION_RULES = [
      // ... other rules ...
      
      // Agentic step-driven health transitions
      {
        from: ["healthy", "in_quarantine"],
        to: "ill",
        event: "health.treatment_required",
        description: "Agent assessment - pet requires medical treatment"
      },
      {
        from: ["healthy", "in_quarantine"],
        to: "healthy",
        event: "health.no_treatment_needed",
        description: "Agent assessment - pet remains healthy"
      },
      // Agentic step-driven adoption transitions
      {
        from: ["healthy"],
        to: "healthy",
        event: "adoption.needs_data",
        description: "Agent assessment - pet needs additional data before adoption",
        flagAction: { action: 'add', flag: 'needs_data' }
      },
      {
        from: ["healthy"],
        to: "available",
        event: "adoption.ready",
        description: "Agent assessment - pet ready for adoption",
        guards: ['no_needs_data_flag']
      }
    ]
    ```
  </Tab>
</Tabs>

---

ðŸŽ‰ **Congratulations!** You've built intelligent agentic workflows that make decisions and drive workflows. Your pet shelter now has automated intelligence that would have taken hundreds of lines of complex logic to implement manually.

---

## What's Next?

Your pet shelter now has intelligent agentic workflows making decisions! But how do you give users real-time feedback while all this AI processing happens in the background?

In the final guide, we'll add **Real-Time Streaming** to provide live updates as your workflows execute:

- **Stream Configuration** - Define stream schemas for type-safe updates
- **API with Streaming** - Initialize streams and return immediately to clients
- **Background Job Streaming** - Push real-time progress updates as jobs process
- **Agentic Step Streaming** - Stream AI enrichment progress in real-time
- **Multi-Step Streaming** - Multiple steps updating the same stream

Let's complete your system by adding real-time streaming capabilities!

Explore more examples in the [Motia Examples Repository](https://github.com/MotiaDev/motia-examples).






-   [api-endpoints](/docs/getting-started/build-your-first-motia-app/api-endpoints): Documentation for api-endpoints.
---
title: API Endpoints
description: Learn how to create HTTP API endpoints with Motia
---

## What You'll Build

A pet management API with these endpoints:

- **POST `/pets`** - Create a new pet
- **GET `/pets`** - List all pets
- **GET `/pets/:id`** - Get a specific pet
- **PUT `/pets/:id`** - Update a pet
- **DELETE `/pets/:id`** - Delete a pet

![workbench](../../img/build-your-first-app/api-workbench.png)
---

## Getting Started

Clone the example repository:

```bash
git clone https://github.com/MotiaDev/build-your-first-app.git
cd build-your-first-app
git checkout api-endpoints
```

Install dependencies:

```bash
npm install
```

Start the Workbench:

```bash
npm run dev
```

Your Workbench will be available at `http://localhost:3000`.

---

## Project Structure

<Folder name="my-pet-api" defaultOpen>
  <Folder name="steps" defaultOpen>
    <Folder name="typescript">
      <File name="create-pet.step.ts" />
      <File name="get-pets.step.ts" />
      <File name="get-pet.step.ts" />
      <File name="update-pet.step.ts" />
      <File name="delete-pet.step.ts" />
      <File name="ts-store.ts" />
    </Folder>
    <Folder name="javascript">
      <File name="create-pet.step.js" />
      <File name="get-pets.step.js" />
      <File name="get-pet.step.js" />
      <File name="update-pet.step.js" />
      <File name="delete-pet.step.js" />
      <File name="js-store.js" />
    </Folder>
    <Folder name="python">
      <File name="create_pet_step.py" />
      <File name="get_pets_step.py" />
      <File name="get_pet_step.py" />
      <File name="update_pet_step.py" />
      <File name="delete_pet_step.py" />
    </Folder>
  </Folder>
    <Folder name="services">
      <File name="pet_store.py" />
      <File name="types.py" />
    </Folder>
  <File name="package.json" />
  <File name="requirements.txt" />
  <File name="types.d.ts" />
</Folder>

<Callout type="info">
Files like `features.json` and `tutorial/tutorial.tsx` are only for the interactive tutorial and are not part of Motia's project structure.
</Callout>

All code examples in this guide are available in the [build-your-first-app](https://github.com/MotiaDev/build-your-first-app/tree/api-endpoints) repository.

You can follow this guide to learn how to build a REST API with Motia step by step, or you can clone the repository and dive into our Interactive Tutorial to learn by doing directly in the Workbench.

![interactive-tutorial](../../img/build-your-first-app/interactive-tutorial.png)

---

## Creating Your First Endpoint

<Callout type="info">
This tutorial focuses on Motia's capabilities to create complete backend system from APIs to Streaming AI agents step-by-step. Here, we're showcasing writing APIs with Motia Steps - For data persistence, we use a simple JSON file store in the examples. In a real application, you would use a database like PostgreSQL, MongoDB, or any other data store of your choice. The complete store implementation is available in the [GitHub repository](https://github.com/MotiaDev/build-your-first-app/tree/api-endpoints).
</Callout>

### Configuration

Every API endpoint has two parts:

**Config** - Defines when and how the step runs:

| Property | Description |
|----------|-------------|
| `name` | Unique identifier |
| `type` | Set to `'api'` |
| `path` | URL path for the endpoint |
| `method` | HTTP method (GET, POST, PUT, DELETE) |

**Handler** - The function that executes your business logic.

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/typescript/create-pet.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/python/create_pet_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/javascript/create-pet.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/create-pet.step.ts"
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'
    import { TSStore } from './ts-store'

    const createPetSchema = z.object({
      name: z.string().min(1, 'Name is required'),
      species: z.enum(['dog', 'cat', 'bird', 'other']),
      ageMonths: z.number().int().min(0),
    })

    export const config: ApiRouteConfig = {
      name: 'CreatePet',
      type: 'api',
      path: '/pets',
      method: 'POST',
      bodySchema: createPetSchema,
      flows: ['PetManagement'],
    }

    export const handler: Handlers['CreatePet'] = async (req, { logger }) => {
      const data = createPetSchema.parse(req.body)
      
      // In a real application, this would be a database call
      // e.g., await db.pets.create(data)
      const pet = TSStore.create(data)

      logger.info('Pet created', { petId: pet.id })

      return { status: 201, body: pet }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/create_pet_step.py"
    import sys
    import os
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
    from services import pet_store

    config = {
        "name": "CreatePet",
        "type": "api",
        "path": "/pets",
        "method": "POST",
        "emits": []
    }

    async def handler(req, ctx=None):
        b = req.get("body") or {}
        name = b.get("name")
        species = b.get("species")
        age = b.get("ageMonths")

        if not isinstance(name, str) or not name.strip():
            return {"status": 400, "body": {"message": "Invalid name"}}
        if species not in ["dog", "cat", "bird", "other"]:
            return {"status": 400, "body": {"message": "Invalid species"}}

        try:
            age_val = int(age)
        except Exception:
            return {"status": 400, "body": {"message": "Invalid ageMonths"}}

        # In a real application, this would be a database call
        # e.g., pet = await db.pets.create(name, species, age_val)
        pet = pet_store.create(name, species, age_val)
        return {"status": 201, "body": pet}
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/create-pet.step.js"
    const { create } = require('./js-store')

    const config = {
      name: 'CreatePet',
      type: 'api',
      path: '/pets',
      method: 'POST',
      emits: []
    }

    const handler = async (req) => {
      const b = req.body || {}
      const name = typeof b.name === 'string' && b.name.trim()
      const speciesOk = ['dog', 'cat', 'bird', 'other'].includes(b.species)
      const ageOk = Number.isFinite(b.ageMonths)

      if (!name || !speciesOk || !ageOk) {
        return { status: 400, body: { message: 'Invalid payload' } }
      }

      // In a real application, this would be a database call
      // e.g., const pet = await db.pets.create({ name, species: b.species, ageMonths: Number(b.ageMonths) })
      const pet = create({ name, species: b.species, ageMonths: Number(b.ageMonths) })
      return { status: 201, body: pet }
    }

    module.exports = { config, handler }
    ```
  </Tab>
</Tabs>

## Testing Your API

You can test your endpoints using curl or the Workbench interface.

### Using curl

```bash
# Create a pet
curl -X POST http://localhost:3000/pets \
  -H "Content-Type: application/json" \
  -d '{"name": "Max", "species": "dog", "ageMonths": 24}'
```

### Using Workbench

You can also test your endpoint directly in the Workbench, which provides an interactive interface to test your API endpoints with real requests and see the responses in real-time:

![create-pet](../../img/build-your-first-app/create-api.png)

---
## Adding GET Endpoints

### List All Pets

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/typescript/get-pets.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/python/get_pets_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/javascript/get-pets.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/get-pets.step.ts"
    import { ApiRouteConfig, Handlers } from 'motia'
    import { TSStore } from './ts-store'

    export const config: ApiRouteConfig = {
      name: 'GetPets',
      type: 'api',
      path: '/pets',
      method: 'GET',
      flows: ['PetManagement'],
    }

    export const handler: Handlers['GetPets'] = async (req, { logger }) => {
      // In a real application, this would be a database call
      // e.g., const pets = await db.pets.findMany()
      const pets = TSStore.list()
      
      logger.info('Retrieved all pets', { count: pets.length })
      return { status: 200, body: pets }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/get_pets_step.py"
    import sys
    import os
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
    from services import pet_store

    config = {
        "name": "GetPets",
        "type": "api",
        "path": "/pets",
        "method": "GET",
        "emits": []
    }

    async def handler(req, ctx=None):
        # In a real application, this would be a database call
        # e.g., pets = await db.pets.find_all()
        return {"status": 200, "body": pet_store.list_all()}
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/get-pets.step.js"
    const { list } = require('./js-store')

    const config = {
      name: 'GetPets',
      type: 'api',
      path: '/pets',
      method: 'GET',
      emits: []
    }

    const handler = async () => {
      // In a real application, this would be a database call
      // e.g., const pets = await db.pets.findAll()
      return { status: 200, body: list() }
    }

    module.exports = { config, handler }
    ```
  </Tab>
</Tabs>

### Testing List All Pets

Test with curl:

```bash
# List all pets
curl http://localhost:3000/pets
```

Or use the Workbench interface:

![create-pet](../../img/build-your-first-app/list-pets.png)

---

### Get Single Pet

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/typescript/get-pet.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/python/get_pet_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/javascript/get-pet.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/get-pet.step.ts"
    import { ApiRouteConfig, Handlers } from 'motia'
    import { TSStore } from './ts-store'

    export const config: ApiRouteConfig = {
      name: 'GetPet',
      type: 'api',
      path: '/pets/:id',
      method: 'GET',
      flows: ['PetManagement'],
    }

    export const handler: Handlers['GetPet'] = async (req, { logger }) => {
      // In a real application, this would be a database call
      // e.g., const pet = await db.pets.findById(req.pathParams.id)
      const pet = TSStore.get(req.pathParams.id)

      if (!pet) {
        logger.warn('Pet not found', { id: req.pathParams.id })
        return { status: 404, body: { message: 'Pet not found' } }
      }

      return { status: 200, body: pet }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/get_pet_step.py"
    import sys
    import os
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
    from services import pet_store

    config = {
        "name": "GetPet",
        "type": "api",
        "path": "/pets/:id",
        "method": "GET",
        "emits": []
    }

    async def handler(req, ctx=None):
        pid = req.get("pathParams", {}).get("id")
        # In a real application, this would be a database call
        # e.g., pet = await db.pets.find_by_id(pid)
        pet = pet_store.get(pid)
        return {"status": 200, "body": pet} if pet else {"status": 404, "body": {"message": "Not found"}}
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/get-pet.step.js"
    const { get } = require('./js-store')

    const config = {
      name: 'GetPet',
      type: 'api',
      path: '/pets/:id',
      method: 'GET',
      emits: []
    }

    const handler = async (req) => {
      // In a real application, this would be a database call
      // e.g., const pet = await db.pets.findById(req.pathParams.id)
      const pet = get(req.pathParams.id)
      return pet 
        ? { status: 200, body: pet } 
        : { status: 404, body: { message: 'Not found' } }
    }

    module.exports = { config, handler }
    ```
  </Tab>
</Tabs>

<Callout type="info">
**Testing tip:** When testing GET endpoints with path parameters like `/pets/:id`, switch to the **Params** tab (not Body) to enter the ID value.
</Callout>

The `:id` in the path creates a path parameter accessible via `req.pathParams.id`.

### Testing Get Single Pet

Test with curl:

```bash
# Get specific pet (replace 1 with an actual pet ID)
curl http://localhost:3000/pets/1
```

Or use the Workbench interface:

![create-pet](../../img/build-your-first-app/get-pet-by-id.png)

---

## Adding UPDATE Endpoint

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/typescript/update-pet.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/python/update_pet_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/javascript/update-pet.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/update-pet.step.ts"
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'
    import { TSStore } from './ts-store'

    const updatePetSchema = z.object({
      name: z.string().min(1).optional(),
      status: z.enum(['available', 'pending', 'adopted']).optional(),
      ageMonths: z.number().int().min(0).optional(),
    })

    export const config: ApiRouteConfig = {
      name: 'UpdatePet',
      type: 'api',
      path: '/pets/:id',
      method: 'PUT',
      bodySchema: updatePetSchema,
      flows: ['PetManagement'],
    }

    export const handler: Handlers['UpdatePet'] = async (req, { logger }) => {
      const updates = updatePetSchema.parse(req.body)
      
      // In a real application, this would be a database call
      // e.g., const pet = await db.pets.update(req.pathParams.id, updates)
      const pet = TSStore.update(req.pathParams.id, updates)

      if (!pet) {
        return { status: 404, body: { message: 'Pet not found' } }
      }

      logger.info('Pet updated', { petId: pet.id })
      return { status: 200, body: pet }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/update_pet_step.py"
    import sys
    import os
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
    from services import pet_store

    config = {
        "name": "UpdatePet",
        "type": "api",
        "path": "/pets/:id",
        "method": "PUT",
        "emits": []
    }

    async def handler(req, ctx=None):
        pid = req.get("pathParams", {}).get("id")
        b = req.get("body") or {}
        patch = {}

        if isinstance(b.get("name"), str):
            patch["name"] = b["name"]
        if b.get("species") in ["dog", "cat", "bird", "other"]:
            patch["species"] = b["species"]
        if isinstance(b.get("ageMonths"), (int, float)):
            patch["ageMonths"] = int(b["ageMonths"])
        if b.get("status") in ["available", "pending", "adopted"]:
            patch["status"] = b["status"]

        # In a real application, this would be a database call
        # e.g., updated = await db.pets.update(pid, patch)
        updated = pet_store.update(pid, patch)
        return {"status": 200, "body": updated} if updated else {"status": 404, "body": {"message": "Not found"}}
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/update-pet.step.js"
    const { update } = require('./js-store')

    const config = {
      name: 'UpdatePet',
      type: 'api',
      path: '/pets/:id',
      method: 'PUT',
      emits: []
    }

    const handler = async (req) => {
      const b = req.body || {}
      const patch = {}

      if (typeof b.name === 'string') patch.name = b.name
      if (['dog', 'cat', 'bird', 'other'].includes(b.species)) patch.species = b.species
      if (Number.isFinite(b.ageMonths)) patch.ageMonths = Number(b.ageMonths)
      if (['available', 'pending', 'adopted'].includes(b.status)) patch.status = b.status

      // In a real application, this would be a database call
      // e.g., const updated = await db.pets.update(req.pathParams.id, patch)
      const updated = update(req.pathParams.id, patch)
      return updated 
        ? { status: 200, body: updated } 
        : { status: 404, body: { message: 'Not found' } }
    }

    module.exports = { config, handler }
    ```
  </Tab>
</Tabs>

### Testing Update Pet

Test with curl:

```bash
# Update a pet (replace 1 with an actual pet ID)
curl -X PUT http://localhost:3000/pets/1 \
  -H "Content-Type: application/json" \
  -d '{"status": "adopted"}'
```

Or use the Workbench interface:

![create-pet](../../img/build-your-first-app/update-pet.png)

---

## Adding DELETE Endpoint

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/typescript/delete-pet.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/python/delete_pet_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/api-endpoints/steps/javascript/delete-pet.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/delete-pet.step.ts"
    import { ApiRouteConfig, Handlers } from 'motia'
    import { TSStore } from './ts-store'

    export const config: ApiRouteConfig = {
      name: 'DeletePet',
      type: 'api',
      path: '/pets/:id',
      method: 'DELETE',
      flows: ['PetManagement'],
    }

    export const handler: Handlers['DeletePet'] = async (req, { logger }) => {
      // In a real application, this would be a database call
      // e.g., const deleted = await db.pets.delete(req.pathParams.id)
      const deleted = TSStore.remove(req.pathParams.id)

      if (!deleted) {
        return { status: 404, body: { message: 'Pet not found' } }
      }

      logger.info('Pet deleted', { petId: req.pathParams.id })
      return { status: 204 }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/delete_pet_step.py"
    import sys
    import os
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
    from services import pet_store

    config = {
        "name": "DeletePet",
        "type": "api",
        "path": "/pets/:id",
        "method": "DELETE",
        "emits": []
    }

    async def handler(req, ctx=None):
        pid = req.get("pathParams", {}).get("id")
        # In a real application, this would be a database call
        # e.g., ok = await db.pets.delete(pid)
        ok = pet_store.remove(pid)
        return {"status": 204, "body": {}} if ok else {"status": 404, "body": {"message": "Not found"}}
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/delete-pet.step.js"
    const { remove } = require('./js-store')

    const config = {
      name: 'DeletePet',
      type: 'api',
      path: '/pets/:id',
      method: 'DELETE',
      emits: []
    }

    const handler = async (req) => {
      // In a real application, this would be a database call
      // e.g., const ok = await db.pets.delete(req.pathParams.id)
      const ok = remove(req.pathParams.id)
      return ok 
        ? { status: 204, body: {} } 
        : { status: 404, body: { message: 'Not found' } }
    }

    module.exports = { config, handler }
    ```
  </Tab>
</Tabs>

DELETE endpoints return `204 No Content` on success.

### Testing Delete Pet

Test with curl:

```bash
# Delete a pet (replace 1 with an actual pet ID)
curl -X DELETE http://localhost:3000/pets/1
```

Or use the Workbench interface:

![create-pet](../../img/build-your-first-app/delete-pet.png)

---

As you can see in this example, Motia handles routing, validation, and error handling automatically. With just a few lines of code, you've built a complete REST API with:
- **Automatic routing** based on your step configuration
- **Path parameter extraction** (`/pets/:id` â†’ `req.pathParams.id`)
- **HTTP method handling** (GET, POST, PUT, DELETE)
- **Response formatting** with proper status codes
- **Built-in error handling** and validation

ðŸŽ‰ **Congratulations!** You've successfully created your first API endpoints with Motia. Your pet store API is now ready to handle all CRUD operations.

---

## What's Next?

You now have a working REST API for your pet store! But a complete backend system needs more than just API endpoints. In the next guide, we'll add background jobs using Event Steps and scheduled tasks with Cron Steps to handle tasks like:

- **SetNextFeedingReminder** - Queue jobs that automatically schedule feeding reminders when pets are added or updated
- **Deletion Reaper** - Cron jobs that run daily to clean up soft-deleted records and expired data

Let's continue building your complete backend system by adding these background jobs with Event Steps and scheduled tasks with Cron Steps.

-   [background-jobs](/docs/getting-started/build-your-first-motia-app/background-jobs): Documentation for background-jobs.
---
title: Background Jobs
description: Learn how to create async background jobs and scheduled tasks with Motia
---

## What You'll Build

A pet management system with background jobs that handle:

- **Event Step** - Async job that sets feeding reminders when pets are created
- **Cron Step** - Scheduled job that runs daily to clean up deleted pets

![workbench](../../img/build-your-first-app/background-jobs-workbench.png)
---

## Getting Started

Clone the example repository:

```bash
git clone https://github.com/MotiaDev/build-your-first-app.git
cd build-your-first-app
git checkout background-jobs
```

Install dependencies:

```bash
npm install
```

Start the Workbench:

```bash
npm run dev
```

Your Workbench will be available at `http://localhost:3000`.

---

## Project Structure

<Folder name="my-pet-api" defaultOpen>
  <Folder name="steps" defaultOpen>
    <Folder name="typescript">
      <File name="create-pet.step.ts" />
      <File name="set-next-feeding-reminder.job.step.ts" />
      <File name="deletion-reaper.cron.step.ts" />
      <File name="ts-store.ts" />
    </Folder>
    <Folder name="javascript">
      <File name="create-pet.step.js" />
      <File name="set-next-feeding-reminder.job.step.js" />
      <File name="deletion-reaper.cron.step.js" />
      <File name="js-store.js" />
    </Folder>
    <Folder name="python">
      <File name="create_pet_step.py" />
      <File name="set_next_feeding_reminder.job_step.py" />
      <File name="deletion_reaper.cron_step.py" />
    </Folder>
  </Folder>
  <Folder name="services">
    <File name="pet_store.py" />
    <File name="types.py" />
  </Folder>
  <File name="package.json" />
  <File name="requirements.txt" />
  <File name="types.d.ts" />
</Folder>

<Callout type="info">
Files like `features.json` and `tutorial/tutorial.tsx` are only for the interactive tutorial and are not part of Motia's project structure.
</Callout>

All code examples in this guide are available in the [build-your-first-app](https://github.com/MotiaDev/build-your-first-app/tree/background-jobs) repository.

You can follow this guide to learn how to build background jobs with Motia step by step, or you can clone the repository and dive into our Interactive Tutorial to learn by doing directly in the Workbench.

![interactive-tutorial](../../img/build-your-first-app/interactive-tutorial-bg.png)

---

## Understanding Background Jobs

Background jobs let you handle time-consuming tasks without blocking your API responses. When a user creates a pet, they get an immediate response while tasks like sending emails or processing data happen in the background.

Motia provides two types of background jobs:

- **Event Steps** - Triggered by events from your API endpoints
- **Cron Steps** - Run on a schedule (like daily cleanup tasks)

---

## Creating Your First Event Step

Let's create a background job that sets feeding reminders when a pet is created. First, we need to emit an event from our API endpoint.

### Step 1: Emit Events from API

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/background-jobs/steps/typescript/create-pet.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/background-jobs/steps/python/create_pet_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/background-jobs/steps/javascript/create-pet.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/create-pet.step.ts"
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'
    import { TSStore } from './ts-store'

    const createPetSchema = z.object({
      name: z.string().min(1, 'Name is required').trim(),
      species: z.enum(['dog', 'cat', 'bird', 'other']),
      ageMonths: z.number().int().min(0, 'Age must be a positive number')
    })

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'TsCreatePet',
      path: '/ts/pets',
      method: 'POST',
      // Declare what events this endpoint can emit
      emits: ['ts.feeding.reminder.enqueued'],
      flows: ['TsPetManagement'],
      bodySchema: createPetSchema
    }

    export const handler: Handlers['TsCreatePet'] = async (req, { emit, logger }) => {
      try {
        const validatedData = createPetSchema.parse(req.body)
        
        const pet = TSStore.create({ 
          name: validatedData.name, 
          species: validatedData.species, 
          ageMonths: validatedData.ageMonths
        })
        
        if (logger) {
          logger.info('ðŸ¾ Pet created', { 
            petId: pet.id, 
            name: pet.name, 
            species: pet.species, 
            status: pet.status 
          })
        }
        
        // Emit event to trigger background job
        if (emit) {
          await emit({
            topic: 'ts.feeding.reminder.enqueued',
            data: {
              petId: pet.id,
              enqueuedAt: Date.now()
            }
          })
        }

        return { status: 201, body: pet }
      } catch (error) {
        if (error instanceof z.ZodError) {
          return { 
            status: 400, 
            body: { 
              message: 'Validation error', 
              errors: error.errors 
            } 
          }
        }
        
        if (logger) {
          logger.error('âŒ Pet creation failed', { 
            error: error instanceof Error ? error.message : 'Unknown error' 
          })
        }
        
        return { 
          status: 500, 
          body: { message: 'Internal server error' } 
        }
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/create_pet_step.py"
    import sys
    import os
    import time
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
    from services import pet_store

    config = {
        "name": "CreatePet",
        "type": "api",
        "path": "/pets",
        "method": "POST",
        "emits": ["py.feeding.reminder.enqueued"]
    }

    async def handler(req, ctx=None):
        b = req.get("body") or {}
        name = b.get("name")
        species = b.get("species")
        age = b.get("ageMonths")

        if not isinstance(name, str) or not name.strip():
            return {"status": 400, "body": {"message": "Invalid name"}}
        if species not in ["dog", "cat", "bird", "other"]:
            return {"status": 400, "body": {"message": "Invalid species"}}

        try:
            age_val = int(age)
        except Exception:
            return {"status": 400, "body": {"message": "Invalid ageMonths"}}

        pet = pet_store.create(name, species, age_val)
        
        # Emit event to trigger background job
        if ctx and ctx.emit:
            await ctx.emit({
                "topic": "py.feeding.reminder.enqueued",
                "data": {
                    "petId": pet["id"],
                    "enqueuedAt": int(time.time() * 1000)
                }
            })

        return {"status": 201, "body": pet}
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/create-pet.step.js"
    const { create } = require('./js-store')

    const config = {
      name: 'CreatePet',
      type: 'api',
      path: '/pets',
      method: 'POST',
      emits: ['js.feeding.reminder.enqueued']
    }

    const handler = async (req, { emit }) => {
      const b = req.body || {}
      const name = typeof b.name === 'string' && b.name.trim()
      const speciesOk = ['dog', 'cat', 'bird', 'other'].includes(b.species)
      const ageOk = Number.isFinite(b.ageMonths)

      if (!name || !speciesOk || !ageOk) {
        return { status: 400, body: { message: 'Invalid payload' } }
      }

      const pet = create({ name, species: b.species, ageMonths: Number(b.ageMonths) })

      // Emit event to trigger background job
      if (emit) {
        await emit({
          topic: 'js.feeding.reminder.enqueued',
          data: {
            petId: pet.id,
            enqueuedAt: Date.now()
          }
        })
      }

      return { status: 201, body: pet }
    }

    module.exports = { config, handler }
    ```
  </Tab>
</Tabs>

The API endpoint now emits an event after creating a pet. The response returns immediately while the background job processes asynchronously.

---

### Step 2: Create the Event Step

Now let's create the background job that listens for this event and sets feeding reminders.

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/background-jobs/steps/typescript/set-next-feeding-reminder.job.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/background-jobs/steps/python/set_next_feeding_reminder.job_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/background-jobs/steps/javascript/set-next-feeding-reminder.job.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/set-next-feeding-reminder.job.step.ts"
    import { EventConfig, Handlers } from 'motia'
    import { TSStore } from './ts-store'

    export const config = {
      type: 'event',
      name: 'TsSetNextFeedingReminder',
      description: 'Background job that sets next feeding reminder and adds welcome notes',
      // Subscribe to the event emitted by CreatePet
      subscribes: ['ts.feeding.reminder.enqueued'],
      emits: [],
      flows: ['TsPetManagement']
    }

    export const handler: Handlers['TsSetNextFeedingReminder'] = async (input, { emit, logger }) => {
      const { petId, enqueuedAt } = input

      if (logger) {
        logger.info('ðŸ”„ Setting next feeding reminder', { petId, enqueuedAt })
      }

      try {
        // Calculate next feeding time (24 hours from now)
        const nextFeedingAt = Date.now() + (24 * 60 * 60 * 1000)
        
        // Fill in non-critical details
        const updates = {
          notes: 'Welcome to our pet store! We\'ll take great care of this pet.',
          nextFeedingAt: nextFeedingAt
        }

        const updatedPet = TSStore.update(petId, updates)
        
        if (!updatedPet) {
          if (logger) {
            logger.error('âŒ Failed to set feeding reminder - pet not found', { petId })
          }
          return
        }

        if (logger) {
          logger.info('âœ… Next feeding reminder set', { 
            petId, 
            notes: updatedPet.notes?.substring(0, 50) + '...',
            nextFeedingAt: new Date(nextFeedingAt).toISOString()
          })
        }

        // Feeding reminder scheduled successfully

      } catch (error: any) {
        if (logger) {
          logger.error('âŒ Feeding reminder job error', { petId, error: error.message })
        }
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/set_next_feeding_reminder.job_step.py"
    import sys
    import os
    import time
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
    from services import pet_store

    config = {
        "type": "event",
        "name": "PySetNextFeedingReminder",
        "description": "Background job that sets next feeding reminder and adds welcome notes",
        "subscribes": ["py.feeding.reminder.enqueued"],
        "emits": []
    }

    async def handler(input_data, ctx=None):
        logger = getattr(ctx, 'logger', None) if ctx else None
        emit = getattr(ctx, 'emit', None) if ctx else None
        
        try:
            import sys
            import os
            import time
            sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
            from services import pet_store
        except ImportError:
            if logger:
                logger.error('âŒ Failed to set feeding reminder - import error')
            return

        pet_id = input_data.get('petId')
        enqueued_at = input_data.get('enqueuedAt')

        if logger:
            logger.info('ðŸ”„ Setting next feeding reminder', {'petId': pet_id, 'enqueuedAt': enqueued_at})

        try:
            # Calculate next feeding time (24 hours from now)
            next_feeding_at = int(time.time() * 1000) + (24 * 60 * 60 * 1000)
            
            # Fill in non-critical details
            updates = {
                'notes': 'Welcome to our pet store! We\'ll take great care of this pet.',
                'nextFeedingAt': next_feeding_at
            }

            updated_pet = pet_store.update(pet_id, updates)
            
            if not updated_pet:
                if logger:
                    logger.error('âŒ Failed to set feeding reminder - pet not found', {'petId': pet_id})
                return

            if logger:
                notes_preview = updated_pet.get('notes', '')[:50] + '...' if updated_pet.get('notes') else ''
                logger.info('âœ… Next feeding reminder set', {
                    'petId': pet_id,
                    'notes': notes_preview,
                    'nextFeedingAt': time.strftime('%Y-%m-%dT%H:%M:%S.000Z', time.gmtime(next_feeding_at / 1000))
                })

        except Exception as error:
            if logger:
                logger.error('âŒ Feeding reminder job error', {'petId': pet_id, 'error': str(error)})
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/set-next-feeding-reminder.job.step.js"
    const { update } = require('./js-store')

    const config = {
      type: 'event',
      name: 'JsSetNextFeedingReminder',
      description: 'Background job that sets next feeding reminder and adds welcome notes',
      subscribes: ['js.feeding.reminder.enqueued'],
      emits: []
    }

    const handler = async (input, context) => {
      const { emit, logger } = context || {}
      const { petId, enqueuedAt } = input

      if (logger) {
        logger.info('ðŸ”„ Setting next feeding reminder', { petId, enqueuedAt })
      }

      try {
        // Calculate next feeding time (24 hours from now)
        const nextFeedingAt = Date.now() + (24 * 60 * 60 * 1000)
        
        // Fill in non-critical details
        const updates = {
          notes: 'Welcome to our pet store! We\'ll take great care of this pet.',
          nextFeedingAt: nextFeedingAt
        }

        const updatedPet = update(petId, updates)
        
        if (!updatedPet) {
          if (logger) {
            logger.error('âŒ Failed to set feeding reminder - pet not found', { petId })
          }
          return
        }

        if (logger) {
          logger.info('âœ… Next feeding reminder set', { 
            petId, 
            notes: updatedPet.notes?.substring(0, 50) + '...',
            nextFeedingAt: new Date(nextFeedingAt).toISOString()
          })
        }

      } catch (error) {
        if (logger) {
          logger.error('âŒ Feeding reminder job error', { petId, error: error.message })
        }
      }
    }

    module.exports = { config, handler }
    ```
  </Tab>
</Tabs>

### How Event Steps Work

Event Steps have a few key differences from API Steps:

- **type** is set to `'event'` instead of `'api'`
- **subscribes** lists the events this job listens for
- **handler** receives the event data as the first argument

When you create a pet, the API returns immediately. The background job picks up the event and processes it asynchronously.

---

## Testing Your Background Job

Create a pet and watch the background job execute:

```bash
# Create a pet
curl -X POST http://localhost:3000/pets \
  -H "Content-Type: application/json" \
  -d '{"name": "Max", "species": "dog", "ageMonths": 24}'
```

Check the logs in Workbench to see both the API call and the background job execution:

![background-job-logs](../../img/build-your-first-app/bg-job-logs.png)

You'll see:
1. "Pet created" log from the API endpoint
2. "Setting next feeding reminder" log from the background job
3. "Next feeding reminder set" log when the job completes

---

## Creating a Scheduled Cron Job

Now let's create a cron job that runs daily to clean up soft-deleted pets. This demonstrates how to handle scheduled maintenance tasks.

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/background-jobs/steps/typescript/deletion-reaper.cron.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/background-jobs/steps/python/deletion_reaper.cron_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/background-jobs/steps/javascript/deletion-reaper.cron.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/deletion-reaper.cron.step.ts"
    import { CronConfig, Handlers } from 'motia'
    import { TSStore } from './ts-store'

    export const config: CronConfig = {
      type: 'cron',
      name: 'TsDeletionReaper',
      description: 'Daily job that permanently removes pets scheduled for deletion',
      cron: '0 2 * * *', // Daily at 2:00 AM
      emits: [],
      flows: ['TsPetManagement']
    }

    export const handler: Handlers['TsDeletionReaper'] = async ({ emit, logger }) => {
      if (logger) {
        logger.info('ðŸ”„ Deletion Reaper started - scanning for pets to purge')
      }

      try {
        const petsToReap = TSStore.findDeletedPetsReadyToPurge()
        
        if (petsToReap.length === 0) {
          if (logger) {
            logger.info('âœ… Deletion Reaper completed - no pets to purge')
          }
          
          // No emit - no subscribers for ts.reaper.completed
          return
        }

        let purgedCount = 0
        
        for (const pet of petsToReap) {
          const success = TSStore.remove(pet.id)
          
          if (success) {
            purgedCount++
            
            if (logger) {
              logger.info('ðŸ’€ Pet permanently purged', { 
                petId: pet.id, 
                name: pet.name,
                deletedAt: new Date(pet.deletedAt!).toISOString(),
                purgeAt: new Date(pet.purgeAt!).toISOString()
              })
            }

            // No emit - no subscribers for ts.pet.purged
          } else {
            if (logger) {
              logger.warn('âš ï¸ Failed to purge pet', { petId: pet.id, name: pet.name })
            }
          }
        }

        if (logger) {
          logger.info('âœ… Deletion Reaper completed', { 
            totalScanned: petsToReap.length,
            purgedCount,
            failedCount: petsToReap.length - purgedCount
          })
        }

        // No emit - no subscribers for ts.reaper.completed

      } catch (error: any) {
        if (logger) {
          logger.error('âŒ Deletion Reaper error', { error: error.message })
        }
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/deletion_reaper.cron_step.py"
    import sys
    import os
    import time
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))
    from services import pet_store

    config = {
        "type": "cron",
        "name": "PyDeletionReaper",
        "description": "Daily job that permanently removes pets scheduled for deletion",
        "cron": "0 2 * * *",  # Daily at 2:00 AM
        "emits": [],
        "flows": ["PyPetManagement"]
    }

    async def handler(ctx):
        logger = getattr(ctx, 'logger', None) if ctx else None
        emit = getattr(ctx, 'emit', None) if ctx else None
        
        try:
            import sys
            import os
            import time
            sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
            from services import pet_store
        except ImportError:
            if logger:
                logger.error('âŒ Deletion Reaper failed - import error')
            return

        if logger:
            logger.info('ðŸ”„ Deletion Reaper started - scanning for pets to purge')

        try:
            pets_to_reap = pet_store.find_deleted_pets_ready_to_purge()
            
            if not pets_to_reap:
                if logger:
                    logger.info('âœ… Deletion Reaper completed - no pets to purge')
                
                # No emit - no subscribers for py.reaper.completed
                return

            purged_count = 0
            
            for pet in pets_to_reap:
                success = pet_store.remove(pet['id'])
                
                if success:
                    purged_count += 1
                    
                    if logger:
                        logger.info('ðŸ’€ Pet permanently purged', {
                            'petId': pet['id'],
                            'name': pet['name'],
                            'deletedAt': time.strftime('%Y-%m-%dT%H:%M:%S', time.gmtime(pet['deletedAt'] / 1000)),
                            'purgeAt': time.strftime('%Y-%m-%dT%H:%M:%S', time.gmtime(pet['purgeAt'] / 1000))
                        })

                    # No emit - no subscribers for py.pet.purged
                else:
                    if logger:
                        logger.warn('âš ï¸ Failed to purge pet', {'petId': pet['id'], 'name': pet['name']})

            if logger:
                logger.info('âœ… Deletion Reaper completed', {
                    'totalScanned': len(pets_to_reap),
                    'purgedCount': purged_count,
                    'failedCount': len(pets_to_reap) - purged_count
                })

            # No emit - no subscribers for py.reaper.completed

        except Exception as error:
            if logger:
                logger.error('âŒ Deletion Reaper error', {'error': str(error)})
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/deletion-reaper.cron.step.js"
    const { findDeletedPetsReadyToPurge, remove } = require('./js-store')

    const config = {
      type: 'cron',
      name: 'JsDeletionReaper',
      description: 'Daily job that permanently removes pets scheduled for deletion',
      cron: '0 2 * * *', // Daily at 2:00 AM
      emits: [],
      flows: ['JsPetManagement']
    }

    const handler = async ({ emit, logger }) => {
      if (logger) {
        logger.info('ðŸ”„ Deletion Reaper started - scanning for pets to purge')
      }

      try {
        const petsToReap = findDeletedPetsReadyToPurge()
        
        if (petsToReap.length === 0) {
          if (logger) {
            logger.info('âœ… Deletion Reaper completed - no pets to purge')
          }
          
          // No emit - no subscribers for js.reaper.completed
          return
        }

        let purgedCount = 0
        
        for (const pet of petsToReap) {
          const success = remove(pet.id)
          
          if (success) {
            purgedCount++
            
            if (logger) {
              logger.info('ðŸ’€ Pet permanently purged', { 
                petId: pet.id, 
                name: pet.name,
                deletedAt: new Date(pet.deletedAt).toISOString(),
                purgeAt: new Date(pet.purgeAt).toISOString()
              })
            }

            // No emit - no subscribers for js.pet.purged
          } else {
            if (logger) {
              logger.warn('âš ï¸ Failed to purge pet', { petId: pet.id, name: pet.name })
            }
          }
        }

        if (logger) {
          logger.info('âœ… Deletion Reaper completed', { 
            totalScanned: petsToReap.length,
            purgedCount,
            failedCount: petsToReap.length - purgedCount
          })
        }

        // No emit - no subscribers for js.reaper.completed

      } catch (error) {
        if (logger) {
          logger.error('âŒ Deletion Reaper error', { error: error.message })
        }
      }
    }

    module.exports = { config, handler }
    ```
  </Tab>
</Tabs>

### Understanding Cron Steps

Cron Steps run on a schedule defined by a cron expression:

- **type** is set to `'cron'`
- **cron** defines when the job runs (e.g., `'0 2 * * *'` = daily at 2 AM)
- **handler** receives only the context (no input data like Event Steps)

Common cron patterns:
- `'*/5 * * * *'` - Every 5 minutes
- `'0 * * * *'` - Every hour
- `'0 0 * * *'` - Daily at midnight
- `'0 9 * * 1'` - Every Monday at 9 AM

---

## Monitoring Background Jobs

Workbench provides tools to monitor your background jobs:

### Tracing

See the complete execution flow from API call to background job:

![tracing](../../img/build-your-first-app/bg-job-tracing.png)

Each trace shows:
- When the API endpoint was called
- When events were emitted
- When background jobs started and completed
- Total processing time

---

ðŸŽ‰ **Congratulations!** You've successfully created background jobs with Motia. Your pet store now handles async tasks efficiently without blocking API responses.

---
## What's Next?

You now have a complete backend system with API endpoints and background jobs! But there's more power in Motia when you combine everything into workflows.

In the next guide, we'll build complete **workflow orchestrations** that connect multiple Steps together:

- **Queue-Based Job Processing** - SetNextFeedingReminder triggered by pet creation, processing asynchronously without blocking API responses
- **Scheduled Maintenance Tasks** - Deletion Reaper running daily at 2 AM to permanently remove soft-deleted pets past their purge date
- **Pet Lifecycle Orchestration** - Staff-driven workflow managing pet status transitions from creation through quarantine, health checks, and adoption
- **Event-Driven State Management** - Centralized orchestrator ensuring consistent pet status changes with automatic progressions and staff decision points

Let's continue building by creating workflows that orchestrate your APIs and background jobs into powerful, event-driven systems.


-   [index](/docs/getting-started/build-your-first-motia-app): Documentation for index.
---
title: Build Your First Motia App
description: Learn Motia step-by-step by building a real pet store backend
---

## What You'll Build

A complete pet store backend system that grows with you:

- **API Endpoints** â†’ Handle requests, return responses
- **Background Jobs** â†’ Process tasks without blocking APIs
- **Workflows** â†’ Coordinate complex business logic automatically
- **AI Agents** â†’ Make intelligent decisions that drive your workflows
- **Real-Time Streaming** â†’ Push live updates to clients as workflows execute

By the end, you'll have a production-ready backend that handles everything from simple CRUD to intelligent, real-time systems.

![workbench](../../img/build-your-first-app/streaming-workbench.png)
---

## Before You Start

You'll need:
- Node.js installed (v18 or higher)
- Basic understanding of TypeScript/JavaScript/Python
- 10-20 minutes per tutorial

That's it. No database setup, no complex config, no separate services to run.

---

## Your Journey

### 1. API Endpoints

**What:** Create HTTP endpoints that handle pet operations.

**You'll learn:**
- How to define API Steps
- Request validation with schemas
- Returning proper HTTP responses
- Testing endpoints in Workbench

**Time:** 10 minutes

<Card href="/docs/getting-started/build-your-first-motia-app/api-endpoints" title="Start with APIs â†’">
  Build your first HTTP endpoints
</Card>

---

### 2. Background Jobs

**What:** Add async tasks that run without blocking your APIs.

**You'll learn:**
- Event Steps that trigger from your APIs
- Cron Steps that run on a schedule
- How events connect your system
- Monitoring jobs in Workbench

**Time:** 15 minutes

<Card href="/docs/getting-started/build-your-first-motia-app/background-jobs" title="Add Background Jobs â†’">
  Handle async tasks efficiently
</Card>

---

### 3. Workflows

**What:** Coordinate complex processes with automatic transitions and validation.

**You'll learn:**
- Building workflow orchestrators
- Automatic vs manual transitions
- State validation and progression
- Chaining multiple actions together

**Time:** 20 minutes

<Card href="/docs/getting-started/build-your-first-motia-app/workflows" title="Build Workflows â†’">
  Orchestrate complex business logic
</Card>

---

### 4. AI Agents

**What:** Add intelligent decision-making to your workflows.

**You'll learn:**
- Content generation with AI
- Decision-making agents
- Integrating AI with workflows
- Building agentic routing

**Time:** 20 minutes

<Card href="/docs/getting-started/build-your-first-motia-app/ai-agents" title="Add AI Agents â†’">
  Make your backend intelligent
</Card>

---

### 5. Real-Time Streaming

**What:** Push live updates to clients while your workflows run in the background.

**You'll learn:**
- Defining stream configurations
- Streaming from APIs that return immediately
- Background jobs that push progress updates
- AI agents that stream enrichment progress
- Connecting multiple steps to the same stream

**Time:** 20 minutes

<Card href="/docs/getting-started/build-your-first-motia-app/streaming-agents" title="Add Streaming â†’">
  Build real-time experiences
</Card>

---

## The Example Project

All tutorials use the same project - a pet store backend that handles:

- **Pet management** â†’ Create, update, list pets
- **Adoption workflow** â†’ Guide pets through quarantine, health checks, and availability
- **Feeding reminders** â†’ Set up schedules when pets arrive
- **Health decisions** â†’ AI evaluates symptoms and recommends treatment
- **Cleanup jobs** â†’ Remove soft-deleted pets on a schedule
- **Real-time updates** â†’ Stream progress to clients as workflows execute

It's a real system with the kind of complexity you'll face building production backends.

---

## Interactive Tutorials

![interactive-tutorial](../../img/build-your-first-app/interactive-tutorial-streaming.png)

Each guide includes an **interactive tutorial** you can run directly in Workbench. It walks you through the code, explains what's happening, and lets you test everything live.

Prefer reading? The written guides cover everything too. They're detailed, with code examples and explanations for every concept.

---

## Ready?

Pick your starting point. If you're new to Motia, start with API Endpoints. If you've already covered the basics, jump to wherever you want to learn more.

<Cards>
  <Card href="/docs/getting-started/build-your-first-motia-app/api-endpoints" title="API Endpoints">
    Start here if you're new
  </Card>
  <Card href="/docs/getting-started/build-your-first-motia-app/background-jobs" title="Background Jobs">
    Add async processing
  </Card>
  <Card href="/docs/getting-started/build-your-first-motia-app/workflows" title="Workflows">
    Coordinate complex logic
  </Card>
  <Card href="/docs/getting-started/build-your-first-motia-app/ai-agents" title="AI Agents">
    Build intelligent systems
  </Card>
  <Card href="/docs/getting-started/build-your-first-motia-app/streaming-agents" title="Real-Time Streaming">
    Push live updates
  </Card>
</Cards>



-   [streaming-agents](/docs/getting-started/build-your-first-motia-app/streaming-agents): Documentation for streaming-agents.
---
title: Real-Time Streaming
description: Learn how to add real-time streaming updates to your Motia workflows
---

## What You'll Build

A pet management system with real-time streaming that provides live updates to clients:

- **Stream Configuration** - Define stream schemas for type-safe updates
- **API with Streaming** - APIs that initialize streams and return immediately
- **Background Job Streaming** - Jobs that push real-time progress updates
- **Agentic Step Streaming** - AI enrichment with live progress updates
- **Multi-Step Streaming** - Multiple steps updating the same stream

![workbench](../../img/build-your-first-app/streaming-workbench.png)
---

## Getting Started

Clone the example repository:

```bash
git clone https://github.com/MotiaDev/build-your-first-app.git
cd build-your-first-app
git checkout stream-ai-agents
```

Install dependencies:

```bash
npm install
```

Set up your OpenAI API key in `.env`:

```bash
OPENAI_API_KEY=your_api_key_here
```

Start the Workbench:

```bash
npm run dev
```

Your Workbench will be available at `http://localhost:3000`.

---

## Project Structure

<Folder name="my-pet-api" defaultOpen>
  <Folder name="steps" defaultOpen>
    <Folder name="typescript">
      <File name="create-pet.step.ts" />
      <File name="pet-creation.stream.ts" />
      <File name="set-next-feeding-reminder.job.step.ts" />
      <File name="ai-profile-enrichment.step.ts" />
      <File name="health-review-agent.step.ts" />
      <File name="pet-lifecycle-orchestrator.step.ts" />
      <File name="ts-store.ts" />
    </Folder>
    <Folder name="javascript">
      <File name="create-pet.step.js" />
      <File name="pet-creation.stream.js" />
      <File name="set-next-feeding-reminder.job.step.js" />
      <File name="ai-profile-enrichment.step.js" />
      <File name="health-review-agent.step.js" />
      <File name="pet-lifecycle-orchestrator.step.js" />
      <File name="js-store.js" />
    </Folder>
    <Folder name="python">
      <File name="create_pet_step.py" />
      <File name="pet_creation.stream.py" />
      <File name="set_next_feeding_reminder.job_step.py" />
      <File name="ai_profile_enrichment_step.py" />
      <File name="health_review_agent_step.py" />
      <File name="pet_lifecycle_orchestrator_step.py" />
    </Folder>
  </Folder>
  <Folder name="services">
    <File name="pet_store.py" />
    <File name="types.py" />
  </Folder>
  <File name=".env" />
  <File name="package.json" />
  <File name="requirements.txt" />
  <File name="types.d.ts" />
</Folder>

<Callout type="info">
Files like `features.json` and `tutorial/tutorial.tsx` are only for the interactive tutorial and are not part of Motia's project structure.
</Callout>

All code examples in this guide are available in the [build-your-first-app](https://github.com/MotiaDev/build-your-first-app/tree/main) repository.

You can follow this guide to learn how to build real-time streaming with Motia step by step, or you can clone the repository and dive into our Interactive Tutorial to learn by doing directly in the Workbench.

![interactive-tutorial](../../img/build-your-first-app/interactive-tutorial-streaming.png)

---

## Understanding Real-Time Streaming

You've built APIs that return immediately, background jobs that process asynchronously, workflows that orchestrate complex logic, and agentic workflows that make intelligent decisions. But how do you give users real-time feedback while all this async processing happens in the background?

That's where **streaming** comes in. Motia provides streams as part of the context in any step handler - you can use them anywhere in your code. Streams use Server-Sent Events (SSE) to push live updates directly to clients as your workflow progresses.

In our pet shelter example:
- The API initializes a stream and returns immediately with a stream ID
- Background jobs push updates as they process (quarantine entry, health checks)
- Agentic steps stream enrichment progress (bio generation, breed analysis)
- Clients get live feedback throughout the entire workflow

The power is in the simplicity - `streams` is available in your handler's context, just like `emit`, `logger`, and `state`. Any step can update any stream, creating a unified real-time experience without complex orchestration.

---

## Creating Your First Stream

### Step 1: Define the Stream Configuration

First, define a stream configuration file. This makes the stream available in the `context.streams` object for all your step handlers.

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/typescript/pet-creation.stream.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/python/pet_creation.stream.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/javascript/pet-creation.stream.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/pet-creation.stream.ts"
    import { StreamConfig } from 'motia'
    import { z } from 'zod'

    export const config: StreamConfig = {
      /**
       * This will be available as context.streams.petCreation in the FlowContext
       */
      name: 'petCreation',
      
      /**
       * Schema defines the structure of stream updates
       */
      schema: z.object({ 
        message: z.string()
      }),

      /**
       * Use default storage for the stream
       */
      baseConfig: {
        storageType: 'default',
      },
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/pet_creation.stream.py"
    config = {
        "name": "petCreation",
        "schema": {
            "type": "object",
            "properties": {
                "message": {"type": "string"}
            },
            "required": ["message"]
        },
        "baseConfig": {
            "storageType": "default"
        }
    }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/pet-creation.stream.js"
    const { z } = require('zod')

    const config = {
      name: 'petCreation',
      
      schema: z.object({ 
        message: z.string()
      }),

      baseConfig: {
        storageType: 'default',
      },
    }

    module.exports = { config }
    ```
  </Tab>
</Tabs>

### How Stream Configuration Works

Stream configuration is simple:

- **name** - Identifier for accessing the stream (e.g., `context.streams.petCreation`)
- **schema** - Zod schema defining what data can be pushed to the stream
- **baseConfig** - Storage settings (default uses in-memory storage)

Once you create this configuration file, the stream is automatically available as `streams.petCreation` in the context of any step handler. It's just like `emit`, `logger`, or `state` - part of the tools available in your handler.

---

## Step 2: Initialize Streams from APIs

Now let's update the pet creation API to initialize a stream and return it immediately to the client.

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/typescript/create-pet.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/python/create_pet_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/javascript/create-pet.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/create-pet.step.ts"
    // steps/typescript/create-pet.step.ts
    import { ApiRouteConfig, Handlers } from 'motia';
    import { z } from 'zod';
    import { TSStore } from './ts-store';

    const createPetSchema = z.object({
      name: z.string().min(1, 'Name is required').trim(),
      species: z.enum(['dog', 'cat', 'bird', 'other']),
      ageMonths: z.number().int().min(0, 'Age must be a positive number'),
      weightKg: z.number().positive().optional(),
      symptoms: z.array(z.string()).optional()
    });

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'TsCreatePet',
      path: '/ts/pets',
      method: 'POST',
      emits: ['ts.pet.created', 'ts.feeding.reminder.enqueued'],
      flows: ['TsPetManagement']
    };

    export const handler: Handlers['TsCreatePet'] = async (req, { emit, logger, streams, traceId }) => {
      try {
        const validatedData = createPetSchema.parse(req.body);

        const pet = TSStore.create({
          name: validatedData.name,
          species: validatedData.species,
          ageMonths: validatedData.ageMonths,
          weightKg: validatedData.weightKg,
          symptoms: validatedData.symptoms
        });

        if (logger) {
          logger.info('ðŸ¾ Pet created', { petId: pet.id, name: pet.name, species: pet.species, status: pet.status });
        }

        // Create & return the initial stream record (following working pattern)
        const result = await streams.petCreation.set(traceId, 'message', { 
          message: `Pet ${pet.name} (ID: ${pet.id}) created successfully - Species: ${pet.species}, Age: ${pet.ageMonths} months, Status: ${pet.status}` 
        });

        if (emit) {
          await emit({
            topic: 'ts.pet.created',
            data: { petId: pet.id, event: 'pet.created', name: pet.name, species: validatedData.species, traceId }
          } as any);

          await emit({
            topic: 'ts.feeding.reminder.enqueued',
            data: { petId: pet.id, enqueuedAt: Date.now(), traceId }
          } as any);
        }

        return { 
          status: 201, 
          body: result 
        };

      } catch (error) {
        if (error instanceof z.ZodError) {
          return {
            status: 400,
            body: {
              message: 'Validation error',
              errors: error.errors
            }
          };
        }

        return {
          status: 500,
          body: { message: 'Internal server error' }
        };
      }
    };
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/create_pet_step.py"
    import asyncio

    config = {
        "type": "api",
        "name": "PyCreatePet",
        "path": "/py/pets",
        "method": "POST",
        "emits": ["py.pet.created", "py.feeding.reminder.enqueued"],
        "flows": ["PyPetManagement"]
    }

    async def handler(req, ctx=None):
        logger = getattr(ctx, 'logger', None) if ctx else None
        emit = getattr(ctx, 'emit', None) if ctx else None
        streams = getattr(ctx, 'streams', None) if ctx else None
        trace_id = getattr(ctx, 'traceId', None) if ctx else None
        
        try:
            import sys
            import os
            import time
            sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
            from services import pet_store
        except ImportError:
            # Fallback for import issues
            return {"status": 500, "body": {"message": "Import error"}}
        
        b = (req.get("body") or {})
        name = b.get("name")
        species = b.get("species")
        age = b.get("ageMonths")
        weight_kg = b.get("weightKg")
        symptoms = b.get("symptoms")
        
        if not isinstance(name, str) or not name.strip():
            return {"status": 400, "body": {"message": "Invalid name"}}
        if species not in ["dog","cat","bird","other"]:
            return {"status": 400, "body": {"message": "Invalid species"}}
        try:
            age_val = int(age)
        except Exception:
            return {"status": 400, "body": {"message": "Invalid ageMonths"}}
        
        # Create the pet
        pet = pet_store.create(name, species, age_val, weight_kg=weight_kg, symptoms=symptoms)
        
        if logger:
            logger.info('ðŸ¾ Pet created', {
                'petId': pet['id'], 
                'name': pet['name'], 
                'species': pet['species'], 
                'status': pet['status']
            })

        # Create & return the initial stream record (following working pattern)
        result = await streams.petCreation.set(trace_id, 'message', { 
            'message': f"Pet {pet['name']} (ID: {pet['id']}) created successfully - Species: {pet['species']}, Age: {pet['ageMonths']} months, Status: {pet['status']}"
        })
        
        if emit:
            await emit({
                'topic': 'py.pet.created',
                'data': {'petId': pet['id'], 'event': 'pet.created', 'name': pet['name'], 'species': pet['species'], 'traceId': trace_id}
            })
            
            # Enqueue feeding reminder background job
            await emit({
                'topic': 'py.feeding.reminder.enqueued',
                'data': {'petId': pet['id'], 'enqueuedAt': int(time.time() * 1000), 'traceId': trace_id}
            })
        
        # Return the stream result so it can be tracked in Workbench
        return {
            "status": 201,
            "body": result
        }
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/create-pet.step.js"
    const { create } = require('./js-store')

    exports.config = {
      type: 'api',
      name: 'JsCreatePet',
      path: '/js/pets',
      method: 'POST',
      emits: ['js.pet.created', 'js.feeding.reminder.enqueued'],
      flows: ['JsPetManagement']
    }

    exports.handler = async (req, context) => {
      const { emit, logger, streams, traceId } = context || {}
      const b = req.body || {}
      const name = typeof b.name === 'string' && b.name.trim()
      const speciesOk = ['dog','cat','bird','other'].includes(b.species)
      const ageOk = Number.isFinite(b.ageMonths)
      
      if (!name || !speciesOk || !ageOk) {
        return { status: 400, body: { message: 'Invalid payload: {name, species, ageMonths}' } }
      }

      // Create the pet
      const pet = create({ 
        name, 
        species: b.species, 
        ageMonths: Number(b.ageMonths),
        weightKg: typeof b.weightKg === 'number' ? b.weightKg : undefined,
        symptoms: Array.isArray(b.symptoms) ? b.symptoms : undefined
      })
      
      if (logger) {
        logger.info('ðŸ¾ Pet created', { petId: pet.id, name: pet.name, species: pet.species, status: pet.status })
      }

      // Create & return the initial stream record (following working pattern)
      const result = await streams.petCreation.set(traceId, 'message', { 
        message: `Pet ${pet.name} (ID: ${pet.id}) created successfully - Species: ${pet.species}, Age: ${pet.ageMonths} months, Status: ${pet.status}` 
      })

      if (emit) {
        await emit({
          topic: 'js.pet.created',
          data: { petId: pet.id, event: 'pet.created', name: pet.name, species: pet.species, traceId }
        })
        
        // Enqueue feeding reminder background job
        await emit({
          topic: 'js.feeding.reminder.enqueued',
          data: { petId: pet.id, enqueuedAt: Date.now(), traceId }
        })
      }

      return { 
        status: 201, 
        body: result 
      }
    }
    ```
  </Tab>
</Tabs>

### How API Stream Initialization Works

The key changes from a regular API:

1. **Access streams from context** - `streams` is available in the FlowContext
2. **Create initial stream message** - `await streams.petCreation.set(traceId, 'message', data)`
3. **Return the stream result** - Contains stream ID and initial message
4. **Background jobs update the same stream** - Using the same traceId

The API returns immediately with a stream ID. Clients can connect to this stream via SSE to receive real-time updates as background jobs process.

---

## Step 3: Stream Updates from Background Jobs

Now let's update the feeding reminder job to push real-time updates to the stream as it processes.

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/typescript/set-next-feeding-reminder.job.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/python/set_next_feeding_reminder.job_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/javascript/set-next-feeding-reminder.job.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/set-next-feeding-reminder.job.step.ts"
    // steps/typescript/set-next-feeding-reminder.job.step.ts
    import { EventConfig, Handlers } from 'motia';
    import { TSStore } from './ts-store';

    export const config = {
      type: 'event',
      name: 'TsSetNextFeedingReminder',
      description: 'Background job that sets next feeding reminder and adds welcome notes',
      subscribes: ['ts.feeding.reminder.enqueued'],
      emits: ['ts.feeding.reminder.completed'],
      flows: ['TsPetManagement']
    };

    export const handler: Handlers['TsSetNextFeedingReminder'] = async (input, { emit, logger, streams, traceId }) => {
      const { petId, enqueuedAt } = input;

      if (logger) {
        logger.info('ðŸ”„ Setting next feeding reminder', { petId, enqueuedAt });
      }

      try {
        // Calculate next feeding time (24 hours from now)
        const nextFeedingAt = Date.now() + (24 * 60 * 60 * 1000);
        
        // Fill in non-critical details and change status to in_quarantine
        const updates = {
          notes: 'Welcome to our pet store! We\'ll take great care of this pet.',
          nextFeedingAt: nextFeedingAt,
          status: 'in_quarantine' as const
        };

        const updatedPet = TSStore.update(petId, updates);
        
        if (!updatedPet) {
          if (logger) {
            logger.error('âŒ Failed to set feeding reminder - pet not found', { petId });
          }
          return;
        }

        if (logger) {
          logger.info('âœ… Next feeding reminder set', { 
            petId, 
            notes: updatedPet.notes?.substring(0, 50) + '...',
            nextFeedingAt: new Date(nextFeedingAt).toISOString()
          });
        }

        // Stream status updates using the simple pattern
        if (streams?.petCreation && traceId) {
          await streams.petCreation.set(traceId, 'message', { 
            message: `Pet ${updatedPet.name} entered quarantine period` 
          });

          // Check symptoms and stream appropriate updates
          if (!updatedPet.symptoms || updatedPet.symptoms.length === 0) {
            await new Promise(resolve => setTimeout(resolve, 1000));
            await streams.petCreation.set(traceId, 'message', { 
              message: `Health check passed for ${updatedPet.name} - no symptoms found` 
            });

            await new Promise(resolve => setTimeout(resolve, 1000));
            await streams.petCreation.set(traceId, 'message', { 
              message: `${updatedPet.name} is healthy and ready for adoption! âœ…` 
            });
          } else {
            await new Promise(resolve => setTimeout(resolve, 1000));
            await streams.petCreation.set(traceId, 'message', { 
              message: `Health check failed for ${updatedPet.name} - symptoms detected: ${updatedPet.symptoms.join(', ')}` 
            });

            await new Promise(resolve => setTimeout(resolve, 1000));
            await streams.petCreation.set(traceId, 'message', { 
              message: `${updatedPet.name} needs medical treatment âŒ` 
            });
          }
        }

        if (emit) {
          (emit as any)({
            topic: 'ts.feeding.reminder.completed',
            data: { 
              petId, 
              event: 'feeding.reminder.completed',
              completedAt: Date.now(),
              processingTimeMs: Date.now() - enqueuedAt
            }
          });
        }

      } catch (error: any) {
        if (logger) {
          logger.error('âŒ Feeding reminder job error', { petId, error: error.message });
        }
      }
    };
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/set_next_feeding_reminder.job_step.py"
    import asyncio

    config = {
        "type": "event",
        "name": "PySetNextFeedingReminder",
        "description": "Sets the next feeding reminder for a pet and updates its status",
        "subscribes": ["py.feeding.reminder.enqueued"],
        "emits": ["py.feeding.reminder.completed"],
        "flows": ["PyPetManagement"]
    }

    async def handler(input_data, ctx=None):
        logger = getattr(ctx, 'logger', None) if ctx else None
        emit = getattr(ctx, 'emit', None) if ctx else None
        streams = getattr(ctx, 'streams', None) if ctx else None
        trace_id = getattr(ctx, 'traceId', None) if ctx else None
        
        try:
            import sys
            import os
            import time
            sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
            from services import pet_store
        except ImportError:
            if logger:
                logger.error('âŒ Failed to set feeding reminder - import error')
            return

        pet_id = input_data.get('petId')
        enqueued_at = input_data.get('enqueuedAt')

        if logger:
            logger.info('ðŸ”„ Setting next feeding reminder', {'petId': pet_id, 'enqueuedAt': enqueued_at})

        try:
            # Calculate next feeding time (24 hours from now)
            next_feeding_at = int(time.time() * 1000) + (24 * 60 * 60 * 1000)
            
            # Fill in non-critical details
            updates = {
                'notes': 'Welcome to our pet store! We\'ll take great care of this pet.',
                'nextFeedingAt': next_feeding_at,
                'status': 'in_quarantine'  # Set status to in_quarantine here
            }

            updated_pet = pet_store.update(pet_id, updates)
            
            if not updated_pet:
                if logger:
                    logger.error('âŒ Failed to set feeding reminder - pet not found', {'petId': pet_id})
                return

            if logger:
                notes_preview = updated_pet.get('notes', '')[:50] + '...' if updated_pet.get('notes') else ''
                logger.info('âœ… Next feeding reminder set', {
                    'petId': pet_id,
                    'notes': notes_preview,
                    'nextFeedingAt': time.strftime('%Y-%m-%dT%H:%M:%S.000Z', time.gmtime(next_feeding_at / 1000))
                })

            # Stream status updates using the simple pattern
            if streams and streams.petCreation and trace_id:
                await streams.petCreation.set(trace_id, 'message', { 
                    'message': f"Pet {updated_pet['name']} entered quarantine period" 
                })

                # Check symptoms and stream appropriate updates
                if not updated_pet.get('symptoms') or len(updated_pet['symptoms']) == 0:
                    await asyncio.sleep(1.0)
                    await streams.petCreation.set(trace_id, 'message', { 
                        'message': f"Health check passed for {updated_pet['name']} - no symptoms found" 
                    })

                    await asyncio.sleep(1.0)
                    await streams.petCreation.set(trace_id, 'message', { 
                        'message': f"{updated_pet['name']} is healthy and ready for adoption! âœ…" 
                    })
                else:
                    await asyncio.sleep(1.0)
                    await streams.petCreation.set(trace_id, 'message', { 
                        'message': f"Health check failed for {updated_pet['name']} - symptoms detected: {', '.join(updated_pet['symptoms'])}" 
                    })

                    await asyncio.sleep(1.0)
                    await streams.petCreation.set(trace_id, 'message', { 
                        'message': f"{updated_pet['name']} needs medical treatment âŒ" 
                    })

            if emit:
                await emit({
                    'topic': 'py.feeding.reminder.completed',
                    'data': {
                        'petId': pet_id,
                        'event': 'feeding.reminder.completed',
                        'completedAt': int(time.time() * 1000),
                        'processingTimeMs': int(time.time() * 1000) - enqueued_at
                    }
                })

        except Exception as error:
            if logger:
                logger.error('âŒ Feeding reminder job error', {'petId': pet_id, 'error': str(error)})
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/set-next-feeding-reminder.job.step.js"
    const { update } = require('./js-store')

    exports.config = {
      type: 'event',
      name: 'JsSetNextFeedingReminder',
      description: 'Sets the next feeding reminder for a pet and updates its status',
      subscribes: ['js.feeding.reminder.enqueued'],
      emits: ['js.feeding.reminder.completed'],
      flows: ['JsPetManagement']
    }

    exports.handler = async (input, context) => {
      const { emit, logger, streams, traceId } = context || {}
      const { petId, enqueuedAt } = input

      if (logger) {
        logger.info('ðŸ”„ Setting next feeding reminder', { petId, enqueuedAt })
      }

      try {
        // Calculate next feeding time (24 hours from now)
        const nextFeedingAt = Date.now() + (24 * 60 * 60 * 1000)
        
        // Fill in non-critical details
        const updates = {
          notes: 'Welcome to our pet store! We\'ll take great care of this pet.',
          nextFeedingAt: nextFeedingAt,
          status: 'in_quarantine' // Set status to in_quarantine here
        }

        const updatedPet = update(petId, updates)
        
        if (!updatedPet) {
          if (logger) {
            logger.error('âŒ Failed to set feeding reminder - pet not found', { petId })
          }
          return
        }

        if (logger) {
          logger.info('âœ… Next feeding reminder set', { 
            petId, 
            notes: updatedPet.notes?.substring(0, 50) + '...',
            nextFeedingAt: new Date(nextFeedingAt).toISOString()
          })
        }

        // Stream status updates using the simple pattern
        if (streams?.petCreation && traceId) {
          await streams.petCreation.set(traceId, 'message', { 
            message: `Pet ${updatedPet.name} entered quarantine period` 
          })

          // Check symptoms and stream appropriate updates
          if (!updatedPet.symptoms || updatedPet.symptoms.length === 0) {
            await new Promise(resolve => setTimeout(resolve, 1000))
            await streams.petCreation.set(traceId, 'message', { 
              message: `Health check passed for ${updatedPet.name} - no symptoms found` 
            })

            await new Promise(resolve => setTimeout(resolve, 1000))
            await streams.petCreation.set(traceId, 'message', { 
              message: `${updatedPet.name} is healthy and ready for adoption! âœ…` 
            })
          } else {
            await new Promise(resolve => setTimeout(resolve, 1000))
            await streams.petCreation.set(traceId, 'message', { 
              message: `Health check failed for ${updatedPet.name} - symptoms detected: ${updatedPet.symptoms.join(', ')}` 
            })

            await new Promise(resolve => setTimeout(resolve, 1000))
            await streams.petCreation.set(traceId, 'message', { 
              message: `${updatedPet.name} needs medical treatment âŒ` 
            })
          }
        }

        if (emit) {
          await emit({
            topic: 'js.feeding.reminder.completed',
            data: { 
              petId, 
              event: 'feeding.reminder.completed',
              completedAt: Date.now(),
              processingTimeMs: Date.now() - enqueuedAt
            }
          })
        }

      } catch (error) {
        if (logger) {
          logger.error('âŒ Feeding reminder job error', { petId, error: error.message })
        }
      }
    }
    ```
  </Tab>
</Tabs>

### How Background Job Streaming Works

Background jobs can push multiple updates to a stream:

- **Access the stream** - `streams.petCreation` is available in context
- **Push updates** - `await streams.petCreation.set(traceId, 'message', data)`
- **Use the same traceId** - Links updates to the original API request
- **Send multiple updates** - Each `set()` call sends immediately to connected clients

The background job processes asynchronously, pushing updates at each stage. Clients connected to the stream receive these updates in real-time via SSE.

---

## Step 4: Agentic Step Streaming

Agentic steps can also stream progress updates as they generate content. This provides live feedback during potentially long-running AI operations.

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/typescript/ai-profile-enrichment.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/python/ai_profile_enrichment_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/main/steps/javascript/ai-profile-enrichment.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/ai-profile-enrichment.step.ts"
    // steps/typescript/ai-profile-enrichment.step.ts
    import { EventConfig, Handlers } from 'motia';
    import { TSStore, PetProfile } from './ts-store';

    export const config = {
      type: 'event',
      name: 'TsAiProfileEnrichment',
      description: 'Agentic step that enriches pet profiles using OpenAI',
      subscribes: ['ts.pet.created'],
      emits: [],
      flows: ['TsPetManagement']
    };

    export const handler: Handlers['TsAiProfileEnrichment'] = async (input, { logger, streams, traceId }) => {
      const { petId, name, species } = input;

      if (logger) {
        logger.info('ðŸ¤– AI Profile Enrichment started', { petId, name, species });
      }

      // Stream enrichment started event
      if (streams && traceId) {
        await (streams as any).petCreation.set(traceId, 'enrichment_started', { 
          message: `AI enrichment started for ${name}`
        } as any);
      }

      try {
        const apiKey = process.env.OPENAI_API_KEY;
        if (!apiKey) {
          throw new Error('OPENAI_API_KEY environment variable is not set');
        }

        const prompt = `Generate a pet profile for adoption purposes. Pet details:
- Name: ${name}
- Species: ${species}

Please provide a JSON response with these fields:
- bio: A warm, engaging 2-3 sentence description that would appeal to potential adopters
- breedGuess: Your best guess at the breed or breed mix (be specific but realistic)
- temperamentTags: An array of 3-5 personality traits (e.g., "friendly", "energetic", "calm")
- adopterHints: Practical advice for potential adopters (family type, living situation, care needs)

Keep it positive, realistic, and adoption-focused.`;

        const enrichmentFields = ['bio', 'breedGuess', 'temperamentTags', 'adopterHints'];
        const enrichedProfile: any = {};

        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'gpt-3.5-turbo',
            messages: [
              {
                role: 'system',
                content: 'You are a pet adoption specialist who creates compelling, accurate pet profiles. Always respond with valid JSON only.'
              },
              {
                role: 'user',
                content: prompt
              }
            ],
            max_tokens: 500,
            temperature: 0.7,
          }),
        });

        if (!response.ok) {
          throw new Error(`OpenAI API error: ${response.status} ${response.statusText}`);
        }

        const data = await response.json();
        const aiResponse = data.choices[0]?.message?.content;

        if (!aiResponse) {
          throw new Error('No response from OpenAI API');
        }

        let profile: PetProfile;
        try {
          profile = JSON.parse(aiResponse);
        } catch (parseError) {
          profile = {
            bio: `${name} is a wonderful ${species} looking for a loving home. This pet has a unique personality and would make a great companion.`,
            breedGuess: species === 'dog' ? 'Mixed Breed' : species === 'cat' ? 'Domestic Shorthair' : 'Mixed Breed',
            temperamentTags: ['friendly', 'loving', 'loyal'],
            adopterHints: `${name} would do well in a caring home with patience and love.`
          };
          
          if (logger) {
            logger.warn('âš ï¸ AI response parsing failed, using fallback profile', { petId, parseError: parseError instanceof Error ? parseError.message : String(parseError) });
          }
        }

        const updatedPet = TSStore.updateProfile(petId, profile);
        
        if (!updatedPet) {
          throw new Error(`Pet not found: ${petId}`);
        }

        if (logger) {
          logger.info('âœ… AI Profile Enrichment completed', { 
            petId, 
            profile: {
              bio: profile.bio.substring(0, 50) + '...',
              breedGuess: profile.breedGuess,
              temperamentTags: profile.temperamentTags,
              adopterHints: profile.adopterHints.substring(0, 50) + '...'
            }
          });
        }

        // Stream each field as it's processed
        for (const field of enrichmentFields) {
          await new Promise(resolve => setTimeout(resolve, 300));
          
          const value = profile[field as keyof PetProfile];
          
          if (streams && traceId) {
            await (streams as any).petCreation.set(traceId, `progress_${field}`, { 
              message: `Generated ${field} for ${name}`
            } as any);
          }
        }

        // Stream enrichment completed event
        if (streams && traceId) {
          await (streams as any).petCreation.set(traceId, 'completed', { 
            message: `AI enrichment completed for ${name}`
          } as any);
        }

      } catch (error: any) {
        if (logger) {
          logger.error('âŒ AI Profile Enrichment failed', { 
            petId, 
            error: error.message 
          });
        }

        const fallbackProfile: PetProfile = {
          bio: `${name} is a lovely ${species} with a unique personality, ready to find their forever home.`,
          breedGuess: species === 'dog' ? 'Mixed Breed' : species === 'cat' ? 'Domestic Shorthair' : 'Mixed Breed',
          temperamentTags: ['friendly', 'adaptable'],
          adopterHints: `${name} is looking for a patient and loving family.`
        };

        TSStore.updateProfile(petId, fallbackProfile);

        // Stream fallback profile completion
        if (streams && traceId) {
          await (streams as any).petCreation.set(traceId, 'completed', { 
            message: `AI enrichment completed with fallback profile for ${name}`
          } as any);
        }
      }
    };
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/ai_profile_enrichment_step.py"
    # steps/python/ai_profile_enrichment_step.py
    import json
    import os
    import asyncio
    import urllib.request
    import urllib.parse
    import urllib.error
    import time

    config = {
        "type": "event",
        "name": "PyAiProfileEnrichment",
        "description": "AI agent that enriches pet profiles using OpenAI",
        "subscribes": ["py.pet.created"],
        "emits": [],
        "flows": ["PyPetManagement"]
    }

    async def handler(input_data, ctx=None):
        logger = getattr(ctx, 'logger', None) if ctx else None
        emit = getattr(ctx, 'emit', None) if ctx else None
        streams = getattr(ctx, 'streams', None) if ctx else None
        trace_id = getattr(ctx, 'traceId', None) if ctx else None
        
        pet_id = input_data.get('petId')
        name = input_data.get('name')
        species = input_data.get('species')

        if logger:
            logger.info('ðŸ¤– AI Profile Enrichment started', {'petId': pet_id, 'name': name, 'species': species})

        # Stream enrichment started event
        if streams and streams.petCreation and trace_id:
            await streams.petCreation.set(trace_id, 'enrichment_started', { 
                'message': f'AI enrichment started for {name}'
            })

        try:
            # Import pet store
            import sys
            import os
            sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
            from services import pet_store

            # Get OpenAI API key from environment
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                raise Exception('OPENAI_API_KEY environment variable is not set')

            # Create AI prompt for pet profile generation
            prompt = f'''Generate a pet profile for adoption purposes. Pet details:
- Name: {name}
- Species: {species}

Please provide a JSON response with these fields:
- bio: A warm, engaging 2-3 sentence description that would appeal to potential adopters
- breedGuess: Your best guess at the breed or breed mix (be specific but realistic)
- temperamentTags: An array of 3-5 personality traits (e.g., "friendly", "energetic", "calm")
- adopterHints: Practical advice for potential adopters (family type, living situation, care needs)

Keep it positive, realistic, and adoption-focused.'''

            # Call OpenAI API using urllib
            request_data = {
                'model': 'gpt-3.5-turbo',
                'messages': [
                    {
                        'role': 'system',
                        'content': 'You are a pet adoption specialist who creates compelling, accurate pet profiles. Always respond with valid JSON only.'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': 500,
                'temperature': 0.7,
            }
            
            request_json = json.dumps(request_data).encode('utf-8')
            
            request = urllib.request.Request(
                'https://api.openai.com/v1/chat/completions',
                data=request_json,
                headers={
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json',
                }
            )
            
            try:
                with urllib.request.urlopen(request) as response:
                    if response.status != 200:
                        raise Exception(f'OpenAI API error: {response.status} {response.reason}')
                    
                    response_data = response.read().decode('utf-8')
                    data = json.loads(response_data)
                    ai_response = data.get('choices', [{}])[0].get('message', {}).get('content')

                    if not ai_response:
                        raise Exception('No response from OpenAI API')
            except urllib.error.HTTPError as e:
                raise Exception(f'OpenAI API HTTP error: {e.code} {e.reason}')
            except urllib.error.URLError as e:
                raise Exception(f'OpenAI API URL error: {e.reason}')

            # Parse AI response
            try:
                profile = json.loads(ai_response)
            except json.JSONDecodeError as parse_error:
                # Fallback profile if AI response is not valid JSON
                profile = {
                    'bio': f'{name} is a wonderful {species} looking for a loving home. This pet has a unique personality and would make a great companion.',
                    'breedGuess': 'Mixed Breed' if species == 'dog' else 'Domestic Shorthair' if species == 'cat' else 'Mixed Breed',
                    'temperamentTags': ['friendly', 'loving', 'loyal'],
                    'adopterHints': f'{name} would do well in a caring home with patience and love.'
                }
                
                if logger:
                    logger.warn('âš ï¸ AI response parsing failed, using fallback profile', {'petId': pet_id, 'parseError': str(parse_error)})

            # Update pet with AI-generated profile
            updated_pet = pet_store.update_profile(pet_id, profile)
            
            if not updated_pet:
                raise Exception(f'Pet not found: {pet_id}')

            if logger:
                logger.info('âœ… AI Profile Enrichment completed', {
                    'petId': pet_id,
                    'profile': {
                        'bio': profile['bio'][:50] + '...',
                        'breedGuess': profile['breedGuess'],
                        'temperamentTags': profile['temperamentTags'],
                        'adopterHints': profile['adopterHints'][:50] + '...'
                    }
                })

            # Stream each field as it's processed
            enrichment_fields = ['bio', 'breedGuess', 'temperamentTags', 'adopterHints']
            for field in enrichment_fields:
                await asyncio.sleep(0.3)
                
                value = profile.get(field)
                
                if streams and streams.petCreation and trace_id:
                    await streams.petCreation.set(trace_id, f'progress_{field}', { 
                        'message': f'Generated {field} for {name}'
                    })

            # Stream enrichment completed event
            if streams and streams.petCreation and trace_id:
                await streams.petCreation.set(trace_id, 'completed', { 
                    'message': f'AI enrichment completed for {name}'
                })

        except Exception as error:
            if logger:
                logger.error('âŒ AI Profile Enrichment failed', {
                    'petId': pet_id,
                    'error': str(error)
                })

            # Create fallback profile on error
            fallback_profile = {
                'bio': f'{name} is a lovely {species} with a unique personality, ready to find their forever home.',
                'breedGuess': 'Mixed Breed' if species == 'dog' else 'Domestic Shorthair' if species == 'cat' else 'Mixed Breed',
                'temperamentTags': ['friendly', 'adaptable'],
                'adopterHints': f'{name} is looking for a patient and loving family.'
            }

            # Still update with fallback profile
            try:
                import sys
                import os
                sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
                from services import pet_store
                pet_store.update_profile(pet_id, fallback_profile)
            except:
                pass

            # Stream fallback profile completion
            if streams and streams.petCreation and trace_id:
                await streams.petCreation.set(trace_id, 'completed', { 
                    'message': f'AI enrichment completed with fallback profile for {name}'
                })
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/ai-profile-enrichment.step.js"
    // steps/javascript/ai-profile-enrichment.step.js
    const { updateProfile } = require('./js-store');

    exports.config = {
      type: 'event',
      name: 'JsAiProfileEnrichment',
      description: 'AI agent that enriches pet profiles using OpenAI',
      subscribes: ['js.pet.created'],
      emits: [],
      flows: ['JsPetManagement']
    };

    exports.handler = async (input, context) => {
      const { logger, streams, traceId } = context || {};
      const { petId, name, species } = input;

      if (logger) {
        logger.info('ðŸ¤– AI Profile Enrichment started', { petId, name, species });
      }

      // Stream enrichment started event
      if (streams && traceId) {
        await streams.petCreation.set(traceId, 'enrichment_started', { 
          message: `AI enrichment started for ${name}`
        });
      }

      try {
        const apiKey = process.env.OPENAI_API_KEY;
        if (!apiKey) {
          throw new Error('OPENAI_API_KEY environment variable is not set');
        }

        const prompt = `Generate a pet profile for adoption purposes. Pet details:
- Name: ${name}
- Species: ${species}

Please provide a JSON response with these fields:
- bio: A warm, engaging 2-3 sentence description that would appeal to potential adopters
- breedGuess: Your best guess at the breed or breed mix (be specific but realistic)
- temperamentTags: An array of 3-5 personality traits (e.g., "friendly", "energetic", "calm")
- adopterHints: Practical advice for potential adopters (family type, living situation, care needs)

Keep it positive, realistic, and adoption-focused.`;

        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'gpt-3.5-turbo',
            messages: [
              {
                role: 'system',
                content: 'You are a pet adoption specialist who creates compelling, accurate pet profiles. Always respond with valid JSON only.'
              },
              {
                role: 'user',
                content: prompt
              }
            ],
            max_tokens: 500,
            temperature: 0.7,
          }),
        });

        if (!response.ok) {
          throw new Error(`OpenAI API error: ${response.status} ${response.statusText}`);
        }

        const data = await response.json();
        const aiResponse = data.choices[0]?.message?.content;

        if (!aiResponse) {
          throw new Error('No response from OpenAI API');
        }

        let profile;
        try {
          profile = JSON.parse(aiResponse);
        } catch (parseError) {
          profile = {
            bio: `${name} is a wonderful ${species} looking for a loving home. This pet has a unique personality and would make a great companion.`,
            breedGuess: species === 'dog' ? 'Mixed Breed' : species === 'cat' ? 'Domestic Shorthair' : 'Mixed Breed',
            temperamentTags: ['friendly', 'loving', 'loyal'],
            adopterHints: `${name} would do well in a caring home with patience and love.`
          };
          
          if (logger) {
            logger.warn('âš ï¸ AI response parsing failed, using fallback profile', { petId, parseError: parseError.message });
          }
        }

        const updatedPet = updateProfile(petId, profile);
        
        if (!updatedPet) {
          throw new Error(`Pet not found: ${petId}`);
        }

        if (logger) {
          logger.info('âœ… AI Profile Enrichment completed', { 
            petId, 
            profile: {
              bio: profile.bio.substring(0, 50) + '...',
              breedGuess: profile.breedGuess,
              temperamentTags: profile.temperamentTags,
              adopterHints: profile.adopterHints.substring(0, 50) + '...'
            }
          });
        }

        // Stream each field as it's processed
        const enrichmentFields = ['bio', 'breedGuess', 'temperamentTags', 'adopterHints'];
        for (const field of enrichmentFields) {
          await new Promise(resolve => setTimeout(resolve, 300));
          
          const value = profile[field];
          
          if (streams && traceId) {
            await streams.petCreation.set(traceId, `progress_${field}`, { 
              message: `Generated ${field} for ${name}`
            });
          }
        }

        // Stream enrichment completed event
        if (streams && traceId) {
          await streams.petCreation.set(traceId, 'completed', { 
            message: `AI enrichment completed for ${name}`
          });
        }

      } catch (error) {
        if (logger) {
          logger.error('âŒ AI Profile Enrichment failed', { 
            petId, 
            error: error.message 
          });
        }

        const fallbackProfile = {
          bio: `${name} is a lovely ${species} with a unique personality, ready to find their forever home.`,
          breedGuess: species === 'dog' ? 'Mixed Breed' : species === 'cat' ? 'Domestic Shorthair' : 'Mixed Breed',
          temperamentTags: ['friendly', 'adaptable'],
          adopterHints: `${name} is looking for a patient and loving family.`
        };

        updateProfile(petId, fallbackProfile);

        // Stream fallback profile completion
        if (streams && traceId) {
          await streams.petCreation.set(traceId, 'completed', { 
            message: `AI enrichment completed with fallback profile for ${name}`
          });
        }
      }
    };
    ```
  </Tab>
</Tabs>

### How Agentic Step Streaming Works

Agentic steps stream progress as they work:

1. **Stream start notification** - Let users know AI processing has begun
2. **Progress updates** - Stream each stage of generation (bio, breed, temperament, etc.)
3. **Stream completion** - Notify when AI processing is done
4. **Error streaming** - Stream errors gracefully with fallback messages

This transforms a potentially slow AI operation into an engaging real-time experience.

---

## Testing Streaming in Action

The best way to test streams is through **Workbench**.

### Test 1: Create a Pet with Streaming

Open Workbench and navigate to the Endpoints section, then test the Pet Creation endpoint:

<Callout type="tip">
**Prefer using curl?**

```bash
curl -X POST http://localhost:3000/ts/pets \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Max",
    "species": "dog",
    "ageMonths": 24,
    "symptoms": ["coughing"]
  }'
```
</Callout>

You'll get an immediate response with the stream result. The API returns right away while background jobs process asynchronously.

### Test 2: Monitor Stream Updates in Workbench

After creating a pet, check the Tracing view in Workbench:

1. Automatically switched to the **Tracing** tab so you can see the stream updates in real-time
2. Click on the most recent trace
3. Watch the timeline as steps execute
4. See stream updates appear in real-time in the timeline

![stream-tracing](../../img/build-your-first-app/stream-tracing.png)

You'll observe:
- Pet creation completes immediately
- Feeding reminder job streams quarantine updates
- AI enrichment streams progress updates
- All updates visible in the trace timeline

### Test 3: Create Pet with Symptoms

Test the conditional streaming logic by creating a pet with symptoms:

```bash
curl -X POST http://localhost:3000/ts/pets \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Luna",
    "species": "cat",
    "ageMonths": 18,
    "symptoms": ["sneezing", "watery eyes"]
  }'
```

Watch the logs to see different stream messages based on the symptoms detected.

### Test 4: Create Pet Without Symptoms

Compare the streaming behavior with a healthy pet:

```bash
curl -X POST http://localhost:3000/ts/pets \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Buddy",
    "species": "dog",
    "ageMonths": 12
  }'
```

The stream will show health check passed messages instead of treatment needed messages.

### Observing Stream Updates

Watch the Workbench console logs to see the real-time stream updates as they're pushed:

```
ðŸ¾ Pet created { petId: '1', name: 'Max', species: 'dog', status: 'new' }
ðŸ“‹ Setting next feeding reminder { petId: '1' }
ðŸ¤– AI Profile Enrichment started { petId: '1', name: 'Max' }
âœ… Next feeding reminder set { petId: '1' }
âœ… AI Profile Enrichment completed { petId: '1' }
```

Each emoji-prefixed log corresponds to a stream update being pushed to connected clients.

---

ðŸŽ‰ **Congratulations!** You've built a complete real-time streaming system with Motia. Your pet management system now provides live feedback to users while complex workflows execute in the background.

---

## What's Next?

You've now mastered the complete Motia stack:

- **API Endpoints** - Build RESTful APIs with validation
- **Background Jobs** - Process async tasks efficiently  
- **Workflows** - Orchestrate complex business logic
- **Agentic Workflows** - Make intelligent decisions with AI
- **Real-Time Streaming** - Provide live updates using streams in any step handler

This is the **complete progression** from simple APIs to intelligent, real-time systems!

**Key Takeaway:** Streams are just another tool in your step handler's context - use them wherever you need real-time updates!

Here are some ideas to extend your streaming implementation:

- **Add stream analytics** - Track how many clients are connected, message delivery rates
- **Implement stream persistence** - Use Redis adapter for stream storage across restarts
- **Create stream multiplexing** - Multiple streams per workflow for different update types
- **Build progress bars** - Use structured progress data (0-100%) instead of just messages
- **Add stream authentication** - Ensure only authorized clients can access streams

Explore more examples in the [Motia Examples Repository](https://github.com/MotiaDev/motia-examples).



-   [workflows](/docs/getting-started/build-your-first-motia-app/workflows): Documentation for workflows.
---
title: Workflows
description: Learn how to build automated workflows that manage complex business logic with Motia
---

## What You'll Build

A pet lifecycle management system that automatically guides pets through their journey at your shelter:

- **Automated Status Transitions** - Pets move through stages automatically when conditions are met
- **Staff Decision Points** - Critical checkpoints where staff make the calls
- **Smart Progressions** - Some transitions trigger follow-up actions automatically
- **Validation Rules** - Prevents invalid status changes to keep data consistent

![workbench](../../img/build-your-first-app/workflow-workbench.png)
---

## Getting Started

Clone the example repository:

```bash
git clone https://github.com/MotiaDev/build-your-first-app.git
cd build-your-first-app
git checkout workflow-orchestrator
```

Install dependencies:

```bash
npm install
```

Start the Workbench:

```bash
npm run dev
```

Your Workbench will be available at `http://localhost:3000`.

---

## Project Structure

<Folder name="my-pet-api" defaultOpen>
  <Folder name="steps" defaultOpen>
    <Folder name="typescript">
      <File name="create-pet.step.ts" />
      <File name="set-next-feeding-reminder.job.step.ts" />
      <File name="pet-lifecycle-orchestrator.step.ts" />
      <File name="ts-store.ts" />
    </Folder>
    <Folder name="javascript">
      <File name="create-pet.step.js" />
      <File name="set-next-feeding-reminder.job.step.js" />
      <File name="pet-lifecycle-orchestrator.step.js" />
      <File name="js-store.js" />
    </Folder>
    <Folder name="python">
      <File name="create_pet_step.py" />
      <File name="set_next_feeding_reminder.job_step.py" />
      <File name="pet_lifecycle_orchestrator_step.py" />
    </Folder>
  </Folder>
  <Folder name="services">
    <File name="pet_store.py" />
    <File name="types.py" />
  </Folder>
  <File name="package.json" />
  <File name="requirements.txt" />
  <File name="types.d.ts" />
</Folder>

<Callout type="info">
Files like `features.json` and `tutorial/tutorial.tsx` are only for the interactive tutorial and are not part of Motia's project structure.
</Callout>

All code examples in this guide are available in the [build-your-first-app](https://github.com/MotiaDev/build-your-first-app/tree/workflow-orchestration) repository.

You can follow this guide to learn how to build workflow orchestration with Motia step by step, or you can clone the repository and dive into our Interactive Tutorial to learn by doing directly in the Workbench.

![interactive-tutorial](../../img/build-your-first-app/interactive-tutorial-workflow.png)

---

## Understanding Workflows

So far, you've built API endpoints that respond to requests and background jobs that handle async tasks. But what about coordinating complex business processes that involve multiple steps and decision points?

That's where workflows come in. It's the conductor of your system - making sure things happen in the right order, at the right time, and only when it makes sense.

In our pet shelter example, a pet goes through many stages:
- New arrivals need health checks
- Healthy pets become available for adoption
- Sick pets need treatment before they're ready
- Adoption applications require staff approval

A workflow manages all these transitions, enforcing the rules and keeping everything consistent.

---

## The Pet Lifecycle Journey

When you create a pet, it starts as `new`. Once the feeding reminder job completes, it automatically moves to `in_quarantine`. Staff then checks on it and marks it `healthy`, which automatically progresses to `available`. When someone wants to adopt, it goes `pending`, then finally `adopted`.

The key here is some transitions happen automatically (like `healthy` â†’ `available`), while others need staff approval (like `in_quarantine` â†’ `healthy`).

**What about sick pets?**

If staff finds a pet is `ill`, it automatically moves to `under_treatment`. When staff marks it `recovered`, it chains through automatic transitions: `recovered` â†’ `healthy` â†’ `available`.

This mix of automatic progressions and human decision points is what makes workflows powerful - the system handles the routine stuff while keeping people in control of important calls.

---

## Creating the Workflow

The workflow orchestrator is a single Event Step that manages all pet lifecycle transitions. Here's the complete implementation:

<Callout type="info">
View on GitHub:
- [TypeScript](https://github.com/MotiaDev/build-your-first-app/blob/workflow-orchestration/steps/typescript/pet-lifecycle-orchestrator.step.ts)
- [Python](https://github.com/MotiaDev/build-your-first-app/blob/workflow-orchestration/steps/python/pet_lifecycle_orchestrator_step.py)
- [JavaScript](https://github.com/MotiaDev/build-your-first-app/blob/workflow-orchestration/steps/javascript/pet-lifecycle-orchestrator.step.js)
</Callout>

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
  <Tab value="TypeScript">
    ```typescript title="steps/typescript/pet-lifecycle-orchestrator.step.ts"
    // steps/typescript/pet-lifecycle-orchestrator.step.ts
    import { EventConfig, Handlers } from 'motia';
    import { TSStore, Pet } from './ts-store';

    type LifecycleEvent = 
      | 'pet.created'
      | 'feeding.reminder.completed'
      | 'status.update.requested';

    type TransitionRule = {
      from: Pet["status"][];
      to: Pet["status"];
      event: LifecycleEvent;
      description: string;
    };

    const TRANSITION_RULES: TransitionRule[] = [
      {
        from: ["new"],
        to: "in_quarantine",
        event: "feeding.reminder.completed",
        description: "Pet moved to quarantine after feeding setup"
      },
      {
        from: ["in_quarantine"],
        to: "healthy",
        event: "status.update.requested",
        description: "Staff health check - pet cleared from quarantine"
      },
      {
        from: ["healthy", "in_quarantine", "available"],
        to: "ill",
        event: "status.update.requested",
        description: "Staff assessment - pet identified as ill"
      },
      {
        from: ["healthy"],
        to: "available",
        event: "status.update.requested",
        description: "Staff decision - pet ready for adoption"
      },
      {
        from: ["ill"],
        to: "under_treatment",
        event: "status.update.requested",
        description: "Staff decision - treatment started"
      },
      {
        from: ["under_treatment"],
        to: "recovered",
        event: "status.update.requested",
        description: "Staff assessment - treatment completed"
      },
      {
        from: ["recovered"],
        to: "healthy",
        event: "status.update.requested",
        description: "Staff clearance - pet fully recovered"
      },
      {
        from: ["available"],
        to: "pending",
        event: "status.update.requested",
        description: "Adoption application received"
      },
      {
        from: ["pending"],
        to: "adopted",
        event: "status.update.requested",
        description: "Adoption completed"
      },
      {
        from: ["pending"],
        to: "available",
        event: "status.update.requested",
        description: "Adoption application rejected/cancelled"
      }
    ];

    export const config = {
      type: 'event',
      name: 'TsPetLifecycleOrchestrator',
      description: 'Pet lifecycle state management with staff interaction points',
      subscribes: ['ts.pet.created', 'ts.feeding.reminder.completed', 'ts.pet.status.update.requested'],
      emits: [],
      flows: ['TsPetManagement']
    };

    export const handler: Handlers['TsPetLifecycleOrchestrator'] = async (input, { emit, logger }) => {
      const { petId, event: eventType, requestedStatus, automatic } = input;

      if (logger) {
        const logMessage = automatic ? 'ðŸ¤– Automatic progression' : 'ðŸ”„ Lifecycle orchestrator processing';
        logger.info(logMessage, { petId, eventType, requestedStatus, automatic });
      }

      try {
        const pet = TSStore.get(petId);
        if (!pet) {
          if (logger) {
            logger.error('âŒ Pet not found for lifecycle transition', { petId, eventType });
          }
          return;
        }

        // For status update requests, find the rule based on requested status
        let rule;
        if (eventType === 'status.update.requested' && requestedStatus) {
          rule = TRANSITION_RULES.find(r => 
            r.event === eventType && 
            r.from.includes(pet.status) && 
            r.to === requestedStatus
          );
        } else {
          // For other events (like feeding.reminder.completed)
          rule = TRANSITION_RULES.find(r => 
            r.event === eventType && r.from.includes(pet.status)
          );
        }

        if (!rule) {
          const reason = eventType === 'status.update.requested' 
            ? `Invalid transition: cannot change from ${pet.status} to ${requestedStatus}`
            : `No transition rule found for ${eventType} from ${pet.status}`;
            
          if (logger) {
            logger.warn('âš ï¸ Transition rejected', { 
              petId, 
              currentStatus: pet.status, 
              requestedStatus,
              eventType,
              reason
            });
          }
          
          // Transition rejected - no event emission needed
          return;
        }

        // Check for idempotency
        if (pet.status === rule.to) {
          if (logger) {
            logger.info('âœ… Already in target status', { 
              petId, 
              status: pet.status,
              eventType
            });
          }
          return;
        }

        // Apply the transition
        const oldStatus = pet.status;
        const updatedPet = TSStore.updateStatus(petId, rule.to);
        
        if (!updatedPet) {
          if (logger) {
            logger.error('âŒ Failed to update pet status', { petId, oldStatus, newStatus: rule.to });
          }
          return;
        }

        if (logger) {
          logger.info('âœ… Lifecycle transition completed', {
            petId,
            oldStatus,
            newStatus: rule.to,
            eventType,
            description: rule.description,
            timestamp: Date.now()
          });
        }

        // Transition completed successfully
        if (logger) {
          logger.info('âœ… Pet status transition completed', { 
            petId, 
            oldStatus, 
            newStatus: rule.to, 
            eventType, 
            description: rule.description 
          });
        }

        // Check for automatic progressions after successful transition
        await processAutomaticProgression(petId, rule.to, emit, logger);

      } catch (error: any) {
        if (logger) {
          logger.error('âŒ Lifecycle orchestrator error', { petId, eventType, error: error.message });
        }
      }
    };

    async function processAutomaticProgression(petId: string, currentStatus: Pet["status"], emit: any, logger: any) {
      // Define automatic progressions
      const automaticProgressions: Partial<Record<Pet["status"], { to: Pet["status"], description: string }>> = {
        'healthy': { to: 'available', description: 'Automatic progression - pet ready for adoption' },
        'ill': { to: 'under_treatment', description: 'Automatic progression - treatment started' },
        'recovered': { to: 'healthy', description: 'Automatic progression - recovery complete' }
      };

      const progression = automaticProgressions[currentStatus];
      if (progression) {
        if (logger) {
          logger.info('ðŸ¤– Processing automatic progression', { 
            petId, 
            currentStatus, 
            nextStatus: progression.to 
          });
        }

        // Find the transition rule for automatic progression
        const rule = TRANSITION_RULES.find(r => 
          r.event === 'status.update.requested' && 
          r.from.includes(currentStatus) && 
          r.to === progression.to
        );

        if (rule) {
          // Apply the automatic transition immediately
          const oldStatus = currentStatus;
          const updatedPet = TSStore.updateStatus(petId, rule.to);
          
          if (updatedPet) {
            if (logger) {
              logger.info('âœ… Automatic progression completed', {
                petId,
                oldStatus,
                newStatus: rule.to,
                description: progression.description,
                timestamp: Date.now()
              });
            }

            // Automatic progression completed successfully
            if (logger) {
              logger.info('âœ… Automatic progression completed', { 
                petId, 
                oldStatus, 
                newStatus: rule.to, 
                description: progression.description 
              });
            }

            // Check for further automatic progressions (for chaining like recovered â†’ healthy â†’ available)
            await processAutomaticProgression(petId, rule.to, emit, logger);
          } else if (logger) {
            logger.error('âŒ Failed to apply automatic progression', { petId, oldStatus, newStatus: rule.to });
          }
        } else if (logger) {
          logger.warn('âš ï¸ No transition rule found for automatic progression', { 
            petId, 
            currentStatus, 
            targetStatus: progression.to 
          });
        }
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python title="steps/python/pet_lifecycle_orchestrator_step.py"
    # steps/python/pet_lifecycle_orchestrator.step.py

    TRANSITION_RULES = [
        {
            'from': ['new'],
            'to': 'in_quarantine',
            'event': 'feeding.reminder.completed',
            'description': 'Pet moved to quarantine after feeding setup'
        },
        {
            'from': ['in_quarantine'],
            'to': 'healthy',
            'event': 'status.update.requested',
            'description': 'Staff health check - pet cleared from quarantine'
        },
        {
            'from': ['healthy', 'in_quarantine', 'available'],
            'to': 'ill',
            'event': 'status.update.requested',
            'description': 'Staff assessment - pet identified as ill'
        },
        {
            'from': ['healthy'],
            'to': 'available',
            'event': 'status.update.requested',
            'description': 'Staff decision - pet ready for adoption'
        },
        {
            'from': ['ill'],
            'to': 'under_treatment',
            'event': 'status.update.requested',
            'description': 'Staff decision - treatment started'
        },
        {
            'from': ['under_treatment'],
            'to': 'recovered',
            'event': 'status.update.requested',
            'description': 'Staff assessment - treatment completed'
        },
        {
            'from': ['recovered'],
            'to': 'healthy',
            'event': 'status.update.requested',
            'description': 'Staff clearance - pet fully recovered'
        },
        {
            'from': ['available'],
            'to': 'pending',
            'event': 'status.update.requested',
            'description': 'Adoption application received'
        },
        {
            'from': ['pending'],
            'to': 'adopted',
            'event': 'status.update.requested',
            'description': 'Adoption completed'
        },
        {
            'from': ['pending'],
            'to': 'available',
            'event': 'status.update.requested',
            'description': 'Adoption application rejected/cancelled'
        }
    ]

    config = {
        "type": "event",
        "name": "PyPetLifecycleOrchestrator",
        "description": "Pet lifecycle state management with staff interaction points",
        "subscribes": [
            "py.pet.created", 
            "py.feeding.reminder.completed",
            "py.pet.status.update.requested"
        ],
        "emits": [],
        "flows": ["PyPetManagement"]
    }

    async def handler(input_data, ctx=None):
        logger = getattr(ctx, 'logger', None) if ctx else None
        emit = getattr(ctx, 'emit', None) if ctx else None
        
        try:
            import sys
            import os
            import time
            sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
            from services import pet_store
        except ImportError:
            if logger:
                logger.error('âŒ Lifecycle orchestrator failed - import error')
            return

        pet_id = input_data.get('petId')
        event_type = input_data.get('event')
        requested_status = input_data.get('requestedStatus')
        automatic = input_data.get('automatic', False)

        if logger:
            log_message = 'ðŸ¤– Automatic progression' if automatic else 'ðŸ”„ Lifecycle orchestrator processing'
            logger.info(log_message, {'petId': pet_id, 'eventType': event_type, 'requestedStatus': requested_status, 'automatic': automatic})

        try:
            pet = pet_store.get(pet_id)
            if not pet:
                if logger:
                    logger.error('âŒ Pet not found for lifecycle transition', {'petId': pet_id, 'eventType': event_type})
                return

            # For status update requests, find the rule based on requested status
            rule = None
            if event_type == 'status.update.requested' and requested_status:
                for r in TRANSITION_RULES:
                    if (r['event'] == event_type and 
                        pet['status'] in r['from'] and 
                        r['to'] == requested_status):
                        rule = r
                        break
            else:
                # For other events (like feeding.reminder.completed)
                for r in TRANSITION_RULES:
                    if r['event'] == event_type and pet['status'] in r['from']:
                        rule = r
                        break

            if not rule:
                reason = (f"Invalid transition: cannot change from {pet['status']} to {requested_status}" 
                         if event_type == 'status.update.requested' 
                         else f"No transition rule found for {event_type} from {pet['status']}")
                    
                if logger:
                    logger.warn('âš ï¸ Transition rejected', {
                        'petId': pet_id,
                        'currentStatus': pet['status'],
                        'requestedStatus': requested_status,
                        'eventType': event_type,
                        'reason': reason
                    })
                
                if emit:
                    await emit({
                        'topic': 'py.lifecycle.transition.rejected',
                        'data': {
                            'petId': pet_id,
                            'currentStatus': pet['status'],
                            'requestedStatus': requested_status,
                            'eventType': event_type,
                            'reason': reason,
                            'timestamp': int(time.time() * 1000)
                        }
                    })
                return

            # Check for idempotency
            if pet['status'] == rule['to']:
                if logger:
                    logger.info('âœ… Already in target status', {
                        'petId': pet_id,
                        'status': pet['status'],
                        'eventType': event_type
                    })
                return

            # Apply the transition
            old_status = pet['status']
            updated_pet = pet_store.update_status(pet_id, rule['to'])
            
            if not updated_pet:
                if logger:
                    logger.error('âŒ Failed to update pet status', {'petId': pet_id, 'oldStatus': old_status, 'newStatus': rule['to']})
                return

            if logger:
                logger.info('âœ… Lifecycle transition completed', {
                    'petId': pet_id,
                    'oldStatus': old_status,
                    'newStatus': rule['to'],
                    'eventType': event_type,
                    'description': rule['description'],
                    'timestamp': int(time.time() * 1000)
                })

            if emit:
                await emit({
                    'topic': 'py.lifecycle.transition.completed',
                    'data': {
                        'petId': pet_id,
                        'oldStatus': old_status,
                        'newStatus': rule['to'],
                        'eventType': event_type,
                        'description': rule['description'],
                        'timestamp': int(time.time() * 1000)
                    }
                })

                # Check for automatic progressions after successful transition
                await check_automatic_progressions(pet_id, rule['to'], emit, logger)

        except Exception as error:
            if logger:
                logger.error('âŒ Lifecycle orchestrator error', {'petId': pet_id, 'eventType': event_type, 'error': str(error)})

    async def check_automatic_progressions(pet_id, current_status, emit, logger):
        # Define automatic progressions
        automatic_progressions = {
            'healthy': {'to': 'available', 'description': 'Automatic progression - pet ready for adoption'},
            'ill': {'to': 'under_treatment', 'description': 'Automatic progression - treatment started'},
            'recovered': {'to': 'healthy', 'description': 'Automatic progression - recovery complete'}
        }

        progression = automatic_progressions.get(current_status)
        if progression:
            if logger:
                logger.info('ðŸ¤– Orchestrator triggering automatic progression', {
                    'petId': pet_id,
                    'currentStatus': current_status,
                    'nextStatus': progression['to']
                })

            # Emit automatic progression event with delay
            import asyncio
            async def delayed_emit():
                await asyncio.sleep(1.5)  # Slightly longer delay to ensure current transition completes
                # Get fresh pet status to ensure we have the latest state
                try:
                    import sys
                    import os
                    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
                    from services import pet_store
                    fresh_pet = pet_store.get(pet_id)
                    if fresh_pet and fresh_pet['status'] == current_status:
                        await emit({
                            'topic': 'py.pet.status.update.requested',
                            'data': {
                                'petId': pet_id,
                                'event': 'status.update.requested',
                                'requestedStatus': progression['to'],
                                'currentStatus': fresh_pet['status'],
                                'automatic': True
                            }
                        })
                    elif logger:
                        logger.warn('âš ï¸ Automatic progression skipped - pet status changed', {
                            'petId': pet_id,
                            'expectedStatus': current_status,
                            'actualStatus': fresh_pet['status'] if fresh_pet else None
                        })
                except Exception as e:
                    if logger:
                        logger.error('âŒ Automatic progression error', {'petId': pet_id, 'error': str(e)})
            
            asyncio.create_task(delayed_emit())
    ```
  </Tab>
  <Tab value="JavaScript">
    ```javascript title="steps/javascript/pet-lifecycle-orchestrator.step.js"
    // steps/javascript/pet-lifecycle-orchestrator.step.js
    const { get, updateStatus } = require('./js-store');

    const TRANSITION_RULES = [
      {
        from: ['new'],
        to: 'in_quarantine',
        event: 'feeding.reminder.completed',
        description: 'Pet moved to quarantine after feeding setup'
      },
      {
        from: ['in_quarantine'],
        to: 'healthy',
        event: 'status.update.requested',
        description: 'Staff health check - pet cleared from quarantine'
      },
      {
        from: ['healthy', 'in_quarantine', 'available'],
        to: 'ill',
        event: 'status.update.requested',
        description: 'Staff assessment - pet identified as ill'
      },
      {
        from: ['healthy'],
        to: 'available',
        event: 'status.update.requested',
        description: 'Staff decision - pet ready for adoption'
      },
      {
        from: ['ill'],
        to: 'under_treatment',
        event: 'status.update.requested',
        description: 'Staff decision - treatment started'
      },
      {
        from: ['under_treatment'],
        to: 'recovered',
        event: 'status.update.requested',
        description: 'Staff assessment - treatment completed'
      },
      {
        from: ['recovered'],
        to: 'healthy',
        event: 'status.update.requested',
        description: 'Staff clearance - pet fully recovered'
      },
      {
        from: ['available'],
        to: 'pending',
        event: 'status.update.requested',
        description: 'Adoption application received'
      },
      {
        from: ['pending'],
        to: 'adopted',
        event: 'status.update.requested',
        description: 'Adoption completed'
      },
      {
        from: ['pending'],
        to: 'available',
        event: 'status.update.requested',
        description: 'Adoption application rejected/cancelled'
      }
    ];

    exports.config = {
      type: 'event',
      name: 'JsPetLifecycleOrchestrator',
      description: 'Pet lifecycle state management with staff interaction points',
      subscribes: ['js.pet.created', 'js.feeding.reminder.completed', 'js.pet.status.update.requested'],
      emits: [],
      flows: ['JsPetManagement']
    };

    exports.handler = async (input, context) => {
      const { emit, logger } = context || {};
      const { petId, event: eventType, requestedStatus, automatic } = input;

      if (logger) {
        const logMessage = automatic ? 'ðŸ¤– Automatic progression' : 'ðŸ”„ Lifecycle orchestrator processing';
        logger.info(logMessage, { petId, eventType, requestedStatus, automatic });
      }

      try {
        const pet = get(petId);
        if (!pet) {
          if (logger) {
            logger.error('âŒ Pet not found for lifecycle transition', { petId, eventType });
          }
          return;
        }

        // For status update requests, find the rule based on requested status
        let rule;
        if (eventType === 'status.update.requested' && requestedStatus) {
          rule = TRANSITION_RULES.find(r => 
            r.event === eventType && 
            r.from.includes(pet.status) && 
            r.to === requestedStatus
          );
        } else {
          // For other events (like feeding.reminder.completed)
          rule = TRANSITION_RULES.find(r => 
            r.event === eventType && r.from.includes(pet.status)
          );
        }

        if (!rule) {
          const reason = eventType === 'status.update.requested' 
            ? `Invalid transition: cannot change from ${pet.status} to ${requestedStatus}`
            : `No transition rule found for ${eventType} from ${pet.status}`;
            
          if (logger) {
            logger.warn('âš ï¸ Transition rejected', { 
              petId, 
              currentStatus: pet.status, 
              requestedStatus,
              eventType,
              reason
            });
          }
          
          if (emit) {
            await emit({
              topic: 'js.lifecycle.transition.rejected',
              data: {
                petId,
                currentStatus: pet.status,
                requestedStatus,
                eventType,
                reason,
                timestamp: Date.now()
              }
            });
          }
          return;
        }

        // Check for idempotency
        if (pet.status === rule.to) {
          if (logger) {
            logger.info('âœ… Already in target status', { 
              petId, 
              status: pet.status,
              eventType
            });
          }
          return;
        }

        // Apply the transition
        const oldStatus = pet.status;
        const updatedPet = updateStatus(petId, rule.to);
        
        if (!updatedPet) {
          if (logger) {
            logger.error('âŒ Failed to update pet status', { petId, oldStatus, newStatus: rule.to });
          }
          return;
        }

        if (logger) {
          logger.info('âœ… Lifecycle transition completed', {
            petId,
            oldStatus,
            newStatus: rule.to,
            eventType,
            description: rule.description,
            timestamp: Date.now()
          });
        }

        if (emit) {
          await emit({
            topic: 'js.lifecycle.transition.completed',
            data: {
              petId,
              oldStatus,
              newStatus: rule.to,
              eventType,
              description: rule.description,
              timestamp: Date.now()
            }
          });

          // Check for automatic progressions after successful transition
          await processAutomaticProgression(petId, rule.to, emit, logger);
        }

      } catch (error) {
        if (logger) {
          logger.error('âŒ Lifecycle orchestrator error', { petId, eventType, error: error.message });
        }
      }
    };

    async function processAutomaticProgression(petId, currentStatus, emit, logger) {
      // Define automatic progressions
      const automaticProgressions = {
        'healthy': { to: 'available', description: 'Automatic progression - pet ready for adoption' },
        'ill': { to: 'under_treatment', description: 'Automatic progression - treatment started' },
        'recovered': { to: 'healthy', description: 'Automatic progression - recovery complete' }
      };

      const progression = automaticProgressions[currentStatus];
      if (progression) {
        if (logger) {
          logger.info('ðŸ¤– Processing automatic progression', { 
            petId, 
            currentStatus, 
            nextStatus: progression.to 
          });
        }

        // Find the transition rule for automatic progression
        const rule = TRANSITION_RULES.find(r => 
          r.event === 'status.update.requested' && 
          r.from.includes(currentStatus) && 
          r.to === progression.to
        );

        if (rule) {
          // Apply the automatic transition immediately
          const oldStatus = currentStatus;
          const updatedPet = updateStatus(petId, rule.to);
          
          if (updatedPet) {
            if (logger) {
              logger.info('âœ… Automatic progression completed', {
                petId,
                oldStatus,
                newStatus: rule.to,
                description: progression.description,
                timestamp: Date.now()
              });
            }

            if (emit) {
              await emit({
                topic: 'js.lifecycle.transition.completed',
                data: {
                  petId,
                  oldStatus,
                  newStatus: rule.to,
                  eventType: 'status.update.requested',
                  description: progression.description,
                  automatic: true,
                  timestamp: Date.now()
                }
              });

              // Check for further automatic progressions (for chaining like recovered â†’ healthy â†’ available)
              await processAutomaticProgression(petId, rule.to, emit, logger);
            }
          } else if (logger) {
            logger.error('âŒ Failed to apply automatic progression', { petId, oldStatus, newStatus: rule.to });
          }
        } else if (logger) {
          logger.warn('âš ï¸ No transition rule found for automatic progression', { 
            petId, 
            currentStatus, 
            targetStatus: progression.to 
          });
        }
      }
    }

    module.exports = { config, handler };
    ```
  </Tab>
</Tabs>

### How the Orchestrator Works

The orchestrator has three main responsibilities:

1. **Validate Transitions** - Ensures pets can only move to valid next statuses
2. **Apply Transitions** - Updates the pet's status in the store
3. **Trigger Automatic Progressions** - Some statuses automatically progress to the next stage

**Key Points:**

- `emits: []` - The orchestrator doesn't declare emits because it only manages state internally
- JavaScript/Python emit events for workflow tracking (optional pattern)
- TypeScript focuses purely on state management
- All languages validate transitions using the same `TRANSITION_RULES`

---

## Testing Your Orchestrator

The best way to test your orchestrator is through **Workbench**. It lets you send requests, watch the workflow execute in real-time, and see all the logs in one place.

### Create a Pet

Open Workbench and test the CreatePet endpoint:

![post-pet-test](../../img/build-your-first-app/post-pet.png)

You'll see in the logs:
```
ðŸ¾ Pet created { petId: '1', name: 'Max', species: 'dog', status: 'new' }
ðŸ”„ Setting next feeding reminder { petId: '1' }
âœ… Next feeding reminder set { petId: '1' }
ðŸ”„ Lifecycle orchestrator processing { petId: '1', eventType: 'feeding.reminder.completed' }
âœ… Lifecycle transition completed { oldStatus: 'new', newStatus: 'in_quarantine' }
```

<Callout type="tip">
**Prefer using curl?** You can also test with command line:

```bash
curl -X POST http://localhost:3000/ts/pets \
  -H "Content-Type: application/json" \
  -d '{"name": "Max", "species": "dog", "ageMonths": 24}'
```
</Callout>

### Staff Health Check

Test the UpdatePet endpoint in Workbench to mark the pet as healthy:

![update-status-test](../../img/build-your-first-app/update-status.png)

Watch the automatic progression:
```
ðŸ‘¤ Staff requesting status change { petId: '1', requestedStatus: 'healthy' }
ðŸ”„ Lifecycle orchestrator processing { petId: '1', eventType: 'status.update.requested' }
âœ… Lifecycle transition completed { oldStatus: 'in_quarantine', newStatus: 'healthy' }
ðŸ¤– Processing automatic progression { petId: '1', currentStatus: 'healthy', nextStatus: 'available' }
âœ… Automatic progression completed { oldStatus: 'healthy', newStatus: 'available' }
```

<Callout type="tip">
**Using curl?**

```bash
curl -X PUT http://localhost:3000/ts/pets/1 \
  -H "Content-Type: application/json" \
  -d '{"status": "healthy"}'
```
</Callout>

### Test Invalid Transitions

Try to skip a step in Workbench:

![skip-status-test](../../img/build-your-first-app/skip-status.png)

The orchestrator rejects it:
```
âš ï¸ Transition rejected { 
  currentStatus: 'in_quarantine', 
  requestedStatus: 'available',
  reason: 'Invalid transition: cannot change from in_quarantine to available'
}
```

<Callout type="tip">
**Using curl?**

```bash
curl -X PUT http://localhost:3000/ts/pets/1 \
  -H "Content-Type: application/json" \
  -d '{"status": "available"}'
```
</Callout>

### Test the Illness Workflow

Mark a pet as ill in Workbench:

![update-status-ill-test](../../img/build-your-first-app/update-status-ill.png)

Watch the automatic treatment start:
```
âœ… Lifecycle transition completed { oldStatus: 'healthy', newStatus: 'ill' }
ðŸ¤– Processing automatic progression { currentStatus: 'ill', nextStatus: 'under_treatment' }
âœ… Automatic progression completed { oldStatus: 'ill', newStatus: 'under_treatment' }
```

<Callout type="tip">
**Using curl?**

```bash
curl -X PUT http://localhost:3000/ts/pets/1 \
  -H "Content-Type: application/json" \
  -d '{"status": "ill"}'
```
</Callout>

Then mark the pet as recovered in Workbench:

![update-status-recovered-test](../../img/build-your-first-app/update-status-recovered.png)

Watch the chained automatic progressions:
```
âœ… Lifecycle transition completed { oldStatus: 'under_treatment', newStatus: 'recovered' }
ðŸ¤– Processing automatic progression { currentStatus: 'recovered', nextStatus: 'healthy' }
âœ… Automatic progression completed { oldStatus: 'recovered', newStatus: 'healthy' }
ðŸ¤– Processing automatic progression { currentStatus: 'healthy', nextStatus: 'available' }
âœ… Automatic progression completed { oldStatus: 'healthy', newStatus: 'available' }
```

<Callout type="tip">
**Using curl?**

```bash
curl -X PUT http://localhost:3000/ts/pets/1 \
  -H "Content-Type: application/json" \
  -d '{"status": "recovered"}'
```
</Callout>

---

## Monitoring Your Orchestrator

Use the Workbench to visualize the entire flow:

### Tracing

See how events flow through your system:

![orchestrator-trace](../../img/build-your-first-app/post-pet.png)

Each trace shows:
- The initial API call
- Background job processing
- Orchestrator transitions
- Automatic progressions
- Total time for each step

### Logs

Filter by pet ID to see the complete lifecycle:

![orchestrator-logs](../../img/build-your-first-app/orchestrator-logs.png)

The logs tell the story of each pet's journey through your shelter.
---

ðŸŽ‰ **Congratulations!** You've built a complete workflow orchestrator that manages complex business logic while keeping your code clean and maintainable.

---

## What's Next?

Your pet shelter now has a complete backend system with workflow orchestration! But what about decisions that aren't black and white? Should this pet's symptoms require treatment?

In the next guide, we'll add **Agentic Workflows** that make intelligent decisions within your workflows:

- **Health Review Agentic Step** - Analyzes symptoms and decides if treatment is needed
- **Adoption Review Agentic Step** - Assesses if pets are ready for adoption
- **AI Profile Enrichment** - Automatically generates engaging pet profiles
- **Agentic Decision Making** - AI that chooses which workflow path to take

Let's continue building by adding intelligent decision-making to your workflows.

-   [quick-start](/docs/getting-started/quick-start): Documentation for quick-start.
---
title: Quick Start
description: Get up and running with a new Motia project in just a few seconds.
---
<Steps>

<Step>
### 1. Create Your Project

Use `npx` to create a new Motia project. This single command will scaffold a new application and install all necessary dependencies.

```bash
npx motia@latest create
```

The installer will guide you through a few questions to set up your project, including choosing a template. Once it's done, you will have a new project directory ready to go.

<Callout type="info">
**Quick Start with a Specific Template**

If you already know which template you want, you can skip the interactive prompts:

```bash
# TypeScript starter
npx motia@latest create my-app --template starter-typescript

# JavaScript starter
npx motia@latest create my-app --template starter-javascript

# Python starter
npx motia@latest create my-app --template starter-python
```

See the [CLI documentation](/docs/development-guide/cli#create) for all available templates.
</Callout>

</Step>

<Step>
### 2. Start the Development Server

Navigate into your new project directory and start the Motia development server.

```bash
cd <your-project-name> # If you've created a new folder for the project, navigate into it

npx motia dev
```

![run dev command](/docs-images/motia-terminal.gif)

<Callout>
The `create` command uses `npm` by default. If you chose a different package manager during setup, use `pnpm dev`, `yarn dev`, or `bun dev`.
</Callout>

This command starts the Motia runtime and the Workbench, a powerful UI for developing and debugging your workflows. By default, it's available at [`http://localhost:3000`](http://localhost:3000).

</Step>

<Step>
### 3. Run Your First Flow

The starter project comes with a pre-built `basic-tutorial` flow. Let's run it.

1.  **Open the Workbench** in your browser at [`http://localhost:3000`](http://localhost:3000).
2.  **Click the `Tutorial`** button on the top right of the workbench.
3.  **Complete the `Tutorial`** to get an understanding of the basics of Motia and using the Workbench.

![run starter app](/docs-images/motia-build-your-app.gif)

</Step>

<Step>
### Next Steps

Congratulations! You've successfully ran, and observed your first Motia workflow.

- Build your first application from scratch, follow our **[Build Your First Motia App](/docs/getting-started/build-your-first-motia-app)** guide.
- To learn about Motia, dive into our **[Core Concepts](/docs/concepts/overview)**.

</Step>
</Steps>


-   [index](/docs/): Documentation for index.
---
title: Welcome to Motia
description: "Build production-grade backends with a single primitive. APIs, background jobs, Queues, Workflows, and AI agents - unified in one system with built-in State management, Streaming, and Observability."
---

# Welcome to Motia

## Why Motia?

**Build production-grade backends with a single primitive.**

Modern backends shouldn't require juggling frameworks, queues, and services. Motia unifies everything: API endpoints, background jobs, durable workflows, AI agents, streaming, and observability into one runtime with a single core primitive.

**Motia** is your complete backend solution:
- ðŸŒ **API** - RESTful endpoints with validation and routing
- âš¡ **Background Jobs** - Async processing with built-in queues
- ðŸ”„ **Durable Workflows** - Complex multi-step orchestration
- ðŸ¤– **Agentic** - AI agent workflows with streaming support
- ðŸª **State** - Built-in persistent storage across Steps
- ðŸ“Š **Streaming** - Real-time data updates to clients
- ðŸ“ **Logging** - Structured, traceable logs
- ðŸ‘ï¸ **Observability** - End-to-end tracing and monitoring

Just as React made frontend development simple by introducing components, **Motia redefines backend development with Steps** - a single primitive that powers everything.

To read more about this, check out our [manifesto](/manifesto).

---
## The Core Primitive: the Step

At the heart of Motia is a single primitive: the **Step**.  

A Step is just a file with a `config` and a `handler`. Motia auto-discovers these files from `/steps` directory and connects them automatically.

Hereâ€™s a simple example of two Steps working together: an API Step that emits an event, and an Event Step that processes it.

<Tabs items={['TypeScript', 'Python', 'JavaScript']}>
<Tab value='TypeScript'>

```ts title="steps/send-message.step.ts"
export const config = {
  name: 'SendMessage',
  type: 'api',
  path: '/messages',
  method: 'POST',
  emits: ['message.sent']
};

export const handler = async (req, { emit }) => {
  await emit({
    topic: 'message.sent',
    data: { text: req.body.text }
  });
  return { status: 200, body: { ok: true } };
};
```

```ts title="steps/process-message.step.ts"
export const config = {
  name: 'ProcessMessage',
  type: 'event',
  subscribes: ['message.sent']
};

export const handler = async (input, { logger }) => {
  logger.info('Processing message', input);
};
```
</Tab>

<Tab value='Python'>

```python title="send_message_step.py"
config = {
    "name": "SendMessage",
    "type": "api",
    "path": "/messages",
    "method": "POST",
    "emits": ["message.sent"]
}

async def handler(req, ctx):
    await ctx.emit({
        "topic": "message.sent",
        "data": {"text": req.body["text"]}
    })
    return {"status": 200, "body": {"ok": True}}
```

```python title="process_message_step.py"
config = {
    "name": "ProcessMessage",
    "type": "event",
    "subscribes": ["message.sent"]
}

async def handler(input, ctx):
    ctx.logger.info("Processing message", input)
```
</Tab>

<Tab value='JavaScript'>

```js title="steps/send-message.step.js"
const config = {
  name: 'SendMessage',
  type: 'api',
  path: '/messages',
  method: 'POST',
  emits: ['message.sent']
};

const handler = async (req, { emit }) => {
  await emit({
    topic: 'message.sent',
    data: { text: req.body.text }
  });
  return { status: 200, body: { ok: true } };
};

module.exports = { config, handler };
```

```js title="steps/process-message.step.js"
const config = {
  name: 'ProcessMessage',
  type: 'event',
  subscribes: ['message.sent']
};

const handler = async (input, { logger }) => {
  logger.info('Processing message', input);
};

module.exports = { config, handler };
```
</Tab>
</Tabs>

ðŸ‘‰ With just two files, youâ€™ve built an **API endpoint**, a **queue**, and a **worker**. No extra frameworks required.

Learn more about Steps here: [What is a Step?](/docs/concepts/steps).

---

### Working with multiple Languages

The rapid advancement of AI has reshaped the software industryâ€”many cutting-edge AI tools are available only in specific programming languages, this forces companies to decide if they either change their team's skillset to a different language or not leveraging these technologies at all.

Motia removes this limitation by allowing each Step to be written in any language, while still sharing a common state.

![Multi-language](./img/what-is-motia/multi-language.png)

_Each rectangle in the diagram above represents a Step, some of them are in TypeScript and others in Python._

## Scalability

One of the biggest dilemmas in backend development is choosing between scalability and development velocity. In startup environments, speed often takes priority, resulting in systems that don't scale well and become problematic under increased load.

Motia addresses scalability by leveraging the core primitive of **Steps**: Each step can scale independently avoiding the bottlenecks common in monolithic architectures.

![Scalable](./img/what-is-motia/scalable.png)

## Observability

Observability in traditional backends often demands significant engineering effort to implement logging, alerting, and tracing. Typically, these tools are only configured for cloud environments, local development is generally neglectedâ€”leading to low productivity and poor dev experience.

Motia offers a complete observability toolkit available in both cloud and local environments, including:

- Logs visualization
- Tracing tool to quickly visualize the flow of requests through the system
- State visualization
- Diagram representation of dependencies between steps and how they are connected

_The image below shows the Workbench interface available when you run `motia dev`. On the top panel you can see a workflow diagram with multiple steps connected.
On the bottom panel you can see the trace view of a single request and what happened in each step._

![Motia Workbench](./img/new-workbench.png)

## Fault tolerance

With the rise of AI, many backend tasks have become less deterministic and more error-prone. These scenarios require robust error handling and retry mechanisms. In traditional systems, developers often need to set up and maintain queue infrastructures to ensure resilience, especially when dealing with unreliable responses from LLMs.

Motia provides fault tolerance out of the box, eliminating the need to manually spin up queue infrastructure.

- Using Event Steps, you get retry mechanisms out of the box
- Configuration of queue infrastructure is abstracted away

## Building and Shipping

Building and deploying backends is inherently complexâ€”especially in polyglot environments. Shipping production systems requires tight collaboration between developers and operations, and automation often takes weeks to get right.

Beyond that, cloud provider lock-in, complicated deployment strategies (e.g., rollbacks, blue/green deployments), and a lack of deployment tooling increase the risk of failure.

Motia abstracts these concerns by providing:

- True cloud-provider agnosticism
- Atomic blue/green deployments and one-click rollbacks via Motia Cloud (canary support coming soon)
- First-class polyglot backend support (currently Node.js and Python, with more on the way)

![Deployments](./img/what-is-motia/deployments.png)

_The image above shows several Steps being build to a single Motia deployable that are ultimately deployed to a cloud provider of your choice. 
Currently we're supporting AWS and Kubernetes, more Cloud providers coming soon. Check our [roadmap](https://github.com/orgs/MotiaDev/projects/2/views/4?filterQuery=title%3A+BYOC) for more details._

### Rollbacks and deployment strategies

Deploying cloud-native, fault-tolerant applications often involves modifying queue systems and other infrastructure components. 
These changes can introduce incompatibilities and lead to runtime failures.

Motia Cloud solves this with **Atomic Deployments**, which:

- Each deployment spins up a new isolated service that shares the same data layer
- Ensures safe, rollback-capable deployments without risking service downtime
- Instant rollbacks with one click since each deployment is isolated

## Real-time data streaming

Handling real-time data is one of the most commonâ€”and complexâ€”challenges in backend development. It's necessary when building event-driven applications, 
and it typically requires setting up and maintaining a significant amount of infrastructure.

Motia provides what we call _Streams_: Developers define the structure of the dataâ€”any changes to these objects are streamed to all subscribed clients in real-time.

![Real-time data streaming](./img/what-is-motia/streams.png)

_The image above shows a Stream definition, a Node.js Step mutating the data and a client subscribing to the stream receiving real-time updates._

-   ['ChessArena AI'](/docs/product-showcase/chessarena-ai): Documentation for 'ChessArena AI'.
---
title: 'ChessArena AI'
---

In the world of AI development, chess serves as the perfect benchmark for intelligence and strategic thinking. But how do you measure which AI models truly "understand" chess beyond simple win/loss statistics? ChessArena.AI solves this challenge by focusing on move quality and game insight rather than just outcomes.

This comprehensive guide explores how to build a production-ready chess platform using Motia's event-driven architecture and real-time streaming capabilities. We'll cover:

1. **Real-Time Chess Streaming**: How Motia Streams enable live game updates across all connected players
2. **Multi-Language Architecture**: Combining TypeScript orchestration with Python chess engine integration
3. **AI Model Integration**: Supporting multiple LLM providers (OpenAI, Anthropic Claude, Google Gemini, xAI Grok) for chess gameplay
4. **Move Evaluation System**: Using Stockfish engine for real-time move analysis and scoring
5. **Production Deployment**: How this exact platform powers the live ChessArena.AI website

Let's build a chess platform that measures AI intelligence through gameplay quality.

---

## ðŸ­ Production-Grade Chess Platform

<div className="my-8">![ChessArena AI Workbench](./../img/chessarena-workbench.png)</div>

**This is not a tutorial project** - this is battle-tested, production-ready code that handles real traffic at scale. Every aspect has been designed for enterprise use:

- **ðŸŽ® Live Chess Platform**: Real-time games with multiple AI models competing simultaneously
- **ðŸ“Š Move Quality Analysis**: Every move evaluated by Stockfish engine for strategic insight
- **âš¡ Real-Time Updates**: Live game state synchronization across all connected clients
- **ðŸ¤– Multi-AI Support**: OpenAI GPT, Anthropic Claude, XAI Grok, Google Gemini integration
- **ðŸ† Dynamic Leaderboards**: Real-time scoring based on move quality, not just wins
- **ðŸŒ Global Scale**: Production deployment on Motia Cloud with worldwide accessibility
- **ðŸ’° Cost Efficient**: Event-driven architecture that scales efficiently

---

## Live Proof: Powering ChessArena.AI

**This isn't just a demo** - this exact code powers the live chess platform at [ChessArena.AI](https://chessarena.ai)!

Visit the platform and you'll see:
- **ðŸ† Live AI Leaderboard** ranking models by move quality
- **âš¡ Real-Time Games** with instant move updates and evaluations
- **ðŸ“Š Move Analysis** showing centipawn scores and blunder detection
- **ðŸŽ® Multi-Model Battles** with GPT-5, Claude Opus 4, Gemini 2.5 Flash, and Grok 4 competing

That live chess platform with real-time AI battles? That's this exact implementation in production, processing thousands of moves and providing instant feedback to chess enthusiasts worldwide!

---

## The Power of Strategic AI Evaluation

<div className="my-8">![ChessArena AI](./../img/chessarena.png)</div>

At its core, ChessArena.AI solves a fundamental challenge: how do you measure AI intelligence in chess beyond simple win/loss statistics? Traditional chess platforms focus on game outcomes, but most LLM games end in draws, making it difficult to distinguish between models.

Our Motia-powered solution revolutionizes AI chess evaluation through:

- **[Stockfish Integration](https://stockfishchess.org/)**: World's strongest open-source chess engine for move analysis
- **[Centipawn Scoring](https://en.wikipedia.org/wiki/Chess_piece_relative_value#Centipawns)**: Precise move quality measurement in hundredths of a pawn
- **[Real-Time Streaming](https://motia.dev)**: Live game updates and move evaluations
- **[Multi-LLM Support](https://platform.openai.com/)**: Support for OpenAI, Anthropic, and Google AI models

Instead of focusing on who wins, we measure how well each AI model understands chess strategy and tactics.

---

## The Anatomy of Our Chess Platform

Our application consists of specialized components handling different aspects of chess gameplay, from game creation to move evaluation. Let's explore the complete architecture.

<Folder name="api/steps" defaultOpen>
  <Folder name="chess" defaultOpen>
    <File name="00-available-models-api.step.ts" />
    <File name="01-create-game.step.ts" />
    <File name="02-get-game.step.ts" />
    <File name="03-move-api.step.ts" />
    <File name="04-chess-game-moved.step.ts" />
    <File name="05-ai-player.step.ts" />
    <File name="evaluate_player_move_step.py" />
    <Folder name="streams" defaultOpen>
      <File name="00-chess-game.stream.ts" />
      <File name="00-chess-game-move.stream.ts" />
      <File name="00-chess-leaderboard.stream.ts" />
    </Folder>
  </Folder>
  <Folder name="auth" defaultOpen>
    <File name="00-auth-api.step.ts" />
    <File name="01-get-user-api.step.ts" />
  </Folder>
</Folder>

<Tabs items={['models-api', 'create-game', 'move-evaluation', 'ai-player', 'streams', 'auth']}>
  <Tab value="models-api">
    The entry point that exposes available AI models from different providers (OpenAI, Anthropic, Google, xAI) for chess gameplay. The platform supports cutting-edge models and allows easy extension for new providers.

    ```typescript
    import { AiModelsSchema } from '@chessarena/types/ai-models'
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'
    import { supportedModelsByProvider } from '../../services/ai/models'

    // Current supported models (as of 2025)
    export const supportedModelsByProvider: AiModels = {
      openai: [
        'gpt-5-2025-08-07',           // Latest GPT-5
        'o4-mini-2025-04-16',         // O4 Mini
        'gpt-4.1-nano-2025-04-14',   // GPT-4.1 Nano
        'o3-mini-2025-01-31',        // O3 Mini
        'gpt-4o-mini-2024-07-18',    // GPT-4o Mini
      ],
      gemini: [
        'gemini-2.5-flash',          // Latest Gemini 2.5 Flash
        'gemini-2.0-flash-001',      // Gemini 2.0 Flash
      ],
      claude: [
        'claude-opus-4-1-20250805',  // Claude Opus 4.1
        'claude-opus-4-20250514',    // Claude Opus 4
        'claude-sonnet-4-20250514',  // Claude Sonnet 4
        'claude-3-7-sonnet-20250219', // Claude 3.7 Sonnet
        'claude-3-5-sonnet-20241022', // Claude 3.5 Sonnet
        'claude-3-5-haiku-20241022',  // Claude 3.5 Haiku
      ],
      grok: [
        'grok-4',                     // Latest Grok 4
        'grok-3',                     // Grok 3
      ],
    }

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'AvailableModels',
      description: 'Expose all available AI models for supported providers',
      path: '/chess/models',
      method: 'GET',
      emits: [],
      flows: ['chess'],
      responseSchema: {
        200: z.object({ models: AiModelsSchema() }),
        404: z.object({ message: z.string() }),
        400: z.object({ message: z.string() }),
      },
    }

    export const handler: Handlers['AvailableModels'] = async (_, { logger }) => {
      logger.info('Received available models request')

      return {
        status: 200,
        body: {
          models: supportedModelsByProvider,
        },
      }
    }
    ```

  </Tab>
  <Tab value="create-game">
    The game creation endpoint that validates AI model selections and initializes new chess games with proper player configurations.

    ```typescript
    import { AiModelProviderSchema } from '@chessarena/types/ai-models'
    import { GameSchema, Player } from '@chessarena/types/game'
    import { ApiRouteConfig, Handlers } from 'motia'
    import { RefinementCtx, z } from 'zod'
    import { supportedModelsByProvider } from '../../services/ai/models'
    import { createGame } from '../../services/chess/create-game'
    import { auth } from '../middlewares/auth.middleware'

    const playerSchema = () => {
      return z
        .object({
          ai: AiModelProviderSchema().optional(),
          model: z.string().optional(),
        })
        .superRefine((data: Player, ctx: RefinementCtx) => {
          if (data.ai && !data.model) {
            ctx.addIssue({
              code: z.ZodIssueCode.custom,
              path: ['model'],
              message: 'Model is required when AI is enabled',
            })
          }

          if (data.ai) {
            const isValidAiProvider = data.ai in supportedModelsByProvider
            const isValidModel = data.model && supportedModelsByProvider[data.ai]?.includes(data.model)

            if (!isValidAiProvider || !isValidModel) {
              ctx.addIssue({
                code: z.ZodIssueCode.custom,
                path: data.ai ? ['model'] : ['ai'],
                message: data.ai ? 'Invalid AI model' : 'Invalid AI provider',
              })
            }
          }
        })
    }

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'CreateGame',
      description: 'Create a new chess game',
      path: '/chess/create-game',
      method: 'POST',
      emits: ['chess-game-created'],
      flows: ['chess'],
      bodySchema: z.object({
        players: z.object({
          white: playerSchema(),
          black: playerSchema(),
        }),
      }),
      middleware: [auth({ required: true })],
      responseSchema: {
        200: GameSchema,
        400: z.object({ message: z.string(), errors: z.array(z.object({ message: z.string() })) }),
        401: z.object({ message: z.string() }),
      },
    }

    export const handler: Handlers['CreateGame'] = async (req, { logger, emit, streams }) => {
      logger.info('[CreateGame] Creating new chess game')

      const game = await createGame(req.body.players, req.user, streams, logger)

      await emit({
        topic: 'chess-game-created',
        data: { gameId: game.id, fenBefore: game.fen },
      })

      logger.info('[CreateGame] Game created successfully', { gameId: game.id })

      return { status: 200, body: game }
    }
    ```

  </Tab>
  <Tab value="move-evaluation">
    The Python-powered move evaluation system that uses Stockfish to analyze every move and calculate centipawn scores for strategic insight.

    ```python
    import chess
    import chess.engine
    import os
    from pydantic import BaseModel, Field

    class EvaluatePlayerMoveInput(BaseModel):
        fenBefore: str = Field(description="The FEN of the game before the move")
        fenAfter: str = Field(description="The FEN of the game after the move")
        gameId: str = Field(description="The ID of the game")
        moveId: str = Field(description="The ID of the move")
        player: str = Field(description="The player who made the move")

    config = {
        "type": "event",
        "name": "EvaluatePlayerMove",
        "description": "Evaluates move quality using Stockfish engine",
        "subscribes": ["evaluate-player-move"], 
        "emits": [],
        "flows": ["chess"],
        "input": EvaluatePlayerMoveInput.model_json_schema(),
    }

    class Evaluation(BaseModel):
        centipawn_score: int = Field(description="The evaluation in centipawns")
        best_move: str = Field(description="The best move")

    async def evaluate_position(
        engine: chess.engine.SimpleEngine,
        board: chess.Board,
        player: str,
        time_limit: float = 1.5
    ) -> Evaluation:
        """Evaluate a chess position and return analysis results."""
        analysis = await engine.analyse(
            board, 
            chess.engine.Limit(time=time_limit),
            info=chess.engine.INFO_ALL
        )
        
        score = analysis["score"]
        centipawn_score = score.white().score() if player == "white" else score.black().score()
        move = analysis.get("pv", [None])[0]

        return Evaluation(
            centipawn_score=centipawn_score if centipawn_score is not None else 0,
            best_move=move.uci() if move is not None else None
        )

    async def handler(input: EvaluatePlayerMoveInput, ctx):
        logger = ctx.logger
        
        # Initialize Stockfish engine
        engine_path = os.getenv("STOCKFISH_BIN_PATH")
        if not engine_path:
            raise EnvironmentError("STOCKFISH_BIN_PATH environment variable not set")
        
        _, engine = await chess.engine.popen_uci(engine_path)
        
        try:
            # Create boards from the positions
            board_before = chess.Board(input.fenBefore)
            board_after = chess.Board(input.fenAfter)
        
            # Evaluate positions
            eval_before = await evaluate_position(engine, board_before, input.player)
            eval_after = await evaluate_position(engine, board_after, input.player)

            # Calculate best move evaluation
            best_move = chess.Move.from_uci(eval_before.best_move)
            board_before.push(best_move)
            eval_best_move = await evaluate_position(engine, board_before, input.player)

            # Calculate move quality metrics
            evaluation_swing = max(0, eval_best_move.centipawn_score - eval_after.centipawn_score)
            blunder = evaluation_swing > 100  # Moves losing >100 centipawns are blunders

            evaluation = {
                "centipawnScore": eval_after.centipawn_score,
                "bestMove": eval_after.best_move,
                "evaluationSwing": evaluation_swing,
                "blunder": blunder,
            }

            # Update move in streams with evaluation
            move_stream = await ctx.streams.chessGameMove.get(input.gameId, input.moveId)
            move_stream["evaluation"] = evaluation
            await ctx.streams.chessGameMove.set(input.gameId, input.moveId, move_stream)

            logger.info("Move evaluation completed", { "evaluation": evaluation })

        finally:
            await engine.quit()
    ```

  </Tab>
  <Tab value="ai-player">
    The AI orchestration step that coordinates with different LLM providers using a unified prompt system. Features retry logic, move validation, and real-time thought streaming.

    ```typescript
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'
    import { makePrompt } from '../../services/ai/make-prompt'
    import { evaluateBestMoves } from '../../services/chess/evaluate-best-moves'
    import { move } from '../../services/chess/move'
    import mustache from 'mustache'

    const MAX_ATTEMPTS = 3

    const responseSchema = z.object({
      thought: z.string({
        description: 'The thought process of the move, make it look like you were just thinking for yourself'
      }),
      move: z.object({
        from: z.string({ description: 'The square to move from, example: e2' }),
        to: z.string({ description: 'The square to move to, example: e4' }),
        promote: z.enum(['queen', 'rook', 'bishop', 'knight']).optional(),
      }),
    })

    export const config: EventConfig = {
      type: 'event',
      name: 'AI_Player',
      description: 'AI Player with unified provider system and retry logic',
      subscribes: ['ai-move'],
      emits: ['chess-game-moved', 'chess-game-ended', 'evaluate-player-move'],
      flows: ['chess'],
      includeFiles: ['05-ai-player.mustache'], // Mustache template for chess prompts
    }

    export const handler: Handlers['AI_Player'] = async (input, { logger, emit, streams }) => {
      const game = await streams.chessGame.get('game', input.gameId)
      const player = input.player === 'white' ? game.players.white : game.players.black

      if (!player.ai) {
        logger.error('Player has no AI configured', { gameId: input.gameId })
        return
      }

      let attempts = 0
      let lastInvalidMove = undefined
      const validMoves = evaluateBestMoves(game)

      while (attempts < MAX_ATTEMPTS) {
        const messageId = crypto.randomUUID()

        // Create real-time thinking message
        await streams.chessGameMessage.set(input.gameId, messageId, {
          id: messageId,
          message: 'Thinking...',
          sender: player.ai,
          role: input.player,
          timestamp: Date.now(),
        })

        // Generate prompt using Mustache template
        const prompt = mustache.render(template, {
          fenBefore: input.fenBefore,
          fen: input.fen,
          lastMove: input.lastMove,
          inCheck: input.check,
          player: input.player,
          lastInvalidMove,
          validMoves,
        })

        try {
          // Use unified AI provider system
          const action = await makePrompt({
            prompt,
            zod: responseSchema,
            provider: player.ai,  // 'openai', 'claude', 'gemini', or 'grok'
            logger,
            model: player.model!, // Specific model like 'gpt-5-2025-08-07'
          })

          // Update message with AI's thought process
          await streams.chessGameMessage.set(input.gameId, messageId, {
            message: action.thought,
            move: action.move,
            sender: player.ai,
            role: input.player,
            timestamp: Date.now(),
          })

          // Execute the chess move
          await move({
            logger,
            streams,
            gameId: input.gameId,
            player: input.player,
            game,
            action: action.move,
            emit,
            illegalMoveAttempts: attempts,
          })

          return // Success!

        } catch (err) {
          attempts++
          lastInvalidMove = action?.move
          
          // Handle illegal moves with retry logic
          if (attempts >= MAX_ATTEMPTS) {
            // Player loses after too many illegal moves
            await streams.chessGame.set('game', game.id, {
              ...game,
              status: 'completed',
              winner: input.player === 'white' ? 'black' : 'white',
              endGameReason: 'Too many illegal moves',
            })
            
            await emit({
              topic: 'chess-game-ended',
              data: { gameId: input.gameId },
            })
          }
        }
      }
    }
    ```

  </Tab>
  <Tab value="streams">
    The real-time data streams that power live chess gameplay, storing game state, moves, and leaderboard data with automatic client synchronization.

    ```typescript
    // Chess Game Stream - stores complete game state
    import { StreamConfig } from 'motia'
    import { GameSchema } from '@chessarena/types/game'

    export const config: StreamConfig = {
      name: 'chessGame',
      schema: GameSchema,
      baseConfig: { storageType: 'default' },
    }
    ```

    ```typescript
    // Chess Game Move Stream - stores individual moves with evaluations
    import { StreamConfig } from 'motia'
    import { GameMoveSchema } from '@chessarena/types/game-move'

    export const config: StreamConfig = {
      name: 'chessGameMove',
      schema: GameMoveSchema,
      baseConfig: { storageType: 'default' },
    }
    ```

    ```typescript
    // Chess Leaderboard Stream - live AI model rankings
    import { StreamConfig } from 'motia'
    import { LeaderboardSchema } from '@chessarena/types/leaderboard'

    export const config: StreamConfig = {
      name: 'chessLeaderboard',
      schema: LeaderboardSchema,
      baseConfig: { storageType: 'default' },
    }
    ```

  </Tab>
  <Tab value="auth">
    The authentication system that manages user sessions and provides secure access to chess game creation and management.

    ```typescript
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'
    import { authenticateUser } from '../../services/auth/auth-service'

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'AuthAPI',
      description: 'Handle user authentication for chess platform',
      path: '/auth/login',
      method: 'POST',
      emits: ['user-authenticated'],
      flows: ['auth'],
      bodySchema: z.object({
        email: z.string().email(),
        password: z.string().min(6),
      }),
      responseSchema: {
        200: z.object({ 
          token: z.string(), 
          user: z.object({ id: z.string(), email: z.string() }) 
        }),
        401: z.object({ message: z.string() }),
      },
    }

    export const handler: Handlers['AuthAPI'] = async (req, { logger, emit }) => {
      const { email, password } = req.body

      try {
        const authResult = await authenticateUser(email, password)
        
        if (!authResult.success) {
          return { status: 401, body: { message: 'Invalid credentials' } }
        }

        await emit({
          topic: 'user-authenticated',
          data: { userId: authResult.user.id, email: authResult.user.email },
        })

        return {
          status: 200,
          body: {
            token: authResult.token,
            user: authResult.user,
          },
        }
      } catch (error) {
        logger.error('[AuthAPI] Authentication error', { error: error.message })
        return { status: 401, body: { message: 'Authentication failed' } }
      }
    }
    ```

  </Tab>
</Tabs>

---

## Extensible AI Provider System

ChessArena.AI features a plugin-based architecture that makes adding new AI providers incredibly simple. The unified `makePrompt` system handles all provider differences behind a clean interface.

### Adding New AI Providers

To add a new AI provider (like Anthropic's upcoming models or other LLM providers), you only need to:

1. **Create a provider handler** in `services/ai/your-provider.ts`:

```typescript
import { Handler } from './types'

export const yourProvider: Handler = async ({ prompt, zod, logger, model }) => {
  // Initialize your AI client
  const client = new YourAIClient({ apiKey: process.env.YOUR_API_KEY })
  
  // Make the API call with structured output
  const response = await client.chat({
    model: model ?? 'your-default-model',
    messages: [{ role: 'user', content: prompt }],
    responseFormat: { type: 'json_schema', schema: zodToJsonSchema(zod) },
  })
  
  logger.info('Your provider response received', { model })
  
  return JSON.parse(response.content)
}
```

2. **Register the provider** in `services/ai/make-prompt.ts`:

```typescript
import { yourProvider } from './your-provider'

const providers: Record<AiModelProvider, Handler> = {
  openai,
  gemini,
  claude,
  grok,
  yourProvider, // Add your provider here
}
```

3. **Update the type definitions** in `types/ai-models.ts`:

```typescript
export const AiModelProviderSchema = () => 
  z.enum(['openai', 'gemini', 'claude', 'grok', 'yourProvider'])
```

4. **Add supported models** in `services/ai/models.ts`:

```typescript
export const supportedModelsByProvider: AiModels = {
  // ... existing providers
  yourProvider: [
    'your-model-v1',
    'your-model-v2-turbo',
    'your-model-reasoning',
  ],
}
```

That's it! Your new AI provider is now fully integrated and can compete in chess battles alongside GPT, Claude, Gemini, and Grok.

### Current Provider Implementations

The platform currently supports four major AI providers with their latest models:

- **OpenAI**: GPT-5, O4 Mini, GPT-4.1 series, O3 Mini
- **Anthropic**: Claude Opus 4.1, Claude Sonnet 4, Claude 3.7 series  
- **Google**: Gemini 2.5 Flash, Gemini 2.0 Flash
- **xAI**: Grok 4, Grok 3

Each provider uses optimized API calls with structured JSON output and proper error handling.

---

## Real-Time Chess Architecture

The beauty of this chess platform lies in its event-driven, real-time architecture. Here's how live chess games flow through the system:

1. **Game Creation** â†’ User selects AI models and creates a new game
2. **Move Generation** â†’ AI models generate moves using LLM APIs
3. **Move Validation** â†’ Chess rules validation and board state updates
4. **Stockfish Analysis** â†’ Real-time move evaluation and scoring
5. **Stream Updates** â†’ Live game state propagated to all connected clients
6. **Leaderboard Updates** â†’ AI model rankings updated based on move quality

**No manual state management, no complex WebSocket handling, no synchronization code required!**

---

## Key Features & Benefits

### ðŸŽ® **Real-Time Chess Gameplay**
Live games with instant move updates across all connected clients - watch AI models battle in real-time.

### ðŸ† **Intelligent Scoring System**  
Move quality evaluation using Stockfish engine with centipawn precision and blunder detection.

### ðŸ¤– **Multi-AI Integration**
Support for OpenAI GPT, Anthropic Claude, and Google Gemini models with unified API interface.

### âš¡ **Event-Driven Architecture**
Scalable, maintainable system where each component handles specific chess functionality.

### ðŸ“Š **Live Leaderboards**
Real-time AI model rankings based on move quality, strategic insight, and game performance.

### ðŸŒ **Production-Ready**
Battle-tested code powering the live ChessArena.AI platform with global accessibility.

---

## Trying It Out

Ready to build your own AI chess platform? Let's get it running.

<Steps>

### Clone and Install

Start by getting the project locally and installing dependencies.

```shell
git clone https://github.com/MotiaDev/chessarena-ai.git
cd chessarena-ai
pnpm install
```

### Install Stockfish Engine

The platform requires Stockfish for move evaluation. Choose your installation method:

**Option A: Using Homebrew (macOS - Recommended)**
```shell
brew install stockfish
```

**Option B: Using the project installer**
```shell
pnpm install-stockfish <platform>
# Supported: linux-x86, mac-m1
```

**Option C: Manual Installation**
Download from [stockfishchess.org](https://stockfishchess.org/)

### Configure Environment Variables

Create a `.env` file with your AI provider API keys:

```shell
# Required: AI Model API Keys
OPENAI_API_KEY="sk-..."
ANTHROPIC_API_KEY="sk-ant-..."
GOOGLE_AI_API_KEY="..."

# Required: Stockfish Engine Path
STOCKFISH_BIN_PATH="/opt/homebrew/bin/stockfish"

# Optional: Authentication (for user management)
JWT_SECRET="your-jwt-secret"
```

### Start the Chess Platform

Launch both the API backend and React frontend:

```shell
pnpm dev
```

This starts:
- **API Backend**: `http://localhost:3000` (Motia API with chess logic)
- **React Frontend**: `http://localhost:5173` (Chess game interface)

### Create Your First AI Battle

1. **Open the Chess Platform**: Navigate to `http://localhost:5173`
2. **Select AI Models**: Choose different models for white and black players
3. **Start the Game**: Watch AI models battle with real-time move evaluation
4. **View Analysis**: See centipawn scores, best moves, and blunder detection
5. **Check Leaderboards**: Monitor AI model performance rankings

### Access Real-Time Data

Your chess games are available via the Motia streams API:

```shell
# Get all active games
curl http://localhost:3000/api/streams/chessGame

# Get specific game state
curl http://localhost:3000/api/streams/chessGame/{gameId}

# Get move history with evaluations
curl http://localhost:3000/api/streams/chessGameMove/{gameId}

# Get AI model leaderboard
curl http://localhost:3000/api/streams/chessLeaderboard
```

### Deploy to Production

Once your chess platform is working locally, deploy it to production with Motia Cloud:

**Option 1: CLI Deployment**
```shell
# Deploy with version and API key
motia cloud deploy --api-key your-api-key --version-name 1.0.0

# Deploy with environment variables
motia cloud deploy --api-key your-api-key \
  --version-name 1.0.0 \
  --env-file .env.production \
  --environment-id your-env-id
```

**Option 2: One-Click Web Deployment**
1. Ensure your local project is running (`pnpm dev`)
2. Go to [Motia Cloud -> Import from Workbench](https://motia.cloud)
3. Select your local project port
4. Choose project and environment name
5. Upload environment variables (optional)
6. Click **Deploy** and watch the magic happen! âœ¨

</Steps>

---

## ðŸš€ Production Deployment Guide

### Environment Variables

Configure these environment variables for production security and functionality:

```shell
# Required: AI Model API Keys
OPENAI_API_KEY="sk-your-openai-key"          # For GPT-5, O4 Mini, GPT-4.1 series
ANTHROPIC_API_KEY="sk-ant-your-anthropic-key" # For Claude Opus 4.1, Sonnet 4
GEMINI_API_KEY="your-google-gemini-key"      # For Gemini 2.5 Flash, 2.0 Flash  
XAI_API_KEY="your-xai-grok-key"              # For Grok 4, Grok 3

# Required: Stockfish Engine Path
STOCKFISH_BIN_PATH="/opt/homebrew/bin/stockfish"

# Optional: Authentication for user management
JWT_SECRET="your-secure-jwt-secret"

# Optional: Database configuration for user data
DATABASE_URL="postgresql://user:password@host:port/database"
```

### Security Best Practices

For production deployments, ensure you:

1. **Secure API keys**: 
   ```shell
   # Generate a cryptographically secure JWT secret
   openssl rand -hex 32
   ```

2. **Store secrets securely**: Use environment variables, never commit API keys to code

3. **Monitor AI usage**: Track API usage and costs across different model providers

4. **Enable rate limiting**: Implement request limits to prevent abuse

### Scaling Considerations

This architecture scales automatically with your chess platform traffic:

- **Multiple games**: Each game gets its own stream for real-time updates
- **High concurrency**: Motia streams handle thousands of concurrent chess games
- **Global distribution**: Deploy to multiple regions for worldwide performance
- **AI model optimization**: Load balance across different model providers
- **Cost optimization**: Pay only for actual usage with serverless scaling

---

## ðŸ’» Dive into the Code

Want to explore the complete chess platform implementation? Check out the full source code with AI integration, real-time streams, and production deployment:

<div className="not-prose">
  <div className="bg-gradient-to-r from-amber-50 to-orange-50 border border-amber-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-amber-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Live ChessArena.AI Platform</h3>
        <p className="text-gray-600 mb-4">Access the complete implementation powering the live chess platform. See exactly how AI models battle with real-time evaluation and scoring!</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/chessarena-ai" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-amber-600 hover:bg-amber-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View ChessArena.AI Code
          </a>
          <a 
            href="https://chessarena.ai" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Play Live Chess â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Intelligence Through Strategic Play

This ChessArena.AI platform demonstrates how to build sophisticated AI evaluation systems using event-driven architecture. By focusing on move quality rather than simple win/loss statistics, we've created a platform that truly measures AI strategic understanding.

The beauty of this approach is its extensibility:
- **Add new AI models**: Integrate any LLM provider with the unified interface
- **Enhanced analysis**: Implement opening book analysis, endgame evaluation
- **Tournament modes**: Multi-round competitions with advanced scoring
- **Educational features**: Move explanations, tactical puzzles, learning modes

Key architectural benefits:
- **Real-time synchronization**: All clients see live game updates automatically
- **Scalable evaluation**: Stockfish analysis runs independently of game flow
- **Multi-language power**: TypeScript orchestration with Python chess engine integration
- **Production reliability**: Battle-tested code handling real user traffic

This exact implementation powers the live chess platform at [ChessArena.AI](https://chessarena.ai) - that real-time AI battle system with move-by-move evaluation? It's this code in action, proven at scale with thousands of chess enthusiasts worldwide.

**Production Metrics:**
- Handles 1,000+ concurrent chess games
- Processes 10,000+ moves daily with real-time evaluation
- Sub-100ms move analysis and streaming updates
- 99.9% uptime with automatic scaling

Ready to build AI evaluation platforms that measure true intelligence? Deploy production-ready chess systems with Motia today!


-   [Product Showcase](/docs/product-showcase): Documentation for Product Showcase.
---
title: Product Showcase
---

Explore full-scale production applications built with Motia that demonstrate the framework's capabilities in real-world scenarios.

<Cards>
  <Card
    title="ChessArena AI"
    href="/docs/product-showcase/chessarena-ai"
    description="Production-grade chess platform with real-time AI battles, move evaluation, and live leaderboards"
  />
</Cards>

<br/>

## ðŸ’» Live Applications

These are not just examples or tutorials - they are fully functional, production-ready applications that handle real user traffic and demonstrate Motia's capabilities at scale.

<div className="not-prose">
  <div className="bg-gradient-to-r from-green-50 to-blue-50 border border-green-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-green-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Production-Ready Applications</h3>
        <p className="text-gray-600 mb-4">These applications demonstrate Motia's enterprise capabilities with real user traffic, production deployments, and battle-tested architectures.</p>
        <div className="grid grid-cols-1 sm:grid-cols-2 gap-3">
          <a 
            href="https://chessarena.ai" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            ðŸ† Live Chess Platform
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            ðŸ“š Source Code â†’
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

## Contribute

Have you built something amazing with Motia? We'd love to feature your production application! Please [reach out to us](mailto:hello@motia.dev) with details about your project.


-   [video-showcase](/docs/video-showcase): Documentation for video-showcase.
---
title: Video Showcase
description: Watch Motia in action through our video demonstrations and tutorials
---

import VideoShowcase from '@/components/VideoShowcase';

{/* 
  TO UPDATE VIDEO TITLES & DESCRIPTIONS:
  1. Visit each YouTube URL below
  2. Copy the actual video title and description
  3. Replace the placeholder text in the videos array
  
  Video URLs to check:
  - https://youtu.be/U59FUduO6wY (Video ID: U59FUduO6wY)
  - https://youtu.be/UUVE5db78cc (Video ID: UUVE5db78cc)  
  - https://youtu.be/7KZS0syLrUo (Video ID: 7KZS0syLrUo)
  - https://youtu.be/JECQtMSBJyY (Video ID: JECQtMSBJyY)
*/}

# Video Showcase

Explore Motia's capabilities through our collection of demonstration videos and tutorials. These videos showcase real-world examples, feature walkthroughs, and development workflows.

<VideoShowcase
  title="Featured Videos"
  description="Watch Motia in action with these curated video demonstrations"
  columns={2}
  videos={[
    {
      id: "demo-1",
      title: "A challenge to traditional backend development flow",
      description: "A challenge to traditional backend",
      url: "https://youtu.be/U59FUduO6wY?si=pw4CmpZXLreHVzs6"
    },
    {
      id: "demo-2", 
      title: "Vercel but for backend",
      description: "Motia Overview",
      url: "https://youtu.be/UUVE5db78cc?si=th_rD9cgMsE1BJrt"
    },
    {
      id: "demo-3",
      title: "Next.js Background Jobs Are Easy Now",
      description: "Next.js Background Jobs with Motia",
      url: "https://youtu.be/7KZS0syLrUo?si=3LEyfcZ-5ZaEB8xQ"
    },
    {
      id: "demo-4",
      title: "You have never seen a DX (Developer Experience) like this",
      description: "Motia's Interactive tutorial Demo",
      url: "https://youtu.be/JECQtMSBJyY?si=aScCBb09B5tXfOsX"
    },
    {
      id: "demo-5",
      title: "The only AI framework youâ€™ll ever need",
      description: "Motia's tutorial for LinkedIn and Twitter Automation on Typefully",
      url: "https://www.youtube.com/watch?v=6EFTemC99AM"
    }
  ]}
/>

## Adding More Videos

To add more videos to this showcase, simply edit this file and add new video objects to the `videos` array. Each video should have:

- `id`: A unique identifier for the video
- `title`: The display title for the video
- `description`: A brief description of what the video covers
- `url`: The YouTube URL (supports various formats)

```typescript
{
  id: "your-video-id",
  title: "Your Video Title",
  description: "Brief description of the video content",
  url: "https://youtu.be/YOUR_VIDEO_ID"
}
```



## Optional
-   [https://motiadev.com](https://motiadev.com): Main page for framework.
-   [Github repo](https://github.com/motiadev/motia): Main github repository to file issues.
